@main () -> () {
    prog.fragment @deinit <CPU> <data> {
        addr:0xffffffffffffffff prog.label[symbol:deinit.__entry]
    }
    prog.fragment @__MLLM_JIT_PACKAGE_CODE_SEGMENT <CPU> <code> {
        addr:0x00000000000000 prog.mode_config[flag:1]
        addr:0x00000000000001 prog.bind[type:0, program_uuid:580, input_pos:0]
        addr:0x00000000000002 prog.bind[type:0, program_uuid:588, input_pos:1]
        addr:0x00000000000003 prog.bind[type:0, program_uuid:589, input_pos:2]
        addr:0x00000000000004 prog.jump visual.__entry[offset:3]
        addr:0x00000000000005 prog.bind[type:1, program_uuid:1266, input_pos:0]
        addr:0x00000000000006 prog.exit() -> ()
        addr:0x00000000000007 prog.label[symbol:visual.__entry]
        addr:0x00000000000008 prog.jump visual.patch_embed.__entry[offset:35]
        addr:0x00000000000009 prog.jump visual.blocks.0.__entry[offset:40]
        addr:0x0000000000000a prog.jump visual.blocks.1.__entry[offset:91]
        addr:0x0000000000000b prog.jump visual.blocks.2.__entry[offset:142]
        addr:0x0000000000000c prog.jump visual.blocks.3.__entry[offset:193]
        addr:0x0000000000000d prog.jump visual.blocks.4.__entry[offset:244]
        addr:0x0000000000000e prog.jump visual.blocks.5.__entry[offset:295]
        addr:0x0000000000000f prog.jump visual.blocks.6.__entry[offset:346]
        addr:0x00000000000010 prog.jump visual.blocks.7.__entry[offset:397]
        addr:0x00000000000011 prog.jump visual.blocks.8.__entry[offset:448]
        addr:0x00000000000012 prog.jump visual.blocks.9.__entry[offset:499]
        addr:0x00000000000013 prog.jump visual.blocks.10.__entry[offset:550]
        addr:0x00000000000014 prog.jump visual.blocks.11.__entry[offset:601]
        addr:0x00000000000015 prog.jump visual.blocks.12.__entry[offset:652]
        addr:0x00000000000016 prog.jump visual.blocks.13.__entry[offset:703]
        addr:0x00000000000017 prog.jump visual.blocks.14.__entry[offset:754]
        addr:0x00000000000018 prog.jump visual.blocks.15.__entry[offset:805]
        addr:0x00000000000019 prog.jump visual.blocks.16.__entry[offset:856]
        addr:0x0000000000001a prog.jump visual.blocks.17.__entry[offset:907]
        addr:0x0000000000001b prog.jump visual.blocks.18.__entry[offset:958]
        addr:0x0000000000001c prog.jump visual.blocks.19.__entry[offset:1009]
        addr:0x0000000000001d prog.jump visual.blocks.20.__entry[offset:1060]
        addr:0x0000000000001e prog.jump visual.blocks.21.__entry[offset:1111]
        addr:0x0000000000001f prog.jump visual.blocks.22.__entry[offset:1162]
        addr:0x00000000000020 prog.jump visual.blocks.23.__entry[offset:1213]
        addr:0x00000000000021 prog.jump visual.blocks.24.__entry[offset:1264]
        addr:0x00000000000022 prog.jump visual.blocks.25.__entry[offset:1315]
        addr:0x00000000000023 prog.jump visual.blocks.26.__entry[offset:1366]
        addr:0x00000000000024 prog.jump visual.blocks.27.__entry[offset:1417]
        addr:0x00000000000025 prog.jump visual.blocks.28.__entry[offset:1468]
        addr:0x00000000000026 prog.jump visual.blocks.29.__entry[offset:1519]
        addr:0x00000000000027 prog.jump visual.blocks.30.__entry[offset:1570]
        addr:0x00000000000028 prog.jump visual.blocks.31.__entry[offset:1621]
        addr:0x00000000000029 prog.jump visual.merger.__entry[offset:1674]
        addr:0x0000000000002a prog.ret
        addr:0x0000000000002b prog.label[symbol:visual.patch_embed.__entry]
        addr:0x0000000000002c prog.kernel_launch(%580:tensor<[680, 1176], Float32, CPU>) -> (%580:tensor<[680, 3, 2, 14, 14], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,2,14,14]}]
        addr:0x0000000000002d prog.kernel_launch(%580:tensor<[680, 3, 2, 14, 14], Float32, CPU>) -> (%590:tensor<[680, 1280, 1, 1, 1], Float32, CPU>)[symbol_name:visual.patch_embed.proj, op_type:Conv3D, op_options:{"bias":false,"impl_type":"Default","in_channels":3,"kernel_size":[2,14,14],"out_channels":1280,"stride":[2,14,14]}]
        addr:0x0000000000002e prog.free(%580:tensor<[680, 3, 2, 14, 14], Float32, CPU>) -> ()
        addr:0x0000000000002f prog.kernel_launch(%590:tensor<[680, 1280, 1, 1, 1], Float32, CPU>) -> (%590:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000030 prog.ret
        addr:0x00000000000031 prog.label[symbol:visual.blocks.0.__entry]
        addr:0x00000000000032 prog.kernel_launch(%590:tensor<[680, 1280], Float32, CPU>) -> (%591:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.0.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000033 prog.jump visual.blocks.0.attn.__entry[offset:10]
        addr:0x00000000000034 prog.kernel_launch(%590:tensor<[680, 1280], Float32, CPU>, %605:tensor<[680, 1280], Float32, CPU>) -> (%606:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000035 prog.free(%605:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000036 prog.free(%590:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000037 prog.kernel_launch(%606:tensor<[680, 1280], Float32, CPU>) -> (%607:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.0.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000038 prog.jump visual.blocks.0.mlp.__entry[offset:37]
        addr:0x00000000000039 prog.kernel_launch(%606:tensor<[680, 1280], Float32, CPU>, %610:tensor<[680, 1280], Float32, CPU>) -> (%611:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000003a prog.free(%610:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000003b prog.free(%606:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000003c prog.ret
        addr:0x0000000000003d prog.label[symbol:visual.blocks.0.attn.__entry]
        addr:0x0000000000003e prog.kernel_launch(%591:tensor<[680, 1280], Float32, CPU>) -> (%592:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.0.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000003f prog.free(%591:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000040 prog.kernel_launch(%592:tensor<[680, 3840], Float32, CPU>) -> (%592:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000041 prog.kernel_launch(%592:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%593:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000042 prog.free(%592:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000043 prog.kernel_launch(%593:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%593:tensor<[3, 680, 16, 80], Float32, CPU>, %593:tensor<[3, 680, 16, 80], Float32, CPU>, %593:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000044 prog.kernel_launch(%593:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%594:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.0.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000045 prog.kernel_launch(%593:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%595:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.0.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000046 prog.kernel_launch(%594:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%596:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000047 prog.free(%594:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000048 prog.kernel_launch(%595:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%597:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000049 prog.free(%595:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000004a prog.kernel_launch(%593:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%598:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000004b prog.free(%593:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000004c prog.kernel_launch(%596:tensor<[1, 16, 680, 80], Float32, CPU>, %597:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%599:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000004d prog.free(%597:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000004e prog.free(%596:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000004f prog.kernel_launch(%599:tensor<[1, 16, 680, 680], Float32, CPU>, %600:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%601:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000050 prog.free(%600:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000051 prog.free(%599:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000052 prog.kernel_launch(%601:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%602:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.0.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000053 prog.free(%601:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000054 prog.kernel_launch(%602:tensor<[1, 16, 680, 680], Float32, CPU>, %598:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%603:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000055 prog.free(%598:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000056 prog.free(%602:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000057 prog.kernel_launch(%603:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%604:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000058 prog.free(%603:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000059 prog.kernel_launch(%604:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%604:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000005a prog.kernel_launch(%604:tensor<[680, 1280], Float32, CPU>) -> (%605:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.0.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000005b prog.free(%604:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000005c prog.ret
        addr:0x0000000000005d prog.label[symbol:visual.blocks.0.mlp.__entry]
        addr:0x0000000000005e prog.kernel_launch(%607:tensor<[680, 1280], Float32, CPU>) -> (%608:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.0.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000005f prog.free(%607:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000060 prog.kernel_launch(%608:tensor<[680, 5120], Float32, CPU>) -> (%609:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.0.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000061 prog.free(%608:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000062 prog.kernel_launch(%609:tensor<[680, 5120], Float32, CPU>) -> (%610:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.0.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000063 prog.free(%609:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000064 prog.ret
        addr:0x00000000000065 prog.label[symbol:visual.blocks.1.__entry]
        addr:0x00000000000066 prog.kernel_launch(%611:tensor<[680, 1280], Float32, CPU>) -> (%612:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.1.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000067 prog.jump visual.blocks.1.attn.__entry[offset:10]
        addr:0x00000000000068 prog.kernel_launch(%611:tensor<[680, 1280], Float32, CPU>, %626:tensor<[680, 1280], Float32, CPU>) -> (%627:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000069 prog.free(%626:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000006a prog.free(%611:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000006b prog.kernel_launch(%627:tensor<[680, 1280], Float32, CPU>) -> (%628:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.1.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000006c prog.jump visual.blocks.1.mlp.__entry[offset:37]
        addr:0x0000000000006d prog.kernel_launch(%627:tensor<[680, 1280], Float32, CPU>, %631:tensor<[680, 1280], Float32, CPU>) -> (%632:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000006e prog.free(%631:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000006f prog.free(%627:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000070 prog.ret
        addr:0x00000000000071 prog.label[symbol:visual.blocks.1.attn.__entry]
        addr:0x00000000000072 prog.kernel_launch(%612:tensor<[680, 1280], Float32, CPU>) -> (%613:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.1.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000073 prog.free(%612:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000074 prog.kernel_launch(%613:tensor<[680, 3840], Float32, CPU>) -> (%613:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000075 prog.kernel_launch(%613:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%614:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000076 prog.free(%613:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000077 prog.kernel_launch(%614:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%614:tensor<[3, 680, 16, 80], Float32, CPU>, %614:tensor<[3, 680, 16, 80], Float32, CPU>, %614:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000078 prog.kernel_launch(%614:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%615:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.1.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000079 prog.kernel_launch(%614:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%616:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.1.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000007a prog.kernel_launch(%615:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%617:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000007b prog.free(%615:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000007c prog.kernel_launch(%616:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%618:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000007d prog.free(%616:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000007e prog.kernel_launch(%614:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%619:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000007f prog.free(%614:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000080 prog.kernel_launch(%617:tensor<[1, 16, 680, 80], Float32, CPU>, %618:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%620:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000081 prog.free(%618:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000082 prog.free(%617:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000083 prog.kernel_launch(%620:tensor<[1, 16, 680, 680], Float32, CPU>, %621:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%622:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000084 prog.free(%621:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000085 prog.free(%620:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000086 prog.kernel_launch(%622:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%623:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.1.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000087 prog.free(%622:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000088 prog.kernel_launch(%623:tensor<[1, 16, 680, 680], Float32, CPU>, %619:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%624:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000089 prog.free(%619:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000008a prog.free(%623:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000008b prog.kernel_launch(%624:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%625:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000008c prog.free(%624:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000008d prog.kernel_launch(%625:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%625:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000008e prog.kernel_launch(%625:tensor<[680, 1280], Float32, CPU>) -> (%626:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.1.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000008f prog.free(%625:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000090 prog.ret
        addr:0x00000000000091 prog.label[symbol:visual.blocks.1.mlp.__entry]
        addr:0x00000000000092 prog.kernel_launch(%628:tensor<[680, 1280], Float32, CPU>) -> (%629:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.1.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000093 prog.free(%628:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000094 prog.kernel_launch(%629:tensor<[680, 5120], Float32, CPU>) -> (%630:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.1.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000095 prog.free(%629:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000096 prog.kernel_launch(%630:tensor<[680, 5120], Float32, CPU>) -> (%631:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.1.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000097 prog.free(%630:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000098 prog.ret
        addr:0x00000000000099 prog.label[symbol:visual.blocks.2.__entry]
        addr:0x0000000000009a prog.kernel_launch(%632:tensor<[680, 1280], Float32, CPU>) -> (%633:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.2.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000009b prog.jump visual.blocks.2.attn.__entry[offset:10]
        addr:0x0000000000009c prog.kernel_launch(%632:tensor<[680, 1280], Float32, CPU>, %647:tensor<[680, 1280], Float32, CPU>) -> (%648:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000009d prog.free(%647:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000009e prog.free(%632:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000009f prog.kernel_launch(%648:tensor<[680, 1280], Float32, CPU>) -> (%649:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.2.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000000a0 prog.jump visual.blocks.2.mlp.__entry[offset:37]
        addr:0x000000000000a1 prog.kernel_launch(%648:tensor<[680, 1280], Float32, CPU>, %652:tensor<[680, 1280], Float32, CPU>) -> (%653:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000000a2 prog.free(%652:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000a3 prog.free(%648:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000a4 prog.ret
        addr:0x000000000000a5 prog.label[symbol:visual.blocks.2.attn.__entry]
        addr:0x000000000000a6 prog.kernel_launch(%633:tensor<[680, 1280], Float32, CPU>) -> (%634:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.2.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000000a7 prog.free(%633:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000a8 prog.kernel_launch(%634:tensor<[680, 3840], Float32, CPU>) -> (%634:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000000a9 prog.kernel_launch(%634:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%635:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000000aa prog.free(%634:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000ab prog.kernel_launch(%635:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%635:tensor<[3, 680, 16, 80], Float32, CPU>, %635:tensor<[3, 680, 16, 80], Float32, CPU>, %635:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000000ac prog.kernel_launch(%635:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%636:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.2.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000000ad prog.kernel_launch(%635:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%637:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.2.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000000ae prog.kernel_launch(%636:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%638:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000af prog.free(%636:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000b0 prog.kernel_launch(%637:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%639:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000b1 prog.free(%637:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000b2 prog.kernel_launch(%635:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%640:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000b3 prog.free(%635:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000b4 prog.kernel_launch(%638:tensor<[1, 16, 680, 80], Float32, CPU>, %639:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%641:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000000b5 prog.free(%639:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000b6 prog.free(%638:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000b7 prog.kernel_launch(%641:tensor<[1, 16, 680, 680], Float32, CPU>, %642:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%643:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000000b8 prog.free(%642:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000000b9 prog.free(%641:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000ba prog.kernel_launch(%643:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%644:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.2.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000000bb prog.free(%643:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000bc prog.kernel_launch(%644:tensor<[1, 16, 680, 680], Float32, CPU>, %640:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%645:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000000bd prog.free(%640:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000be prog.free(%644:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000bf prog.kernel_launch(%645:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%646:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000c0 prog.free(%645:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000c1 prog.kernel_launch(%646:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%646:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000000c2 prog.kernel_launch(%646:tensor<[680, 1280], Float32, CPU>) -> (%647:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.2.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000000c3 prog.free(%646:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000c4 prog.ret
        addr:0x000000000000c5 prog.label[symbol:visual.blocks.2.mlp.__entry]
        addr:0x000000000000c6 prog.kernel_launch(%649:tensor<[680, 1280], Float32, CPU>) -> (%650:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.2.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000000c7 prog.free(%649:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000c8 prog.kernel_launch(%650:tensor<[680, 5120], Float32, CPU>) -> (%651:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.2.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000000c9 prog.free(%650:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000000ca prog.kernel_launch(%651:tensor<[680, 5120], Float32, CPU>) -> (%652:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.2.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000000cb prog.free(%651:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000000cc prog.ret
        addr:0x000000000000cd prog.label[symbol:visual.blocks.3.__entry]
        addr:0x000000000000ce prog.kernel_launch(%653:tensor<[680, 1280], Float32, CPU>) -> (%654:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.3.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000000cf prog.jump visual.blocks.3.attn.__entry[offset:10]
        addr:0x000000000000d0 prog.kernel_launch(%653:tensor<[680, 1280], Float32, CPU>, %668:tensor<[680, 1280], Float32, CPU>) -> (%669:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000000d1 prog.free(%668:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000d2 prog.free(%653:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000d3 prog.kernel_launch(%669:tensor<[680, 1280], Float32, CPU>) -> (%670:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.3.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000000d4 prog.jump visual.blocks.3.mlp.__entry[offset:37]
        addr:0x000000000000d5 prog.kernel_launch(%669:tensor<[680, 1280], Float32, CPU>, %673:tensor<[680, 1280], Float32, CPU>) -> (%674:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000000d6 prog.free(%673:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000d7 prog.free(%669:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000d8 prog.ret
        addr:0x000000000000d9 prog.label[symbol:visual.blocks.3.attn.__entry]
        addr:0x000000000000da prog.kernel_launch(%654:tensor<[680, 1280], Float32, CPU>) -> (%655:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.3.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000000db prog.free(%654:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000dc prog.kernel_launch(%655:tensor<[680, 3840], Float32, CPU>) -> (%655:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000000dd prog.kernel_launch(%655:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%656:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000000de prog.free(%655:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000df prog.kernel_launch(%656:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%656:tensor<[3, 680, 16, 80], Float32, CPU>, %656:tensor<[3, 680, 16, 80], Float32, CPU>, %656:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000000e0 prog.kernel_launch(%656:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%657:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.3.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000000e1 prog.kernel_launch(%656:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%658:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.3.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000000e2 prog.kernel_launch(%657:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%659:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000e3 prog.free(%657:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000e4 prog.kernel_launch(%658:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%660:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000e5 prog.free(%658:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000e6 prog.kernel_launch(%656:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%661:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000e7 prog.free(%656:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000000e8 prog.kernel_launch(%659:tensor<[1, 16, 680, 80], Float32, CPU>, %660:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%662:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000000e9 prog.free(%660:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000ea prog.free(%659:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000eb prog.kernel_launch(%662:tensor<[1, 16, 680, 680], Float32, CPU>, %663:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%664:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000000ec prog.free(%663:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000000ed prog.free(%662:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000ee prog.kernel_launch(%664:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%665:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.3.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000000ef prog.free(%664:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000f0 prog.kernel_launch(%665:tensor<[1, 16, 680, 680], Float32, CPU>, %661:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%666:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000000f1 prog.free(%661:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000f2 prog.free(%665:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000000f3 prog.kernel_launch(%666:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%667:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000000f4 prog.free(%666:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000000f5 prog.kernel_launch(%667:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%667:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000000f6 prog.kernel_launch(%667:tensor<[680, 1280], Float32, CPU>) -> (%668:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.3.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000000f7 prog.free(%667:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000f8 prog.ret
        addr:0x000000000000f9 prog.label[symbol:visual.blocks.3.mlp.__entry]
        addr:0x000000000000fa prog.kernel_launch(%670:tensor<[680, 1280], Float32, CPU>) -> (%671:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.3.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000000fb prog.free(%670:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000000fc prog.kernel_launch(%671:tensor<[680, 5120], Float32, CPU>) -> (%672:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.3.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000000fd prog.free(%671:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000000fe prog.kernel_launch(%672:tensor<[680, 5120], Float32, CPU>) -> (%673:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.3.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000000ff prog.free(%672:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000100 prog.ret
        addr:0x00000000000101 prog.label[symbol:visual.blocks.4.__entry]
        addr:0x00000000000102 prog.kernel_launch(%674:tensor<[680, 1280], Float32, CPU>) -> (%675:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.4.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000103 prog.jump visual.blocks.4.attn.__entry[offset:10]
        addr:0x00000000000104 prog.kernel_launch(%674:tensor<[680, 1280], Float32, CPU>, %689:tensor<[680, 1280], Float32, CPU>) -> (%690:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000105 prog.free(%689:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000106 prog.free(%674:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000107 prog.kernel_launch(%690:tensor<[680, 1280], Float32, CPU>) -> (%691:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.4.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000108 prog.jump visual.blocks.4.mlp.__entry[offset:37]
        addr:0x00000000000109 prog.kernel_launch(%690:tensor<[680, 1280], Float32, CPU>, %694:tensor<[680, 1280], Float32, CPU>) -> (%695:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000010a prog.free(%694:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000010b prog.free(%690:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000010c prog.ret
        addr:0x0000000000010d prog.label[symbol:visual.blocks.4.attn.__entry]
        addr:0x0000000000010e prog.kernel_launch(%675:tensor<[680, 1280], Float32, CPU>) -> (%676:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.4.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000010f prog.free(%675:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000110 prog.kernel_launch(%676:tensor<[680, 3840], Float32, CPU>) -> (%676:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000111 prog.kernel_launch(%676:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%677:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000112 prog.free(%676:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000113 prog.kernel_launch(%677:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%677:tensor<[3, 680, 16, 80], Float32, CPU>, %677:tensor<[3, 680, 16, 80], Float32, CPU>, %677:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000114 prog.kernel_launch(%677:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%678:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.4.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000115 prog.kernel_launch(%677:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%679:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.4.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000116 prog.kernel_launch(%678:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%680:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000117 prog.free(%678:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000118 prog.kernel_launch(%679:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%681:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000119 prog.free(%679:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000011a prog.kernel_launch(%677:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%682:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000011b prog.free(%677:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000011c prog.kernel_launch(%680:tensor<[1, 16, 680, 80], Float32, CPU>, %681:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%683:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000011d prog.free(%681:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000011e prog.free(%680:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000011f prog.kernel_launch(%683:tensor<[1, 16, 680, 680], Float32, CPU>, %684:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%685:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000120 prog.free(%684:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000121 prog.free(%683:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000122 prog.kernel_launch(%685:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%686:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.4.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000123 prog.free(%685:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000124 prog.kernel_launch(%686:tensor<[1, 16, 680, 680], Float32, CPU>, %682:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%687:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000125 prog.free(%682:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000126 prog.free(%686:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000127 prog.kernel_launch(%687:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%688:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000128 prog.free(%687:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000129 prog.kernel_launch(%688:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%688:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000012a prog.kernel_launch(%688:tensor<[680, 1280], Float32, CPU>) -> (%689:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.4.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000012b prog.free(%688:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000012c prog.ret
        addr:0x0000000000012d prog.label[symbol:visual.blocks.4.mlp.__entry]
        addr:0x0000000000012e prog.kernel_launch(%691:tensor<[680, 1280], Float32, CPU>) -> (%692:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.4.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000012f prog.free(%691:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000130 prog.kernel_launch(%692:tensor<[680, 5120], Float32, CPU>) -> (%693:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.4.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000131 prog.free(%692:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000132 prog.kernel_launch(%693:tensor<[680, 5120], Float32, CPU>) -> (%694:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.4.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000133 prog.free(%693:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000134 prog.ret
        addr:0x00000000000135 prog.label[symbol:visual.blocks.5.__entry]
        addr:0x00000000000136 prog.kernel_launch(%695:tensor<[680, 1280], Float32, CPU>) -> (%696:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.5.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000137 prog.jump visual.blocks.5.attn.__entry[offset:10]
        addr:0x00000000000138 prog.kernel_launch(%695:tensor<[680, 1280], Float32, CPU>, %710:tensor<[680, 1280], Float32, CPU>) -> (%711:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000139 prog.free(%710:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000013a prog.free(%695:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000013b prog.kernel_launch(%711:tensor<[680, 1280], Float32, CPU>) -> (%712:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.5.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000013c prog.jump visual.blocks.5.mlp.__entry[offset:37]
        addr:0x0000000000013d prog.kernel_launch(%711:tensor<[680, 1280], Float32, CPU>, %715:tensor<[680, 1280], Float32, CPU>) -> (%716:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000013e prog.free(%715:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000013f prog.free(%711:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000140 prog.ret
        addr:0x00000000000141 prog.label[symbol:visual.blocks.5.attn.__entry]
        addr:0x00000000000142 prog.kernel_launch(%696:tensor<[680, 1280], Float32, CPU>) -> (%697:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.5.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000143 prog.free(%696:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000144 prog.kernel_launch(%697:tensor<[680, 3840], Float32, CPU>) -> (%697:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000145 prog.kernel_launch(%697:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%698:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000146 prog.free(%697:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000147 prog.kernel_launch(%698:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%698:tensor<[3, 680, 16, 80], Float32, CPU>, %698:tensor<[3, 680, 16, 80], Float32, CPU>, %698:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000148 prog.kernel_launch(%698:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%699:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.5.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000149 prog.kernel_launch(%698:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%700:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.5.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000014a prog.kernel_launch(%699:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%701:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000014b prog.free(%699:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000014c prog.kernel_launch(%700:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%702:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000014d prog.free(%700:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000014e prog.kernel_launch(%698:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%703:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000014f prog.free(%698:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000150 prog.kernel_launch(%701:tensor<[1, 16, 680, 80], Float32, CPU>, %702:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%704:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000151 prog.free(%702:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000152 prog.free(%701:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000153 prog.kernel_launch(%704:tensor<[1, 16, 680, 680], Float32, CPU>, %705:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%706:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000154 prog.free(%705:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000155 prog.free(%704:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000156 prog.kernel_launch(%706:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%707:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.5.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000157 prog.free(%706:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000158 prog.kernel_launch(%707:tensor<[1, 16, 680, 680], Float32, CPU>, %703:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%708:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000159 prog.free(%703:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000015a prog.free(%707:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000015b prog.kernel_launch(%708:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%709:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000015c prog.free(%708:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000015d prog.kernel_launch(%709:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%709:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000015e prog.kernel_launch(%709:tensor<[680, 1280], Float32, CPU>) -> (%710:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.5.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000015f prog.free(%709:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000160 prog.ret
        addr:0x00000000000161 prog.label[symbol:visual.blocks.5.mlp.__entry]
        addr:0x00000000000162 prog.kernel_launch(%712:tensor<[680, 1280], Float32, CPU>) -> (%713:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.5.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000163 prog.free(%712:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000164 prog.kernel_launch(%713:tensor<[680, 5120], Float32, CPU>) -> (%714:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.5.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000165 prog.free(%713:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000166 prog.kernel_launch(%714:tensor<[680, 5120], Float32, CPU>) -> (%715:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.5.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000167 prog.free(%714:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000168 prog.ret
        addr:0x00000000000169 prog.label[symbol:visual.blocks.6.__entry]
        addr:0x0000000000016a prog.kernel_launch(%716:tensor<[680, 1280], Float32, CPU>) -> (%717:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.6.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000016b prog.jump visual.blocks.6.attn.__entry[offset:10]
        addr:0x0000000000016c prog.kernel_launch(%716:tensor<[680, 1280], Float32, CPU>, %731:tensor<[680, 1280], Float32, CPU>) -> (%732:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000016d prog.free(%731:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000016e prog.free(%716:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000016f prog.kernel_launch(%732:tensor<[680, 1280], Float32, CPU>) -> (%733:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.6.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000170 prog.jump visual.blocks.6.mlp.__entry[offset:37]
        addr:0x00000000000171 prog.kernel_launch(%732:tensor<[680, 1280], Float32, CPU>, %736:tensor<[680, 1280], Float32, CPU>) -> (%737:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000172 prog.free(%736:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000173 prog.free(%732:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000174 prog.ret
        addr:0x00000000000175 prog.label[symbol:visual.blocks.6.attn.__entry]
        addr:0x00000000000176 prog.kernel_launch(%717:tensor<[680, 1280], Float32, CPU>) -> (%718:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.6.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000177 prog.free(%717:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000178 prog.kernel_launch(%718:tensor<[680, 3840], Float32, CPU>) -> (%718:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000179 prog.kernel_launch(%718:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%719:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000017a prog.free(%718:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000017b prog.kernel_launch(%719:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%719:tensor<[3, 680, 16, 80], Float32, CPU>, %719:tensor<[3, 680, 16, 80], Float32, CPU>, %719:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x0000000000017c prog.kernel_launch(%719:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%720:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.6.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000017d prog.kernel_launch(%719:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%721:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.6.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000017e prog.kernel_launch(%720:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%722:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000017f prog.free(%720:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000180 prog.kernel_launch(%721:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%723:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000181 prog.free(%721:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000182 prog.kernel_launch(%719:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%724:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000183 prog.free(%719:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000184 prog.kernel_launch(%722:tensor<[1, 16, 680, 80], Float32, CPU>, %723:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%725:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000185 prog.free(%723:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000186 prog.free(%722:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000187 prog.kernel_launch(%725:tensor<[1, 16, 680, 680], Float32, CPU>, %726:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%727:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000188 prog.free(%726:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000189 prog.free(%725:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000018a prog.kernel_launch(%727:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%728:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.6.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000018b prog.free(%727:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000018c prog.kernel_launch(%728:tensor<[1, 16, 680, 680], Float32, CPU>, %724:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%729:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x0000000000018d prog.free(%724:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000018e prog.free(%728:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000018f prog.kernel_launch(%729:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%730:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000190 prog.free(%729:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000191 prog.kernel_launch(%730:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%730:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000192 prog.kernel_launch(%730:tensor<[680, 1280], Float32, CPU>) -> (%731:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.6.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000193 prog.free(%730:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000194 prog.ret
        addr:0x00000000000195 prog.label[symbol:visual.blocks.6.mlp.__entry]
        addr:0x00000000000196 prog.kernel_launch(%733:tensor<[680, 1280], Float32, CPU>) -> (%734:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.6.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000197 prog.free(%733:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000198 prog.kernel_launch(%734:tensor<[680, 5120], Float32, CPU>) -> (%735:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.6.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000199 prog.free(%734:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000019a prog.kernel_launch(%735:tensor<[680, 5120], Float32, CPU>) -> (%736:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.6.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000019b prog.free(%735:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000019c prog.ret
        addr:0x0000000000019d prog.label[symbol:visual.blocks.7.__entry]
        addr:0x0000000000019e prog.kernel_launch(%737:tensor<[680, 1280], Float32, CPU>) -> (%738:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.7.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000019f prog.jump visual.blocks.7.attn.__entry[offset:10]
        addr:0x000000000001a0 prog.kernel_launch(%737:tensor<[680, 1280], Float32, CPU>, %752:tensor<[680, 1280], Float32, CPU>) -> (%753:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000001a1 prog.free(%752:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001a2 prog.free(%737:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001a3 prog.kernel_launch(%753:tensor<[680, 1280], Float32, CPU>) -> (%754:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.7.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001a4 prog.jump visual.blocks.7.mlp.__entry[offset:37]
        addr:0x000000000001a5 prog.kernel_launch(%753:tensor<[680, 1280], Float32, CPU>, %757:tensor<[680, 1280], Float32, CPU>) -> (%758:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000001a6 prog.free(%757:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001a7 prog.free(%753:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001a8 prog.ret
        addr:0x000000000001a9 prog.label[symbol:visual.blocks.7.attn.__entry]
        addr:0x000000000001aa prog.kernel_launch(%738:tensor<[680, 1280], Float32, CPU>) -> (%739:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.7.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001ab prog.free(%738:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001ac prog.kernel_launch(%739:tensor<[680, 3840], Float32, CPU>) -> (%739:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000001ad prog.kernel_launch(%739:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%740:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000001ae prog.free(%739:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001af prog.kernel_launch(%740:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%740:tensor<[3, 680, 16, 80], Float32, CPU>, %740:tensor<[3, 680, 16, 80], Float32, CPU>, %740:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000001b0 prog.kernel_launch(%740:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%741:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.7.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001b1 prog.kernel_launch(%740:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%742:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.7.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001b2 prog.kernel_launch(%741:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%743:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001b3 prog.free(%741:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001b4 prog.kernel_launch(%742:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%744:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001b5 prog.free(%742:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001b6 prog.kernel_launch(%740:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%745:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001b7 prog.free(%740:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001b8 prog.kernel_launch(%743:tensor<[1, 16, 680, 80], Float32, CPU>, %744:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%746:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000001b9 prog.free(%744:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001ba prog.free(%743:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001bb prog.kernel_launch(%746:tensor<[1, 16, 680, 680], Float32, CPU>, %747:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%748:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000001bc prog.free(%747:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000001bd prog.free(%746:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001be prog.kernel_launch(%748:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%749:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.7.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001bf prog.free(%748:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001c0 prog.kernel_launch(%749:tensor<[1, 16, 680, 680], Float32, CPU>, %745:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%750:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000001c1 prog.free(%745:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001c2 prog.free(%749:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001c3 prog.kernel_launch(%750:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%751:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001c4 prog.free(%750:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001c5 prog.kernel_launch(%751:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%751:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000001c6 prog.kernel_launch(%751:tensor<[680, 1280], Float32, CPU>) -> (%752:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.7.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001c7 prog.free(%751:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001c8 prog.ret
        addr:0x000000000001c9 prog.label[symbol:visual.blocks.7.mlp.__entry]
        addr:0x000000000001ca prog.kernel_launch(%754:tensor<[680, 1280], Float32, CPU>) -> (%755:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.7.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001cb prog.free(%754:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001cc prog.kernel_launch(%755:tensor<[680, 5120], Float32, CPU>) -> (%756:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.7.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001cd prog.free(%755:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000001ce prog.kernel_launch(%756:tensor<[680, 5120], Float32, CPU>) -> (%757:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.7.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001cf prog.free(%756:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000001d0 prog.ret
        addr:0x000000000001d1 prog.label[symbol:visual.blocks.8.__entry]
        addr:0x000000000001d2 prog.kernel_launch(%758:tensor<[680, 1280], Float32, CPU>) -> (%759:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.8.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001d3 prog.jump visual.blocks.8.attn.__entry[offset:10]
        addr:0x000000000001d4 prog.kernel_launch(%758:tensor<[680, 1280], Float32, CPU>, %773:tensor<[680, 1280], Float32, CPU>) -> (%774:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000001d5 prog.free(%773:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001d6 prog.free(%758:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001d7 prog.kernel_launch(%774:tensor<[680, 1280], Float32, CPU>) -> (%775:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.8.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001d8 prog.jump visual.blocks.8.mlp.__entry[offset:37]
        addr:0x000000000001d9 prog.kernel_launch(%774:tensor<[680, 1280], Float32, CPU>, %778:tensor<[680, 1280], Float32, CPU>) -> (%779:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000001da prog.free(%778:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001db prog.free(%774:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001dc prog.ret
        addr:0x000000000001dd prog.label[symbol:visual.blocks.8.attn.__entry]
        addr:0x000000000001de prog.kernel_launch(%759:tensor<[680, 1280], Float32, CPU>) -> (%760:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.8.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001df prog.free(%759:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001e0 prog.kernel_launch(%760:tensor<[680, 3840], Float32, CPU>) -> (%760:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000001e1 prog.kernel_launch(%760:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%761:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000001e2 prog.free(%760:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001e3 prog.kernel_launch(%761:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%761:tensor<[3, 680, 16, 80], Float32, CPU>, %761:tensor<[3, 680, 16, 80], Float32, CPU>, %761:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000001e4 prog.kernel_launch(%761:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%762:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.8.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001e5 prog.kernel_launch(%761:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%763:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.8.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001e6 prog.kernel_launch(%762:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%764:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001e7 prog.free(%762:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001e8 prog.kernel_launch(%763:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%765:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001e9 prog.free(%763:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001ea prog.kernel_launch(%761:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%766:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001eb prog.free(%761:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000001ec prog.kernel_launch(%764:tensor<[1, 16, 680, 80], Float32, CPU>, %765:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%767:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000001ed prog.free(%765:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001ee prog.free(%764:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001ef prog.kernel_launch(%767:tensor<[1, 16, 680, 680], Float32, CPU>, %768:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%769:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000001f0 prog.free(%768:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000001f1 prog.free(%767:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001f2 prog.kernel_launch(%769:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%770:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.8.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001f3 prog.free(%769:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001f4 prog.kernel_launch(%770:tensor<[1, 16, 680, 680], Float32, CPU>, %766:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%771:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000001f5 prog.free(%766:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001f6 prog.free(%770:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000001f7 prog.kernel_launch(%771:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%772:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000001f8 prog.free(%771:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000001f9 prog.kernel_launch(%772:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%772:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000001fa prog.kernel_launch(%772:tensor<[680, 1280], Float32, CPU>) -> (%773:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.8.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001fb prog.free(%772:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000001fc prog.ret
        addr:0x000000000001fd prog.label[symbol:visual.blocks.8.mlp.__entry]
        addr:0x000000000001fe prog.kernel_launch(%775:tensor<[680, 1280], Float32, CPU>) -> (%776:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.8.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001ff prog.free(%775:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000200 prog.kernel_launch(%776:tensor<[680, 5120], Float32, CPU>) -> (%777:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.8.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000201 prog.free(%776:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000202 prog.kernel_launch(%777:tensor<[680, 5120], Float32, CPU>) -> (%778:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.8.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000203 prog.free(%777:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000204 prog.ret
        addr:0x00000000000205 prog.label[symbol:visual.blocks.9.__entry]
        addr:0x00000000000206 prog.kernel_launch(%779:tensor<[680, 1280], Float32, CPU>) -> (%780:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.9.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000207 prog.jump visual.blocks.9.attn.__entry[offset:10]
        addr:0x00000000000208 prog.kernel_launch(%779:tensor<[680, 1280], Float32, CPU>, %794:tensor<[680, 1280], Float32, CPU>) -> (%795:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000209 prog.free(%794:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000020a prog.free(%779:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000020b prog.kernel_launch(%795:tensor<[680, 1280], Float32, CPU>) -> (%796:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.9.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000020c prog.jump visual.blocks.9.mlp.__entry[offset:37]
        addr:0x0000000000020d prog.kernel_launch(%795:tensor<[680, 1280], Float32, CPU>, %799:tensor<[680, 1280], Float32, CPU>) -> (%800:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000020e prog.free(%799:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000020f prog.free(%795:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000210 prog.ret
        addr:0x00000000000211 prog.label[symbol:visual.blocks.9.attn.__entry]
        addr:0x00000000000212 prog.kernel_launch(%780:tensor<[680, 1280], Float32, CPU>) -> (%781:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.9.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000213 prog.free(%780:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000214 prog.kernel_launch(%781:tensor<[680, 3840], Float32, CPU>) -> (%781:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000215 prog.kernel_launch(%781:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%782:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000216 prog.free(%781:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000217 prog.kernel_launch(%782:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%782:tensor<[3, 680, 16, 80], Float32, CPU>, %782:tensor<[3, 680, 16, 80], Float32, CPU>, %782:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000218 prog.kernel_launch(%782:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%783:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.9.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000219 prog.kernel_launch(%782:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%784:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.9.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000021a prog.kernel_launch(%783:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%785:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000021b prog.free(%783:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000021c prog.kernel_launch(%784:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%786:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000021d prog.free(%784:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000021e prog.kernel_launch(%782:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%787:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000021f prog.free(%782:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000220 prog.kernel_launch(%785:tensor<[1, 16, 680, 80], Float32, CPU>, %786:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%788:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000221 prog.free(%786:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000222 prog.free(%785:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000223 prog.kernel_launch(%788:tensor<[1, 16, 680, 680], Float32, CPU>, %789:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%790:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000224 prog.free(%789:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000225 prog.free(%788:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000226 prog.kernel_launch(%790:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%791:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.9.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000227 prog.free(%790:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000228 prog.kernel_launch(%791:tensor<[1, 16, 680, 680], Float32, CPU>, %787:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%792:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000229 prog.free(%787:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000022a prog.free(%791:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000022b prog.kernel_launch(%792:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%793:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000022c prog.free(%792:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000022d prog.kernel_launch(%793:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%793:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000022e prog.kernel_launch(%793:tensor<[680, 1280], Float32, CPU>) -> (%794:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.9.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000022f prog.free(%793:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000230 prog.ret
        addr:0x00000000000231 prog.label[symbol:visual.blocks.9.mlp.__entry]
        addr:0x00000000000232 prog.kernel_launch(%796:tensor<[680, 1280], Float32, CPU>) -> (%797:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.9.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000233 prog.free(%796:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000234 prog.kernel_launch(%797:tensor<[680, 5120], Float32, CPU>) -> (%798:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.9.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000235 prog.free(%797:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000236 prog.kernel_launch(%798:tensor<[680, 5120], Float32, CPU>) -> (%799:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.9.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000237 prog.free(%798:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000238 prog.ret
        addr:0x00000000000239 prog.label[symbol:visual.blocks.10.__entry]
        addr:0x0000000000023a prog.kernel_launch(%800:tensor<[680, 1280], Float32, CPU>) -> (%801:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.10.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000023b prog.jump visual.blocks.10.attn.__entry[offset:10]
        addr:0x0000000000023c prog.kernel_launch(%800:tensor<[680, 1280], Float32, CPU>, %815:tensor<[680, 1280], Float32, CPU>) -> (%816:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000023d prog.free(%815:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000023e prog.free(%800:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000023f prog.kernel_launch(%816:tensor<[680, 1280], Float32, CPU>) -> (%817:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.10.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000240 prog.jump visual.blocks.10.mlp.__entry[offset:37]
        addr:0x00000000000241 prog.kernel_launch(%816:tensor<[680, 1280], Float32, CPU>, %820:tensor<[680, 1280], Float32, CPU>) -> (%821:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000242 prog.free(%820:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000243 prog.free(%816:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000244 prog.ret
        addr:0x00000000000245 prog.label[symbol:visual.blocks.10.attn.__entry]
        addr:0x00000000000246 prog.kernel_launch(%801:tensor<[680, 1280], Float32, CPU>) -> (%802:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.10.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000247 prog.free(%801:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000248 prog.kernel_launch(%802:tensor<[680, 3840], Float32, CPU>) -> (%802:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000249 prog.kernel_launch(%802:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%803:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000024a prog.free(%802:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000024b prog.kernel_launch(%803:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%803:tensor<[3, 680, 16, 80], Float32, CPU>, %803:tensor<[3, 680, 16, 80], Float32, CPU>, %803:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x0000000000024c prog.kernel_launch(%803:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%804:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.10.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000024d prog.kernel_launch(%803:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%805:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.10.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000024e prog.kernel_launch(%804:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%806:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000024f prog.free(%804:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000250 prog.kernel_launch(%805:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%807:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000251 prog.free(%805:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000252 prog.kernel_launch(%803:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%808:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000253 prog.free(%803:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000254 prog.kernel_launch(%806:tensor<[1, 16, 680, 80], Float32, CPU>, %807:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%809:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000255 prog.free(%807:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000256 prog.free(%806:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000257 prog.kernel_launch(%809:tensor<[1, 16, 680, 680], Float32, CPU>, %810:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%811:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000258 prog.free(%810:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000259 prog.free(%809:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000025a prog.kernel_launch(%811:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%812:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.10.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000025b prog.free(%811:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000025c prog.kernel_launch(%812:tensor<[1, 16, 680, 680], Float32, CPU>, %808:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%813:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x0000000000025d prog.free(%808:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000025e prog.free(%812:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000025f prog.kernel_launch(%813:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%814:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000260 prog.free(%813:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000261 prog.kernel_launch(%814:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%814:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000262 prog.kernel_launch(%814:tensor<[680, 1280], Float32, CPU>) -> (%815:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.10.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000263 prog.free(%814:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000264 prog.ret
        addr:0x00000000000265 prog.label[symbol:visual.blocks.10.mlp.__entry]
        addr:0x00000000000266 prog.kernel_launch(%817:tensor<[680, 1280], Float32, CPU>) -> (%818:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.10.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000267 prog.free(%817:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000268 prog.kernel_launch(%818:tensor<[680, 5120], Float32, CPU>) -> (%819:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.10.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000269 prog.free(%818:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000026a prog.kernel_launch(%819:tensor<[680, 5120], Float32, CPU>) -> (%820:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.10.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000026b prog.free(%819:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000026c prog.ret
        addr:0x0000000000026d prog.label[symbol:visual.blocks.11.__entry]
        addr:0x0000000000026e prog.kernel_launch(%821:tensor<[680, 1280], Float32, CPU>) -> (%822:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.11.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000026f prog.jump visual.blocks.11.attn.__entry[offset:10]
        addr:0x00000000000270 prog.kernel_launch(%821:tensor<[680, 1280], Float32, CPU>, %836:tensor<[680, 1280], Float32, CPU>) -> (%837:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000271 prog.free(%836:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000272 prog.free(%821:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000273 prog.kernel_launch(%837:tensor<[680, 1280], Float32, CPU>) -> (%838:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.11.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000274 prog.jump visual.blocks.11.mlp.__entry[offset:37]
        addr:0x00000000000275 prog.kernel_launch(%837:tensor<[680, 1280], Float32, CPU>, %841:tensor<[680, 1280], Float32, CPU>) -> (%842:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000276 prog.free(%841:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000277 prog.free(%837:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000278 prog.ret
        addr:0x00000000000279 prog.label[symbol:visual.blocks.11.attn.__entry]
        addr:0x0000000000027a prog.kernel_launch(%822:tensor<[680, 1280], Float32, CPU>) -> (%823:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.11.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000027b prog.free(%822:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000027c prog.kernel_launch(%823:tensor<[680, 3840], Float32, CPU>) -> (%823:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x0000000000027d prog.kernel_launch(%823:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%824:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000027e prog.free(%823:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000027f prog.kernel_launch(%824:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%824:tensor<[3, 680, 16, 80], Float32, CPU>, %824:tensor<[3, 680, 16, 80], Float32, CPU>, %824:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000280 prog.kernel_launch(%824:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%825:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.11.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000281 prog.kernel_launch(%824:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%826:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.11.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000282 prog.kernel_launch(%825:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%827:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000283 prog.free(%825:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000284 prog.kernel_launch(%826:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%828:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000285 prog.free(%826:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000286 prog.kernel_launch(%824:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%829:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000287 prog.free(%824:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000288 prog.kernel_launch(%827:tensor<[1, 16, 680, 80], Float32, CPU>, %828:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%830:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000289 prog.free(%828:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000028a prog.free(%827:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000028b prog.kernel_launch(%830:tensor<[1, 16, 680, 680], Float32, CPU>, %831:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%832:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x0000000000028c prog.free(%831:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x0000000000028d prog.free(%830:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000028e prog.kernel_launch(%832:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%833:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.11.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000028f prog.free(%832:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000290 prog.kernel_launch(%833:tensor<[1, 16, 680, 680], Float32, CPU>, %829:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%834:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000291 prog.free(%829:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000292 prog.free(%833:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000293 prog.kernel_launch(%834:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%835:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000294 prog.free(%834:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000295 prog.kernel_launch(%835:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%835:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000296 prog.kernel_launch(%835:tensor<[680, 1280], Float32, CPU>) -> (%836:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.11.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000297 prog.free(%835:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000298 prog.ret
        addr:0x00000000000299 prog.label[symbol:visual.blocks.11.mlp.__entry]
        addr:0x0000000000029a prog.kernel_launch(%838:tensor<[680, 1280], Float32, CPU>) -> (%839:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.11.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000029b prog.free(%838:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000029c prog.kernel_launch(%839:tensor<[680, 5120], Float32, CPU>) -> (%840:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.11.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000029d prog.free(%839:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000029e prog.kernel_launch(%840:tensor<[680, 5120], Float32, CPU>) -> (%841:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.11.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000029f prog.free(%840:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000002a0 prog.ret
        addr:0x000000000002a1 prog.label[symbol:visual.blocks.12.__entry]
        addr:0x000000000002a2 prog.kernel_launch(%842:tensor<[680, 1280], Float32, CPU>) -> (%843:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.12.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000002a3 prog.jump visual.blocks.12.attn.__entry[offset:10]
        addr:0x000000000002a4 prog.kernel_launch(%842:tensor<[680, 1280], Float32, CPU>, %857:tensor<[680, 1280], Float32, CPU>) -> (%858:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000002a5 prog.free(%857:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002a6 prog.free(%842:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002a7 prog.kernel_launch(%858:tensor<[680, 1280], Float32, CPU>) -> (%859:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.12.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000002a8 prog.jump visual.blocks.12.mlp.__entry[offset:37]
        addr:0x000000000002a9 prog.kernel_launch(%858:tensor<[680, 1280], Float32, CPU>, %862:tensor<[680, 1280], Float32, CPU>) -> (%863:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000002aa prog.free(%862:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002ab prog.free(%858:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002ac prog.ret
        addr:0x000000000002ad prog.label[symbol:visual.blocks.12.attn.__entry]
        addr:0x000000000002ae prog.kernel_launch(%843:tensor<[680, 1280], Float32, CPU>) -> (%844:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.12.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000002af prog.free(%843:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002b0 prog.kernel_launch(%844:tensor<[680, 3840], Float32, CPU>) -> (%844:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000002b1 prog.kernel_launch(%844:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%845:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000002b2 prog.free(%844:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002b3 prog.kernel_launch(%845:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%845:tensor<[3, 680, 16, 80], Float32, CPU>, %845:tensor<[3, 680, 16, 80], Float32, CPU>, %845:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000002b4 prog.kernel_launch(%845:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%846:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.12.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000002b5 prog.kernel_launch(%845:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%847:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.12.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000002b6 prog.kernel_launch(%846:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%848:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002b7 prog.free(%846:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002b8 prog.kernel_launch(%847:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%849:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002b9 prog.free(%847:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002ba prog.kernel_launch(%845:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%850:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002bb prog.free(%845:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002bc prog.kernel_launch(%848:tensor<[1, 16, 680, 80], Float32, CPU>, %849:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%851:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000002bd prog.free(%849:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002be prog.free(%848:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002bf prog.kernel_launch(%851:tensor<[1, 16, 680, 680], Float32, CPU>, %852:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%853:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000002c0 prog.free(%852:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000002c1 prog.free(%851:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002c2 prog.kernel_launch(%853:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%854:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.12.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000002c3 prog.free(%853:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002c4 prog.kernel_launch(%854:tensor<[1, 16, 680, 680], Float32, CPU>, %850:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%855:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000002c5 prog.free(%850:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002c6 prog.free(%854:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002c7 prog.kernel_launch(%855:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%856:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002c8 prog.free(%855:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002c9 prog.kernel_launch(%856:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%856:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000002ca prog.kernel_launch(%856:tensor<[680, 1280], Float32, CPU>) -> (%857:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.12.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000002cb prog.free(%856:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002cc prog.ret
        addr:0x000000000002cd prog.label[symbol:visual.blocks.12.mlp.__entry]
        addr:0x000000000002ce prog.kernel_launch(%859:tensor<[680, 1280], Float32, CPU>) -> (%860:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.12.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000002cf prog.free(%859:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002d0 prog.kernel_launch(%860:tensor<[680, 5120], Float32, CPU>) -> (%861:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.12.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000002d1 prog.free(%860:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000002d2 prog.kernel_launch(%861:tensor<[680, 5120], Float32, CPU>) -> (%862:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.12.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000002d3 prog.free(%861:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000002d4 prog.ret
        addr:0x000000000002d5 prog.label[symbol:visual.blocks.13.__entry]
        addr:0x000000000002d6 prog.kernel_launch(%863:tensor<[680, 1280], Float32, CPU>) -> (%864:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.13.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000002d7 prog.jump visual.blocks.13.attn.__entry[offset:10]
        addr:0x000000000002d8 prog.kernel_launch(%863:tensor<[680, 1280], Float32, CPU>, %878:tensor<[680, 1280], Float32, CPU>) -> (%879:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000002d9 prog.free(%878:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002da prog.free(%863:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002db prog.kernel_launch(%879:tensor<[680, 1280], Float32, CPU>) -> (%880:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.13.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000002dc prog.jump visual.blocks.13.mlp.__entry[offset:37]
        addr:0x000000000002dd prog.kernel_launch(%879:tensor<[680, 1280], Float32, CPU>, %883:tensor<[680, 1280], Float32, CPU>) -> (%884:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000002de prog.free(%883:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002df prog.free(%879:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002e0 prog.ret
        addr:0x000000000002e1 prog.label[symbol:visual.blocks.13.attn.__entry]
        addr:0x000000000002e2 prog.kernel_launch(%864:tensor<[680, 1280], Float32, CPU>) -> (%865:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.13.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000002e3 prog.free(%864:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000002e4 prog.kernel_launch(%865:tensor<[680, 3840], Float32, CPU>) -> (%865:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000002e5 prog.kernel_launch(%865:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%866:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000002e6 prog.free(%865:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002e7 prog.kernel_launch(%866:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%866:tensor<[3, 680, 16, 80], Float32, CPU>, %866:tensor<[3, 680, 16, 80], Float32, CPU>, %866:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000002e8 prog.kernel_launch(%866:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%867:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.13.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000002e9 prog.kernel_launch(%866:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%868:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.13.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000002ea prog.kernel_launch(%867:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%869:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002eb prog.free(%867:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002ec prog.kernel_launch(%868:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%870:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002ed prog.free(%868:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002ee prog.kernel_launch(%866:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%871:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002ef prog.free(%866:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000002f0 prog.kernel_launch(%869:tensor<[1, 16, 680, 80], Float32, CPU>, %870:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%872:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000002f1 prog.free(%870:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002f2 prog.free(%869:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002f3 prog.kernel_launch(%872:tensor<[1, 16, 680, 680], Float32, CPU>, %873:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%874:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000002f4 prog.free(%873:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000002f5 prog.free(%872:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002f6 prog.kernel_launch(%874:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%875:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.13.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000002f7 prog.free(%874:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002f8 prog.kernel_launch(%875:tensor<[1, 16, 680, 680], Float32, CPU>, %871:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%876:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000002f9 prog.free(%871:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002fa prog.free(%875:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000002fb prog.kernel_launch(%876:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%877:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000002fc prog.free(%876:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000002fd prog.kernel_launch(%877:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%877:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000002fe prog.kernel_launch(%877:tensor<[680, 1280], Float32, CPU>) -> (%878:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.13.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000002ff prog.free(%877:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000300 prog.ret
        addr:0x00000000000301 prog.label[symbol:visual.blocks.13.mlp.__entry]
        addr:0x00000000000302 prog.kernel_launch(%880:tensor<[680, 1280], Float32, CPU>) -> (%881:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.13.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000303 prog.free(%880:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000304 prog.kernel_launch(%881:tensor<[680, 5120], Float32, CPU>) -> (%882:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.13.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000305 prog.free(%881:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000306 prog.kernel_launch(%882:tensor<[680, 5120], Float32, CPU>) -> (%883:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.13.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000307 prog.free(%882:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000308 prog.ret
        addr:0x00000000000309 prog.label[symbol:visual.blocks.14.__entry]
        addr:0x0000000000030a prog.kernel_launch(%884:tensor<[680, 1280], Float32, CPU>) -> (%885:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.14.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000030b prog.jump visual.blocks.14.attn.__entry[offset:10]
        addr:0x0000000000030c prog.kernel_launch(%884:tensor<[680, 1280], Float32, CPU>, %899:tensor<[680, 1280], Float32, CPU>) -> (%900:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000030d prog.free(%899:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000030e prog.free(%884:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000030f prog.kernel_launch(%900:tensor<[680, 1280], Float32, CPU>) -> (%901:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.14.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000310 prog.jump visual.blocks.14.mlp.__entry[offset:37]
        addr:0x00000000000311 prog.kernel_launch(%900:tensor<[680, 1280], Float32, CPU>, %904:tensor<[680, 1280], Float32, CPU>) -> (%905:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000312 prog.free(%904:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000313 prog.free(%900:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000314 prog.ret
        addr:0x00000000000315 prog.label[symbol:visual.blocks.14.attn.__entry]
        addr:0x00000000000316 prog.kernel_launch(%885:tensor<[680, 1280], Float32, CPU>) -> (%886:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.14.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000317 prog.free(%885:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000318 prog.kernel_launch(%886:tensor<[680, 3840], Float32, CPU>) -> (%886:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000319 prog.kernel_launch(%886:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%887:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000031a prog.free(%886:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000031b prog.kernel_launch(%887:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%887:tensor<[3, 680, 16, 80], Float32, CPU>, %887:tensor<[3, 680, 16, 80], Float32, CPU>, %887:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x0000000000031c prog.kernel_launch(%887:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%888:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.14.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000031d prog.kernel_launch(%887:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%889:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.14.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000031e prog.kernel_launch(%888:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%890:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000031f prog.free(%888:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000320 prog.kernel_launch(%889:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%891:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000321 prog.free(%889:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000322 prog.kernel_launch(%887:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%892:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000323 prog.free(%887:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000324 prog.kernel_launch(%890:tensor<[1, 16, 680, 80], Float32, CPU>, %891:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%893:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000325 prog.free(%891:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000326 prog.free(%890:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000327 prog.kernel_launch(%893:tensor<[1, 16, 680, 680], Float32, CPU>, %894:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%895:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000328 prog.free(%894:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000329 prog.free(%893:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000032a prog.kernel_launch(%895:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%896:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.14.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000032b prog.free(%895:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000032c prog.kernel_launch(%896:tensor<[1, 16, 680, 680], Float32, CPU>, %892:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%897:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x0000000000032d prog.free(%892:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000032e prog.free(%896:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000032f prog.kernel_launch(%897:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%898:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000330 prog.free(%897:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000331 prog.kernel_launch(%898:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%898:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000332 prog.kernel_launch(%898:tensor<[680, 1280], Float32, CPU>) -> (%899:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.14.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000333 prog.free(%898:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000334 prog.ret
        addr:0x00000000000335 prog.label[symbol:visual.blocks.14.mlp.__entry]
        addr:0x00000000000336 prog.kernel_launch(%901:tensor<[680, 1280], Float32, CPU>) -> (%902:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.14.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000337 prog.free(%901:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000338 prog.kernel_launch(%902:tensor<[680, 5120], Float32, CPU>) -> (%903:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.14.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000339 prog.free(%902:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000033a prog.kernel_launch(%903:tensor<[680, 5120], Float32, CPU>) -> (%904:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.14.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000033b prog.free(%903:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000033c prog.ret
        addr:0x0000000000033d prog.label[symbol:visual.blocks.15.__entry]
        addr:0x0000000000033e prog.kernel_launch(%905:tensor<[680, 1280], Float32, CPU>) -> (%906:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.15.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000033f prog.jump visual.blocks.15.attn.__entry[offset:10]
        addr:0x00000000000340 prog.kernel_launch(%905:tensor<[680, 1280], Float32, CPU>, %920:tensor<[680, 1280], Float32, CPU>) -> (%921:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000341 prog.free(%920:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000342 prog.free(%905:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000343 prog.kernel_launch(%921:tensor<[680, 1280], Float32, CPU>) -> (%922:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.15.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000344 prog.jump visual.blocks.15.mlp.__entry[offset:37]
        addr:0x00000000000345 prog.kernel_launch(%921:tensor<[680, 1280], Float32, CPU>, %925:tensor<[680, 1280], Float32, CPU>) -> (%926:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000346 prog.free(%925:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000347 prog.free(%921:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000348 prog.ret
        addr:0x00000000000349 prog.label[symbol:visual.blocks.15.attn.__entry]
        addr:0x0000000000034a prog.kernel_launch(%906:tensor<[680, 1280], Float32, CPU>) -> (%907:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.15.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000034b prog.free(%906:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000034c prog.kernel_launch(%907:tensor<[680, 3840], Float32, CPU>) -> (%907:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x0000000000034d prog.kernel_launch(%907:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%908:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000034e prog.free(%907:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000034f prog.kernel_launch(%908:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%908:tensor<[3, 680, 16, 80], Float32, CPU>, %908:tensor<[3, 680, 16, 80], Float32, CPU>, %908:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000350 prog.kernel_launch(%908:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%909:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.15.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000351 prog.kernel_launch(%908:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%910:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.15.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000352 prog.kernel_launch(%909:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%911:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000353 prog.free(%909:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000354 prog.kernel_launch(%910:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%912:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000355 prog.free(%910:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000356 prog.kernel_launch(%908:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%913:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000357 prog.free(%908:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000358 prog.kernel_launch(%911:tensor<[1, 16, 680, 80], Float32, CPU>, %912:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%914:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000359 prog.free(%912:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000035a prog.free(%911:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000035b prog.kernel_launch(%914:tensor<[1, 16, 680, 680], Float32, CPU>, %915:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%916:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x0000000000035c prog.free(%915:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x0000000000035d prog.free(%914:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000035e prog.kernel_launch(%916:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%917:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.15.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000035f prog.free(%916:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000360 prog.kernel_launch(%917:tensor<[1, 16, 680, 680], Float32, CPU>, %913:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%918:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000361 prog.free(%913:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000362 prog.free(%917:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000363 prog.kernel_launch(%918:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%919:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000364 prog.free(%918:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000365 prog.kernel_launch(%919:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%919:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000366 prog.kernel_launch(%919:tensor<[680, 1280], Float32, CPU>) -> (%920:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.15.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000367 prog.free(%919:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000368 prog.ret
        addr:0x00000000000369 prog.label[symbol:visual.blocks.15.mlp.__entry]
        addr:0x0000000000036a prog.kernel_launch(%922:tensor<[680, 1280], Float32, CPU>) -> (%923:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.15.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000036b prog.free(%922:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000036c prog.kernel_launch(%923:tensor<[680, 5120], Float32, CPU>) -> (%924:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.15.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000036d prog.free(%923:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000036e prog.kernel_launch(%924:tensor<[680, 5120], Float32, CPU>) -> (%925:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.15.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000036f prog.free(%924:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000370 prog.ret
        addr:0x00000000000371 prog.label[symbol:visual.blocks.16.__entry]
        addr:0x00000000000372 prog.kernel_launch(%926:tensor<[680, 1280], Float32, CPU>) -> (%927:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.16.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000373 prog.jump visual.blocks.16.attn.__entry[offset:10]
        addr:0x00000000000374 prog.kernel_launch(%926:tensor<[680, 1280], Float32, CPU>, %941:tensor<[680, 1280], Float32, CPU>) -> (%942:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000375 prog.free(%941:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000376 prog.free(%926:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000377 prog.kernel_launch(%942:tensor<[680, 1280], Float32, CPU>) -> (%943:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.16.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000378 prog.jump visual.blocks.16.mlp.__entry[offset:37]
        addr:0x00000000000379 prog.kernel_launch(%942:tensor<[680, 1280], Float32, CPU>, %946:tensor<[680, 1280], Float32, CPU>) -> (%947:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000037a prog.free(%946:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000037b prog.free(%942:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000037c prog.ret
        addr:0x0000000000037d prog.label[symbol:visual.blocks.16.attn.__entry]
        addr:0x0000000000037e prog.kernel_launch(%927:tensor<[680, 1280], Float32, CPU>) -> (%928:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.16.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000037f prog.free(%927:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000380 prog.kernel_launch(%928:tensor<[680, 3840], Float32, CPU>) -> (%928:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000381 prog.kernel_launch(%928:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%929:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000382 prog.free(%928:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000383 prog.kernel_launch(%929:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%929:tensor<[3, 680, 16, 80], Float32, CPU>, %929:tensor<[3, 680, 16, 80], Float32, CPU>, %929:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000384 prog.kernel_launch(%929:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%930:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.16.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000385 prog.kernel_launch(%929:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%931:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.16.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000386 prog.kernel_launch(%930:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%932:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000387 prog.free(%930:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000388 prog.kernel_launch(%931:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%933:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000389 prog.free(%931:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000038a prog.kernel_launch(%929:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%934:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000038b prog.free(%929:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000038c prog.kernel_launch(%932:tensor<[1, 16, 680, 80], Float32, CPU>, %933:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%935:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000038d prog.free(%933:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000038e prog.free(%932:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000038f prog.kernel_launch(%935:tensor<[1, 16, 680, 680], Float32, CPU>, %936:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%937:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000390 prog.free(%936:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000391 prog.free(%935:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000392 prog.kernel_launch(%937:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%938:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.16.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000393 prog.free(%937:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000394 prog.kernel_launch(%938:tensor<[1, 16, 680, 680], Float32, CPU>, %934:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%939:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000395 prog.free(%934:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000396 prog.free(%938:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000397 prog.kernel_launch(%939:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%940:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000398 prog.free(%939:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000399 prog.kernel_launch(%940:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%940:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000039a prog.kernel_launch(%940:tensor<[680, 1280], Float32, CPU>) -> (%941:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.16.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000039b prog.free(%940:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000039c prog.ret
        addr:0x0000000000039d prog.label[symbol:visual.blocks.16.mlp.__entry]
        addr:0x0000000000039e prog.kernel_launch(%943:tensor<[680, 1280], Float32, CPU>) -> (%944:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.16.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000039f prog.free(%943:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003a0 prog.kernel_launch(%944:tensor<[680, 5120], Float32, CPU>) -> (%945:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.16.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000003a1 prog.free(%944:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000003a2 prog.kernel_launch(%945:tensor<[680, 5120], Float32, CPU>) -> (%946:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.16.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000003a3 prog.free(%945:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000003a4 prog.ret
        addr:0x000000000003a5 prog.label[symbol:visual.blocks.17.__entry]
        addr:0x000000000003a6 prog.kernel_launch(%947:tensor<[680, 1280], Float32, CPU>) -> (%948:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.17.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000003a7 prog.jump visual.blocks.17.attn.__entry[offset:10]
        addr:0x000000000003a8 prog.kernel_launch(%947:tensor<[680, 1280], Float32, CPU>, %962:tensor<[680, 1280], Float32, CPU>) -> (%963:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000003a9 prog.free(%962:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003aa prog.free(%947:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003ab prog.kernel_launch(%963:tensor<[680, 1280], Float32, CPU>) -> (%964:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.17.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000003ac prog.jump visual.blocks.17.mlp.__entry[offset:37]
        addr:0x000000000003ad prog.kernel_launch(%963:tensor<[680, 1280], Float32, CPU>, %967:tensor<[680, 1280], Float32, CPU>) -> (%968:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000003ae prog.free(%967:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003af prog.free(%963:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003b0 prog.ret
        addr:0x000000000003b1 prog.label[symbol:visual.blocks.17.attn.__entry]
        addr:0x000000000003b2 prog.kernel_launch(%948:tensor<[680, 1280], Float32, CPU>) -> (%949:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.17.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000003b3 prog.free(%948:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003b4 prog.kernel_launch(%949:tensor<[680, 3840], Float32, CPU>) -> (%949:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000003b5 prog.kernel_launch(%949:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%950:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000003b6 prog.free(%949:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003b7 prog.kernel_launch(%950:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%950:tensor<[3, 680, 16, 80], Float32, CPU>, %950:tensor<[3, 680, 16, 80], Float32, CPU>, %950:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000003b8 prog.kernel_launch(%950:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%951:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.17.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000003b9 prog.kernel_launch(%950:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%952:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.17.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000003ba prog.kernel_launch(%951:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%953:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003bb prog.free(%951:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003bc prog.kernel_launch(%952:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%954:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003bd prog.free(%952:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003be prog.kernel_launch(%950:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%955:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003bf prog.free(%950:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003c0 prog.kernel_launch(%953:tensor<[1, 16, 680, 80], Float32, CPU>, %954:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%956:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000003c1 prog.free(%954:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003c2 prog.free(%953:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003c3 prog.kernel_launch(%956:tensor<[1, 16, 680, 680], Float32, CPU>, %957:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%958:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000003c4 prog.free(%957:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000003c5 prog.free(%956:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003c6 prog.kernel_launch(%958:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%959:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.17.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000003c7 prog.free(%958:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003c8 prog.kernel_launch(%959:tensor<[1, 16, 680, 680], Float32, CPU>, %955:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%960:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000003c9 prog.free(%955:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003ca prog.free(%959:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003cb prog.kernel_launch(%960:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%961:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003cc prog.free(%960:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003cd prog.kernel_launch(%961:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%961:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000003ce prog.kernel_launch(%961:tensor<[680, 1280], Float32, CPU>) -> (%962:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.17.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000003cf prog.free(%961:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003d0 prog.ret
        addr:0x000000000003d1 prog.label[symbol:visual.blocks.17.mlp.__entry]
        addr:0x000000000003d2 prog.kernel_launch(%964:tensor<[680, 1280], Float32, CPU>) -> (%965:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.17.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000003d3 prog.free(%964:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003d4 prog.kernel_launch(%965:tensor<[680, 5120], Float32, CPU>) -> (%966:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.17.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000003d5 prog.free(%965:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000003d6 prog.kernel_launch(%966:tensor<[680, 5120], Float32, CPU>) -> (%967:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.17.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000003d7 prog.free(%966:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000003d8 prog.ret
        addr:0x000000000003d9 prog.label[symbol:visual.blocks.18.__entry]
        addr:0x000000000003da prog.kernel_launch(%968:tensor<[680, 1280], Float32, CPU>) -> (%969:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.18.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000003db prog.jump visual.blocks.18.attn.__entry[offset:10]
        addr:0x000000000003dc prog.kernel_launch(%968:tensor<[680, 1280], Float32, CPU>, %983:tensor<[680, 1280], Float32, CPU>) -> (%984:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000003dd prog.free(%983:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003de prog.free(%968:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003df prog.kernel_launch(%984:tensor<[680, 1280], Float32, CPU>) -> (%985:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.18.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000003e0 prog.jump visual.blocks.18.mlp.__entry[offset:37]
        addr:0x000000000003e1 prog.kernel_launch(%984:tensor<[680, 1280], Float32, CPU>, %988:tensor<[680, 1280], Float32, CPU>) -> (%989:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000003e2 prog.free(%988:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003e3 prog.free(%984:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003e4 prog.ret
        addr:0x000000000003e5 prog.label[symbol:visual.blocks.18.attn.__entry]
        addr:0x000000000003e6 prog.kernel_launch(%969:tensor<[680, 1280], Float32, CPU>) -> (%970:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.18.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000003e7 prog.free(%969:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000003e8 prog.kernel_launch(%970:tensor<[680, 3840], Float32, CPU>) -> (%970:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000003e9 prog.kernel_launch(%970:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%971:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000003ea prog.free(%970:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003eb prog.kernel_launch(%971:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%971:tensor<[3, 680, 16, 80], Float32, CPU>, %971:tensor<[3, 680, 16, 80], Float32, CPU>, %971:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000003ec prog.kernel_launch(%971:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%972:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.18.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000003ed prog.kernel_launch(%971:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%973:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.18.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000003ee prog.kernel_launch(%972:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%974:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003ef prog.free(%972:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003f0 prog.kernel_launch(%973:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%975:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003f1 prog.free(%973:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003f2 prog.kernel_launch(%971:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%976:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000003f3 prog.free(%971:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000003f4 prog.kernel_launch(%974:tensor<[1, 16, 680, 80], Float32, CPU>, %975:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%977:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000003f5 prog.free(%975:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003f6 prog.free(%974:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003f7 prog.kernel_launch(%977:tensor<[1, 16, 680, 680], Float32, CPU>, %978:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%979:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000003f8 prog.free(%978:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000003f9 prog.free(%977:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003fa prog.kernel_launch(%979:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%980:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.18.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000003fb prog.free(%979:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003fc prog.kernel_launch(%980:tensor<[1, 16, 680, 680], Float32, CPU>, %976:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%981:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000003fd prog.free(%976:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000003fe prog.free(%980:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000003ff prog.kernel_launch(%981:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%982:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000400 prog.free(%981:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000401 prog.kernel_launch(%982:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%982:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000402 prog.kernel_launch(%982:tensor<[680, 1280], Float32, CPU>) -> (%983:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.18.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000403 prog.free(%982:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000404 prog.ret
        addr:0x00000000000405 prog.label[symbol:visual.blocks.18.mlp.__entry]
        addr:0x00000000000406 prog.kernel_launch(%985:tensor<[680, 1280], Float32, CPU>) -> (%986:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.18.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000407 prog.free(%985:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000408 prog.kernel_launch(%986:tensor<[680, 5120], Float32, CPU>) -> (%987:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.18.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000409 prog.free(%986:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000040a prog.kernel_launch(%987:tensor<[680, 5120], Float32, CPU>) -> (%988:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.18.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000040b prog.free(%987:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000040c prog.ret
        addr:0x0000000000040d prog.label[symbol:visual.blocks.19.__entry]
        addr:0x0000000000040e prog.kernel_launch(%989:tensor<[680, 1280], Float32, CPU>) -> (%990:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.19.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000040f prog.jump visual.blocks.19.attn.__entry[offset:10]
        addr:0x00000000000410 prog.kernel_launch(%989:tensor<[680, 1280], Float32, CPU>, %1004:tensor<[680, 1280], Float32, CPU>) -> (%1005:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000411 prog.free(%1004:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000412 prog.free(%989:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000413 prog.kernel_launch(%1005:tensor<[680, 1280], Float32, CPU>) -> (%1006:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.19.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000414 prog.jump visual.blocks.19.mlp.__entry[offset:37]
        addr:0x00000000000415 prog.kernel_launch(%1005:tensor<[680, 1280], Float32, CPU>, %1009:tensor<[680, 1280], Float32, CPU>) -> (%1010:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000416 prog.free(%1009:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000417 prog.free(%1005:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000418 prog.ret
        addr:0x00000000000419 prog.label[symbol:visual.blocks.19.attn.__entry]
        addr:0x0000000000041a prog.kernel_launch(%990:tensor<[680, 1280], Float32, CPU>) -> (%991:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.19.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000041b prog.free(%990:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000041c prog.kernel_launch(%991:tensor<[680, 3840], Float32, CPU>) -> (%991:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x0000000000041d prog.kernel_launch(%991:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%992:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000041e prog.free(%991:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000041f prog.kernel_launch(%992:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%992:tensor<[3, 680, 16, 80], Float32, CPU>, %992:tensor<[3, 680, 16, 80], Float32, CPU>, %992:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000420 prog.kernel_launch(%992:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%993:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.19.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000421 prog.kernel_launch(%992:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%994:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.19.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000422 prog.kernel_launch(%993:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%995:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000423 prog.free(%993:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000424 prog.kernel_launch(%994:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%996:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000425 prog.free(%994:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000426 prog.kernel_launch(%992:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%997:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000427 prog.free(%992:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000428 prog.kernel_launch(%995:tensor<[1, 16, 680, 80], Float32, CPU>, %996:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%998:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000429 prog.free(%996:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000042a prog.free(%995:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000042b prog.kernel_launch(%998:tensor<[1, 16, 680, 680], Float32, CPU>, %999:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1000:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x0000000000042c prog.free(%999:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x0000000000042d prog.free(%998:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000042e prog.kernel_launch(%1000:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1001:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.19.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000042f prog.free(%1000:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000430 prog.kernel_launch(%1001:tensor<[1, 16, 680, 680], Float32, CPU>, %997:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1002:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000431 prog.free(%997:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000432 prog.free(%1001:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000433 prog.kernel_launch(%1002:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1003:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000434 prog.free(%1002:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000435 prog.kernel_launch(%1003:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1003:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000436 prog.kernel_launch(%1003:tensor<[680, 1280], Float32, CPU>) -> (%1004:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.19.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000437 prog.free(%1003:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000438 prog.ret
        addr:0x00000000000439 prog.label[symbol:visual.blocks.19.mlp.__entry]
        addr:0x0000000000043a prog.kernel_launch(%1006:tensor<[680, 1280], Float32, CPU>) -> (%1007:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.19.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000043b prog.free(%1006:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000043c prog.kernel_launch(%1007:tensor<[680, 5120], Float32, CPU>) -> (%1008:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.19.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000043d prog.free(%1007:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000043e prog.kernel_launch(%1008:tensor<[680, 5120], Float32, CPU>) -> (%1009:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.19.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000043f prog.free(%1008:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000440 prog.ret
        addr:0x00000000000441 prog.label[symbol:visual.blocks.20.__entry]
        addr:0x00000000000442 prog.kernel_launch(%1010:tensor<[680, 1280], Float32, CPU>) -> (%1011:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.20.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000443 prog.jump visual.blocks.20.attn.__entry[offset:10]
        addr:0x00000000000444 prog.kernel_launch(%1010:tensor<[680, 1280], Float32, CPU>, %1025:tensor<[680, 1280], Float32, CPU>) -> (%1026:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000445 prog.free(%1025:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000446 prog.free(%1010:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000447 prog.kernel_launch(%1026:tensor<[680, 1280], Float32, CPU>) -> (%1027:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.20.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000448 prog.jump visual.blocks.20.mlp.__entry[offset:37]
        addr:0x00000000000449 prog.kernel_launch(%1026:tensor<[680, 1280], Float32, CPU>, %1030:tensor<[680, 1280], Float32, CPU>) -> (%1031:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000044a prog.free(%1030:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000044b prog.free(%1026:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000044c prog.ret
        addr:0x0000000000044d prog.label[symbol:visual.blocks.20.attn.__entry]
        addr:0x0000000000044e prog.kernel_launch(%1011:tensor<[680, 1280], Float32, CPU>) -> (%1012:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.20.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000044f prog.free(%1011:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000450 prog.kernel_launch(%1012:tensor<[680, 3840], Float32, CPU>) -> (%1012:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000451 prog.kernel_launch(%1012:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1013:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000452 prog.free(%1012:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000453 prog.kernel_launch(%1013:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1013:tensor<[3, 680, 16, 80], Float32, CPU>, %1013:tensor<[3, 680, 16, 80], Float32, CPU>, %1013:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000454 prog.kernel_launch(%1013:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1014:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.20.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000455 prog.kernel_launch(%1013:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1015:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.20.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000456 prog.kernel_launch(%1014:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1016:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000457 prog.free(%1014:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000458 prog.kernel_launch(%1015:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1017:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000459 prog.free(%1015:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000045a prog.kernel_launch(%1013:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1018:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000045b prog.free(%1013:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000045c prog.kernel_launch(%1016:tensor<[1, 16, 680, 80], Float32, CPU>, %1017:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1019:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000045d prog.free(%1017:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000045e prog.free(%1016:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000045f prog.kernel_launch(%1019:tensor<[1, 16, 680, 680], Float32, CPU>, %1020:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1021:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000460 prog.free(%1020:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000461 prog.free(%1019:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000462 prog.kernel_launch(%1021:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1022:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.20.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000463 prog.free(%1021:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000464 prog.kernel_launch(%1022:tensor<[1, 16, 680, 680], Float32, CPU>, %1018:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1023:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000465 prog.free(%1018:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000466 prog.free(%1022:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000467 prog.kernel_launch(%1023:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1024:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000468 prog.free(%1023:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000469 prog.kernel_launch(%1024:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1024:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000046a prog.kernel_launch(%1024:tensor<[680, 1280], Float32, CPU>) -> (%1025:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.20.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000046b prog.free(%1024:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000046c prog.ret
        addr:0x0000000000046d prog.label[symbol:visual.blocks.20.mlp.__entry]
        addr:0x0000000000046e prog.kernel_launch(%1027:tensor<[680, 1280], Float32, CPU>) -> (%1028:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.20.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000046f prog.free(%1027:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000470 prog.kernel_launch(%1028:tensor<[680, 5120], Float32, CPU>) -> (%1029:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.20.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000471 prog.free(%1028:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000472 prog.kernel_launch(%1029:tensor<[680, 5120], Float32, CPU>) -> (%1030:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.20.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000473 prog.free(%1029:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000474 prog.ret
        addr:0x00000000000475 prog.label[symbol:visual.blocks.21.__entry]
        addr:0x00000000000476 prog.kernel_launch(%1031:tensor<[680, 1280], Float32, CPU>) -> (%1032:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.21.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000477 prog.jump visual.blocks.21.attn.__entry[offset:10]
        addr:0x00000000000478 prog.kernel_launch(%1031:tensor<[680, 1280], Float32, CPU>, %1046:tensor<[680, 1280], Float32, CPU>) -> (%1047:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000479 prog.free(%1046:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000047a prog.free(%1031:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000047b prog.kernel_launch(%1047:tensor<[680, 1280], Float32, CPU>) -> (%1048:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.21.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000047c prog.jump visual.blocks.21.mlp.__entry[offset:37]
        addr:0x0000000000047d prog.kernel_launch(%1047:tensor<[680, 1280], Float32, CPU>, %1051:tensor<[680, 1280], Float32, CPU>) -> (%1052:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000047e prog.free(%1051:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000047f prog.free(%1047:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000480 prog.ret
        addr:0x00000000000481 prog.label[symbol:visual.blocks.21.attn.__entry]
        addr:0x00000000000482 prog.kernel_launch(%1032:tensor<[680, 1280], Float32, CPU>) -> (%1033:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.21.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000483 prog.free(%1032:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000484 prog.kernel_launch(%1033:tensor<[680, 3840], Float32, CPU>) -> (%1033:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000485 prog.kernel_launch(%1033:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1034:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000486 prog.free(%1033:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000487 prog.kernel_launch(%1034:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1034:tensor<[3, 680, 16, 80], Float32, CPU>, %1034:tensor<[3, 680, 16, 80], Float32, CPU>, %1034:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000488 prog.kernel_launch(%1034:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1035:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.21.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000489 prog.kernel_launch(%1034:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1036:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.21.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000048a prog.kernel_launch(%1035:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1037:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000048b prog.free(%1035:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000048c prog.kernel_launch(%1036:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1038:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000048d prog.free(%1036:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000048e prog.kernel_launch(%1034:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1039:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000048f prog.free(%1034:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000490 prog.kernel_launch(%1037:tensor<[1, 16, 680, 80], Float32, CPU>, %1038:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1040:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000491 prog.free(%1038:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000492 prog.free(%1037:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000493 prog.kernel_launch(%1040:tensor<[1, 16, 680, 680], Float32, CPU>, %1041:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1042:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000494 prog.free(%1041:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000495 prog.free(%1040:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000496 prog.kernel_launch(%1042:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1043:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.21.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000497 prog.free(%1042:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000498 prog.kernel_launch(%1043:tensor<[1, 16, 680, 680], Float32, CPU>, %1039:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1044:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000499 prog.free(%1039:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000049a prog.free(%1043:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000049b prog.kernel_launch(%1044:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1045:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000049c prog.free(%1044:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000049d prog.kernel_launch(%1045:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1045:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000049e prog.kernel_launch(%1045:tensor<[680, 1280], Float32, CPU>) -> (%1046:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.21.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000049f prog.free(%1045:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004a0 prog.ret
        addr:0x000000000004a1 prog.label[symbol:visual.blocks.21.mlp.__entry]
        addr:0x000000000004a2 prog.kernel_launch(%1048:tensor<[680, 1280], Float32, CPU>) -> (%1049:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.21.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000004a3 prog.free(%1048:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004a4 prog.kernel_launch(%1049:tensor<[680, 5120], Float32, CPU>) -> (%1050:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.21.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000004a5 prog.free(%1049:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000004a6 prog.kernel_launch(%1050:tensor<[680, 5120], Float32, CPU>) -> (%1051:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.21.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000004a7 prog.free(%1050:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000004a8 prog.ret
        addr:0x000000000004a9 prog.label[symbol:visual.blocks.22.__entry]
        addr:0x000000000004aa prog.kernel_launch(%1052:tensor<[680, 1280], Float32, CPU>) -> (%1053:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.22.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000004ab prog.jump visual.blocks.22.attn.__entry[offset:10]
        addr:0x000000000004ac prog.kernel_launch(%1052:tensor<[680, 1280], Float32, CPU>, %1067:tensor<[680, 1280], Float32, CPU>) -> (%1068:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000004ad prog.free(%1067:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004ae prog.free(%1052:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004af prog.kernel_launch(%1068:tensor<[680, 1280], Float32, CPU>) -> (%1069:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.22.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000004b0 prog.jump visual.blocks.22.mlp.__entry[offset:37]
        addr:0x000000000004b1 prog.kernel_launch(%1068:tensor<[680, 1280], Float32, CPU>, %1072:tensor<[680, 1280], Float32, CPU>) -> (%1073:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000004b2 prog.free(%1072:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004b3 prog.free(%1068:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004b4 prog.ret
        addr:0x000000000004b5 prog.label[symbol:visual.blocks.22.attn.__entry]
        addr:0x000000000004b6 prog.kernel_launch(%1053:tensor<[680, 1280], Float32, CPU>) -> (%1054:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.22.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000004b7 prog.free(%1053:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004b8 prog.kernel_launch(%1054:tensor<[680, 3840], Float32, CPU>) -> (%1054:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000004b9 prog.kernel_launch(%1054:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1055:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000004ba prog.free(%1054:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004bb prog.kernel_launch(%1055:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1055:tensor<[3, 680, 16, 80], Float32, CPU>, %1055:tensor<[3, 680, 16, 80], Float32, CPU>, %1055:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000004bc prog.kernel_launch(%1055:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1056:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.22.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000004bd prog.kernel_launch(%1055:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1057:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.22.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000004be prog.kernel_launch(%1056:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1058:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004bf prog.free(%1056:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004c0 prog.kernel_launch(%1057:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1059:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004c1 prog.free(%1057:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004c2 prog.kernel_launch(%1055:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1060:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004c3 prog.free(%1055:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004c4 prog.kernel_launch(%1058:tensor<[1, 16, 680, 80], Float32, CPU>, %1059:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1061:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000004c5 prog.free(%1059:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004c6 prog.free(%1058:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004c7 prog.kernel_launch(%1061:tensor<[1, 16, 680, 680], Float32, CPU>, %1062:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1063:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000004c8 prog.free(%1062:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000004c9 prog.free(%1061:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000004ca prog.kernel_launch(%1063:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1064:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.22.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000004cb prog.free(%1063:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000004cc prog.kernel_launch(%1064:tensor<[1, 16, 680, 680], Float32, CPU>, %1060:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1065:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000004cd prog.free(%1060:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004ce prog.free(%1064:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000004cf prog.kernel_launch(%1065:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1066:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004d0 prog.free(%1065:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004d1 prog.kernel_launch(%1066:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1066:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000004d2 prog.kernel_launch(%1066:tensor<[680, 1280], Float32, CPU>) -> (%1067:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.22.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000004d3 prog.free(%1066:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004d4 prog.ret
        addr:0x000000000004d5 prog.label[symbol:visual.blocks.22.mlp.__entry]
        addr:0x000000000004d6 prog.kernel_launch(%1069:tensor<[680, 1280], Float32, CPU>) -> (%1070:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.22.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000004d7 prog.free(%1069:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004d8 prog.kernel_launch(%1070:tensor<[680, 5120], Float32, CPU>) -> (%1071:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.22.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000004d9 prog.free(%1070:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000004da prog.kernel_launch(%1071:tensor<[680, 5120], Float32, CPU>) -> (%1072:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.22.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000004db prog.free(%1071:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000004dc prog.ret
        addr:0x000000000004dd prog.label[symbol:visual.blocks.23.__entry]
        addr:0x000000000004de prog.kernel_launch(%1073:tensor<[680, 1280], Float32, CPU>) -> (%1074:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.23.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000004df prog.jump visual.blocks.23.attn.__entry[offset:10]
        addr:0x000000000004e0 prog.kernel_launch(%1073:tensor<[680, 1280], Float32, CPU>, %1088:tensor<[680, 1280], Float32, CPU>) -> (%1089:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000004e1 prog.free(%1088:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004e2 prog.free(%1073:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004e3 prog.kernel_launch(%1089:tensor<[680, 1280], Float32, CPU>) -> (%1090:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.23.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000004e4 prog.jump visual.blocks.23.mlp.__entry[offset:37]
        addr:0x000000000004e5 prog.kernel_launch(%1089:tensor<[680, 1280], Float32, CPU>, %1093:tensor<[680, 1280], Float32, CPU>) -> (%1094:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000004e6 prog.free(%1093:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004e7 prog.free(%1089:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004e8 prog.ret
        addr:0x000000000004e9 prog.label[symbol:visual.blocks.23.attn.__entry]
        addr:0x000000000004ea prog.kernel_launch(%1074:tensor<[680, 1280], Float32, CPU>) -> (%1075:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.23.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000004eb prog.free(%1074:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000004ec prog.kernel_launch(%1075:tensor<[680, 3840], Float32, CPU>) -> (%1075:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000004ed prog.kernel_launch(%1075:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1076:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000004ee prog.free(%1075:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004ef prog.kernel_launch(%1076:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1076:tensor<[3, 680, 16, 80], Float32, CPU>, %1076:tensor<[3, 680, 16, 80], Float32, CPU>, %1076:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000004f0 prog.kernel_launch(%1076:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1077:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.23.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000004f1 prog.kernel_launch(%1076:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1078:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.23.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000004f2 prog.kernel_launch(%1077:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1079:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004f3 prog.free(%1077:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004f4 prog.kernel_launch(%1078:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1080:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004f5 prog.free(%1078:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004f6 prog.kernel_launch(%1076:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1081:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000004f7 prog.free(%1076:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000004f8 prog.kernel_launch(%1079:tensor<[1, 16, 680, 80], Float32, CPU>, %1080:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1082:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000004f9 prog.free(%1080:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004fa prog.free(%1079:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000004fb prog.kernel_launch(%1082:tensor<[1, 16, 680, 680], Float32, CPU>, %1083:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1084:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000004fc prog.free(%1083:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000004fd prog.free(%1082:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000004fe prog.kernel_launch(%1084:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1085:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.23.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000004ff prog.free(%1084:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000500 prog.kernel_launch(%1085:tensor<[1, 16, 680, 680], Float32, CPU>, %1081:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1086:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000501 prog.free(%1081:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000502 prog.free(%1085:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000503 prog.kernel_launch(%1086:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1087:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000504 prog.free(%1086:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000505 prog.kernel_launch(%1087:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1087:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000506 prog.kernel_launch(%1087:tensor<[680, 1280], Float32, CPU>) -> (%1088:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.23.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000507 prog.free(%1087:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000508 prog.ret
        addr:0x00000000000509 prog.label[symbol:visual.blocks.23.mlp.__entry]
        addr:0x0000000000050a prog.kernel_launch(%1090:tensor<[680, 1280], Float32, CPU>) -> (%1091:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.23.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000050b prog.free(%1090:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000050c prog.kernel_launch(%1091:tensor<[680, 5120], Float32, CPU>) -> (%1092:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.23.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000050d prog.free(%1091:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000050e prog.kernel_launch(%1092:tensor<[680, 5120], Float32, CPU>) -> (%1093:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.23.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000050f prog.free(%1092:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000510 prog.ret
        addr:0x00000000000511 prog.label[symbol:visual.blocks.24.__entry]
        addr:0x00000000000512 prog.kernel_launch(%1094:tensor<[680, 1280], Float32, CPU>) -> (%1095:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.24.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000513 prog.jump visual.blocks.24.attn.__entry[offset:10]
        addr:0x00000000000514 prog.kernel_launch(%1094:tensor<[680, 1280], Float32, CPU>, %1109:tensor<[680, 1280], Float32, CPU>) -> (%1110:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000515 prog.free(%1109:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000516 prog.free(%1094:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000517 prog.kernel_launch(%1110:tensor<[680, 1280], Float32, CPU>) -> (%1111:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.24.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000518 prog.jump visual.blocks.24.mlp.__entry[offset:37]
        addr:0x00000000000519 prog.kernel_launch(%1110:tensor<[680, 1280], Float32, CPU>, %1114:tensor<[680, 1280], Float32, CPU>) -> (%1115:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000051a prog.free(%1114:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000051b prog.free(%1110:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000051c prog.ret
        addr:0x0000000000051d prog.label[symbol:visual.blocks.24.attn.__entry]
        addr:0x0000000000051e prog.kernel_launch(%1095:tensor<[680, 1280], Float32, CPU>) -> (%1096:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.24.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000051f prog.free(%1095:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000520 prog.kernel_launch(%1096:tensor<[680, 3840], Float32, CPU>) -> (%1096:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000521 prog.kernel_launch(%1096:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1097:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000522 prog.free(%1096:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000523 prog.kernel_launch(%1097:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1097:tensor<[3, 680, 16, 80], Float32, CPU>, %1097:tensor<[3, 680, 16, 80], Float32, CPU>, %1097:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000524 prog.kernel_launch(%1097:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1098:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.24.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000525 prog.kernel_launch(%1097:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1099:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.24.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000526 prog.kernel_launch(%1098:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1100:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000527 prog.free(%1098:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000528 prog.kernel_launch(%1099:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1101:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000529 prog.free(%1099:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000052a prog.kernel_launch(%1097:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1102:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000052b prog.free(%1097:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000052c prog.kernel_launch(%1100:tensor<[1, 16, 680, 80], Float32, CPU>, %1101:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1103:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000052d prog.free(%1101:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000052e prog.free(%1100:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000052f prog.kernel_launch(%1103:tensor<[1, 16, 680, 680], Float32, CPU>, %1104:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1105:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000530 prog.free(%1104:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000531 prog.free(%1103:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000532 prog.kernel_launch(%1105:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1106:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.24.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000533 prog.free(%1105:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000534 prog.kernel_launch(%1106:tensor<[1, 16, 680, 680], Float32, CPU>, %1102:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1107:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000535 prog.free(%1102:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000536 prog.free(%1106:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000537 prog.kernel_launch(%1107:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1108:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000538 prog.free(%1107:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000539 prog.kernel_launch(%1108:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1108:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000053a prog.kernel_launch(%1108:tensor<[680, 1280], Float32, CPU>) -> (%1109:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.24.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000053b prog.free(%1108:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000053c prog.ret
        addr:0x0000000000053d prog.label[symbol:visual.blocks.24.mlp.__entry]
        addr:0x0000000000053e prog.kernel_launch(%1111:tensor<[680, 1280], Float32, CPU>) -> (%1112:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.24.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000053f prog.free(%1111:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000540 prog.kernel_launch(%1112:tensor<[680, 5120], Float32, CPU>) -> (%1113:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.24.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000541 prog.free(%1112:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000542 prog.kernel_launch(%1113:tensor<[680, 5120], Float32, CPU>) -> (%1114:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.24.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000543 prog.free(%1113:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000544 prog.ret
        addr:0x00000000000545 prog.label[symbol:visual.blocks.25.__entry]
        addr:0x00000000000546 prog.kernel_launch(%1115:tensor<[680, 1280], Float32, CPU>) -> (%1116:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.25.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000547 prog.jump visual.blocks.25.attn.__entry[offset:10]
        addr:0x00000000000548 prog.kernel_launch(%1115:tensor<[680, 1280], Float32, CPU>, %1130:tensor<[680, 1280], Float32, CPU>) -> (%1131:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000549 prog.free(%1130:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000054a prog.free(%1115:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000054b prog.kernel_launch(%1131:tensor<[680, 1280], Float32, CPU>) -> (%1132:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.25.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000054c prog.jump visual.blocks.25.mlp.__entry[offset:37]
        addr:0x0000000000054d prog.kernel_launch(%1131:tensor<[680, 1280], Float32, CPU>, %1135:tensor<[680, 1280], Float32, CPU>) -> (%1136:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000054e prog.free(%1135:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000054f prog.free(%1131:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000550 prog.ret
        addr:0x00000000000551 prog.label[symbol:visual.blocks.25.attn.__entry]
        addr:0x00000000000552 prog.kernel_launch(%1116:tensor<[680, 1280], Float32, CPU>) -> (%1117:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.25.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000553 prog.free(%1116:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000554 prog.kernel_launch(%1117:tensor<[680, 3840], Float32, CPU>) -> (%1117:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000555 prog.kernel_launch(%1117:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1118:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000556 prog.free(%1117:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000557 prog.kernel_launch(%1118:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1118:tensor<[3, 680, 16, 80], Float32, CPU>, %1118:tensor<[3, 680, 16, 80], Float32, CPU>, %1118:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000558 prog.kernel_launch(%1118:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1119:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.25.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000559 prog.kernel_launch(%1118:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1120:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.25.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000055a prog.kernel_launch(%1119:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1121:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000055b prog.free(%1119:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000055c prog.kernel_launch(%1120:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1122:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000055d prog.free(%1120:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000055e prog.kernel_launch(%1118:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1123:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000055f prog.free(%1118:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000560 prog.kernel_launch(%1121:tensor<[1, 16, 680, 80], Float32, CPU>, %1122:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1124:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000561 prog.free(%1122:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000562 prog.free(%1121:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000563 prog.kernel_launch(%1124:tensor<[1, 16, 680, 680], Float32, CPU>, %1125:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1126:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000564 prog.free(%1125:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000565 prog.free(%1124:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000566 prog.kernel_launch(%1126:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1127:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.25.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000567 prog.free(%1126:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000568 prog.kernel_launch(%1127:tensor<[1, 16, 680, 680], Float32, CPU>, %1123:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1128:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000569 prog.free(%1123:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000056a prog.free(%1127:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000056b prog.kernel_launch(%1128:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1129:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000056c prog.free(%1128:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000056d prog.kernel_launch(%1129:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1129:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000056e prog.kernel_launch(%1129:tensor<[680, 1280], Float32, CPU>) -> (%1130:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.25.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000056f prog.free(%1129:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000570 prog.ret
        addr:0x00000000000571 prog.label[symbol:visual.blocks.25.mlp.__entry]
        addr:0x00000000000572 prog.kernel_launch(%1132:tensor<[680, 1280], Float32, CPU>) -> (%1133:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.25.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000573 prog.free(%1132:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000574 prog.kernel_launch(%1133:tensor<[680, 5120], Float32, CPU>) -> (%1134:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.25.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000575 prog.free(%1133:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000576 prog.kernel_launch(%1134:tensor<[680, 5120], Float32, CPU>) -> (%1135:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.25.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000577 prog.free(%1134:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000578 prog.ret
        addr:0x00000000000579 prog.label[symbol:visual.blocks.26.__entry]
        addr:0x0000000000057a prog.kernel_launch(%1136:tensor<[680, 1280], Float32, CPU>) -> (%1137:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.26.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000057b prog.jump visual.blocks.26.attn.__entry[offset:10]
        addr:0x0000000000057c prog.kernel_launch(%1136:tensor<[680, 1280], Float32, CPU>, %1151:tensor<[680, 1280], Float32, CPU>) -> (%1152:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000057d prog.free(%1151:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000057e prog.free(%1136:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000057f prog.kernel_launch(%1152:tensor<[680, 1280], Float32, CPU>) -> (%1153:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.26.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000580 prog.jump visual.blocks.26.mlp.__entry[offset:37]
        addr:0x00000000000581 prog.kernel_launch(%1152:tensor<[680, 1280], Float32, CPU>, %1156:tensor<[680, 1280], Float32, CPU>) -> (%1157:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000582 prog.free(%1156:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000583 prog.free(%1152:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000584 prog.ret
        addr:0x00000000000585 prog.label[symbol:visual.blocks.26.attn.__entry]
        addr:0x00000000000586 prog.kernel_launch(%1137:tensor<[680, 1280], Float32, CPU>) -> (%1138:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.26.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000587 prog.free(%1137:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000588 prog.kernel_launch(%1138:tensor<[680, 3840], Float32, CPU>) -> (%1138:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000589 prog.kernel_launch(%1138:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1139:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000058a prog.free(%1138:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000058b prog.kernel_launch(%1139:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1139:tensor<[3, 680, 16, 80], Float32, CPU>, %1139:tensor<[3, 680, 16, 80], Float32, CPU>, %1139:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x0000000000058c prog.kernel_launch(%1139:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1140:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.26.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000058d prog.kernel_launch(%1139:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1141:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.26.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000058e prog.kernel_launch(%1140:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1142:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000058f prog.free(%1140:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000590 prog.kernel_launch(%1141:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1143:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000591 prog.free(%1141:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000592 prog.kernel_launch(%1139:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1144:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000593 prog.free(%1139:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000594 prog.kernel_launch(%1142:tensor<[1, 16, 680, 80], Float32, CPU>, %1143:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1145:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000595 prog.free(%1143:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000596 prog.free(%1142:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000597 prog.kernel_launch(%1145:tensor<[1, 16, 680, 680], Float32, CPU>, %1146:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1147:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000598 prog.free(%1146:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000599 prog.free(%1145:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000059a prog.kernel_launch(%1147:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1148:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.26.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000059b prog.free(%1147:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000059c prog.kernel_launch(%1148:tensor<[1, 16, 680, 680], Float32, CPU>, %1144:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1149:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x0000000000059d prog.free(%1144:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000059e prog.free(%1148:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000059f prog.kernel_launch(%1149:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1150:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005a0 prog.free(%1149:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005a1 prog.kernel_launch(%1150:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1150:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000005a2 prog.kernel_launch(%1150:tensor<[680, 1280], Float32, CPU>) -> (%1151:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.26.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000005a3 prog.free(%1150:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005a4 prog.ret
        addr:0x000000000005a5 prog.label[symbol:visual.blocks.26.mlp.__entry]
        addr:0x000000000005a6 prog.kernel_launch(%1153:tensor<[680, 1280], Float32, CPU>) -> (%1154:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.26.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000005a7 prog.free(%1153:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005a8 prog.kernel_launch(%1154:tensor<[680, 5120], Float32, CPU>) -> (%1155:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.26.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000005a9 prog.free(%1154:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000005aa prog.kernel_launch(%1155:tensor<[680, 5120], Float32, CPU>) -> (%1156:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.26.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000005ab prog.free(%1155:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000005ac prog.ret
        addr:0x000000000005ad prog.label[symbol:visual.blocks.27.__entry]
        addr:0x000000000005ae prog.kernel_launch(%1157:tensor<[680, 1280], Float32, CPU>) -> (%1158:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.27.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000005af prog.jump visual.blocks.27.attn.__entry[offset:10]
        addr:0x000000000005b0 prog.kernel_launch(%1157:tensor<[680, 1280], Float32, CPU>, %1172:tensor<[680, 1280], Float32, CPU>) -> (%1173:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000005b1 prog.free(%1172:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005b2 prog.free(%1157:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005b3 prog.kernel_launch(%1173:tensor<[680, 1280], Float32, CPU>) -> (%1174:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.27.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000005b4 prog.jump visual.blocks.27.mlp.__entry[offset:37]
        addr:0x000000000005b5 prog.kernel_launch(%1173:tensor<[680, 1280], Float32, CPU>, %1177:tensor<[680, 1280], Float32, CPU>) -> (%1178:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000005b6 prog.free(%1177:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005b7 prog.free(%1173:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005b8 prog.ret
        addr:0x000000000005b9 prog.label[symbol:visual.blocks.27.attn.__entry]
        addr:0x000000000005ba prog.kernel_launch(%1158:tensor<[680, 1280], Float32, CPU>) -> (%1159:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.27.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000005bb prog.free(%1158:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005bc prog.kernel_launch(%1159:tensor<[680, 3840], Float32, CPU>) -> (%1159:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000005bd prog.kernel_launch(%1159:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1160:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000005be prog.free(%1159:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005bf prog.kernel_launch(%1160:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1160:tensor<[3, 680, 16, 80], Float32, CPU>, %1160:tensor<[3, 680, 16, 80], Float32, CPU>, %1160:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000005c0 prog.kernel_launch(%1160:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1161:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.27.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000005c1 prog.kernel_launch(%1160:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1162:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.27.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000005c2 prog.kernel_launch(%1161:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1163:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005c3 prog.free(%1161:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005c4 prog.kernel_launch(%1162:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1164:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005c5 prog.free(%1162:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005c6 prog.kernel_launch(%1160:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1165:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005c7 prog.free(%1160:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005c8 prog.kernel_launch(%1163:tensor<[1, 16, 680, 80], Float32, CPU>, %1164:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1166:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000005c9 prog.free(%1164:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005ca prog.free(%1163:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005cb prog.kernel_launch(%1166:tensor<[1, 16, 680, 680], Float32, CPU>, %1167:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1168:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x000000000005cc prog.free(%1167:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x000000000005cd prog.free(%1166:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000005ce prog.kernel_launch(%1168:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1169:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.27.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000005cf prog.free(%1168:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000005d0 prog.kernel_launch(%1169:tensor<[1, 16, 680, 680], Float32, CPU>, %1165:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1170:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000005d1 prog.free(%1165:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005d2 prog.free(%1169:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000005d3 prog.kernel_launch(%1170:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1171:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005d4 prog.free(%1170:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005d5 prog.kernel_launch(%1171:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1171:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000005d6 prog.kernel_launch(%1171:tensor<[680, 1280], Float32, CPU>) -> (%1172:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.27.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000005d7 prog.free(%1171:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005d8 prog.ret
        addr:0x000000000005d9 prog.label[symbol:visual.blocks.27.mlp.__entry]
        addr:0x000000000005da prog.kernel_launch(%1174:tensor<[680, 1280], Float32, CPU>) -> (%1175:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.27.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000005db prog.free(%1174:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005dc prog.kernel_launch(%1175:tensor<[680, 5120], Float32, CPU>) -> (%1176:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.27.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000005dd prog.free(%1175:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000005de prog.kernel_launch(%1176:tensor<[680, 5120], Float32, CPU>) -> (%1177:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.27.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000005df prog.free(%1176:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000005e0 prog.ret
        addr:0x000000000005e1 prog.label[symbol:visual.blocks.28.__entry]
        addr:0x000000000005e2 prog.kernel_launch(%1178:tensor<[680, 1280], Float32, CPU>) -> (%1179:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.28.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000005e3 prog.jump visual.blocks.28.attn.__entry[offset:10]
        addr:0x000000000005e4 prog.kernel_launch(%1178:tensor<[680, 1280], Float32, CPU>, %1193:tensor<[680, 1280], Float32, CPU>) -> (%1194:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000005e5 prog.free(%1193:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005e6 prog.free(%1178:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005e7 prog.kernel_launch(%1194:tensor<[680, 1280], Float32, CPU>) -> (%1195:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.28.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000005e8 prog.jump visual.blocks.28.mlp.__entry[offset:37]
        addr:0x000000000005e9 prog.kernel_launch(%1194:tensor<[680, 1280], Float32, CPU>, %1198:tensor<[680, 1280], Float32, CPU>) -> (%1199:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x000000000005ea prog.free(%1198:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005eb prog.free(%1194:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005ec prog.ret
        addr:0x000000000005ed prog.label[symbol:visual.blocks.28.attn.__entry]
        addr:0x000000000005ee prog.kernel_launch(%1179:tensor<[680, 1280], Float32, CPU>) -> (%1180:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.28.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000005ef prog.free(%1179:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000005f0 prog.kernel_launch(%1180:tensor<[680, 3840], Float32, CPU>) -> (%1180:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x000000000005f1 prog.kernel_launch(%1180:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1181:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x000000000005f2 prog.free(%1180:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005f3 prog.kernel_launch(%1181:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1181:tensor<[3, 680, 16, 80], Float32, CPU>, %1181:tensor<[3, 680, 16, 80], Float32, CPU>, %1181:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x000000000005f4 prog.kernel_launch(%1181:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1182:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.28.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000005f5 prog.kernel_launch(%1181:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1183:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.28.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000005f6 prog.kernel_launch(%1182:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1184:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005f7 prog.free(%1182:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005f8 prog.kernel_launch(%1183:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1185:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005f9 prog.free(%1183:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005fa prog.kernel_launch(%1181:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1186:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000005fb prog.free(%1181:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x000000000005fc prog.kernel_launch(%1184:tensor<[1, 16, 680, 80], Float32, CPU>, %1185:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1187:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x000000000005fd prog.free(%1185:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005fe prog.free(%1184:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000005ff prog.kernel_launch(%1187:tensor<[1, 16, 680, 680], Float32, CPU>, %1188:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1189:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000600 prog.free(%1188:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000601 prog.free(%1187:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000602 prog.kernel_launch(%1189:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1190:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.28.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000603 prog.free(%1189:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000604 prog.kernel_launch(%1190:tensor<[1, 16, 680, 680], Float32, CPU>, %1186:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1191:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000605 prog.free(%1186:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000606 prog.free(%1190:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000607 prog.kernel_launch(%1191:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1192:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000608 prog.free(%1191:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000609 prog.kernel_launch(%1192:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1192:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000060a prog.kernel_launch(%1192:tensor<[680, 1280], Float32, CPU>) -> (%1193:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.28.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000060b prog.free(%1192:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000060c prog.ret
        addr:0x0000000000060d prog.label[symbol:visual.blocks.28.mlp.__entry]
        addr:0x0000000000060e prog.kernel_launch(%1195:tensor<[680, 1280], Float32, CPU>) -> (%1196:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.28.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000060f prog.free(%1195:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000610 prog.kernel_launch(%1196:tensor<[680, 5120], Float32, CPU>) -> (%1197:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.28.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000611 prog.free(%1196:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000612 prog.kernel_launch(%1197:tensor<[680, 5120], Float32, CPU>) -> (%1198:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.28.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000613 prog.free(%1197:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000614 prog.ret
        addr:0x00000000000615 prog.label[symbol:visual.blocks.29.__entry]
        addr:0x00000000000616 prog.kernel_launch(%1199:tensor<[680, 1280], Float32, CPU>) -> (%1200:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.29.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000617 prog.jump visual.blocks.29.attn.__entry[offset:10]
        addr:0x00000000000618 prog.kernel_launch(%1199:tensor<[680, 1280], Float32, CPU>, %1214:tensor<[680, 1280], Float32, CPU>) -> (%1215:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000619 prog.free(%1214:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000061a prog.free(%1199:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000061b prog.kernel_launch(%1215:tensor<[680, 1280], Float32, CPU>) -> (%1216:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.29.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000061c prog.jump visual.blocks.29.mlp.__entry[offset:37]
        addr:0x0000000000061d prog.kernel_launch(%1215:tensor<[680, 1280], Float32, CPU>, %1219:tensor<[680, 1280], Float32, CPU>) -> (%1220:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000061e prog.free(%1219:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000061f prog.free(%1215:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000620 prog.ret
        addr:0x00000000000621 prog.label[symbol:visual.blocks.29.attn.__entry]
        addr:0x00000000000622 prog.kernel_launch(%1200:tensor<[680, 1280], Float32, CPU>) -> (%1201:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.29.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000623 prog.free(%1200:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000624 prog.kernel_launch(%1201:tensor<[680, 3840], Float32, CPU>) -> (%1201:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000625 prog.kernel_launch(%1201:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1202:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x00000000000626 prog.free(%1201:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000627 prog.kernel_launch(%1202:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1202:tensor<[3, 680, 16, 80], Float32, CPU>, %1202:tensor<[3, 680, 16, 80], Float32, CPU>, %1202:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000628 prog.kernel_launch(%1202:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1203:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.29.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000629 prog.kernel_launch(%1202:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1204:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.29.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000062a prog.kernel_launch(%1203:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1205:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000062b prog.free(%1203:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000062c prog.kernel_launch(%1204:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1206:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000062d prog.free(%1204:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000062e prog.kernel_launch(%1202:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1207:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000062f prog.free(%1202:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000630 prog.kernel_launch(%1205:tensor<[1, 16, 680, 80], Float32, CPU>, %1206:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1208:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000631 prog.free(%1206:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000632 prog.free(%1205:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000633 prog.kernel_launch(%1208:tensor<[1, 16, 680, 680], Float32, CPU>, %1209:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1210:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000634 prog.free(%1209:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000635 prog.free(%1208:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000636 prog.kernel_launch(%1210:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1211:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.29.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000637 prog.free(%1210:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x00000000000638 prog.kernel_launch(%1211:tensor<[1, 16, 680, 680], Float32, CPU>, %1207:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1212:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x00000000000639 prog.free(%1207:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000063a prog.free(%1211:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000063b prog.kernel_launch(%1212:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1213:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000063c prog.free(%1212:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000063d prog.kernel_launch(%1213:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1213:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x0000000000063e prog.kernel_launch(%1213:tensor<[680, 1280], Float32, CPU>) -> (%1214:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.29.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000063f prog.free(%1213:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000640 prog.ret
        addr:0x00000000000641 prog.label[symbol:visual.blocks.29.mlp.__entry]
        addr:0x00000000000642 prog.kernel_launch(%1216:tensor<[680, 1280], Float32, CPU>) -> (%1217:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.29.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000643 prog.free(%1216:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000644 prog.kernel_launch(%1217:tensor<[680, 5120], Float32, CPU>) -> (%1218:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.29.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000645 prog.free(%1217:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000646 prog.kernel_launch(%1218:tensor<[680, 5120], Float32, CPU>) -> (%1219:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.29.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000647 prog.free(%1218:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x00000000000648 prog.ret
        addr:0x00000000000649 prog.label[symbol:visual.blocks.30.__entry]
        addr:0x0000000000064a prog.kernel_launch(%1220:tensor<[680, 1280], Float32, CPU>) -> (%1221:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.30.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000064b prog.jump visual.blocks.30.attn.__entry[offset:10]
        addr:0x0000000000064c prog.kernel_launch(%1220:tensor<[680, 1280], Float32, CPU>, %1235:tensor<[680, 1280], Float32, CPU>) -> (%1236:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x0000000000064d prog.free(%1235:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000064e prog.free(%1220:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000064f prog.kernel_launch(%1236:tensor<[680, 1280], Float32, CPU>) -> (%1237:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.30.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000650 prog.jump visual.blocks.30.mlp.__entry[offset:37]
        addr:0x00000000000651 prog.kernel_launch(%1236:tensor<[680, 1280], Float32, CPU>, %1240:tensor<[680, 1280], Float32, CPU>) -> (%1241:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000652 prog.free(%1240:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000653 prog.free(%1236:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000654 prog.ret
        addr:0x00000000000655 prog.label[symbol:visual.blocks.30.attn.__entry]
        addr:0x00000000000656 prog.kernel_launch(%1221:tensor<[680, 1280], Float32, CPU>) -> (%1222:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.30.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000657 prog.free(%1221:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000658 prog.kernel_launch(%1222:tensor<[680, 3840], Float32, CPU>) -> (%1222:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x00000000000659 prog.kernel_launch(%1222:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1223:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000065a prog.free(%1222:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000065b prog.kernel_launch(%1223:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1223:tensor<[3, 680, 16, 80], Float32, CPU>, %1223:tensor<[3, 680, 16, 80], Float32, CPU>, %1223:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x0000000000065c prog.kernel_launch(%1223:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1224:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.30.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000065d prog.kernel_launch(%1223:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1225:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.30.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000065e prog.kernel_launch(%1224:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1226:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x0000000000065f prog.free(%1224:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000660 prog.kernel_launch(%1225:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1227:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000661 prog.free(%1225:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000662 prog.kernel_launch(%1223:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1228:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000663 prog.free(%1223:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000664 prog.kernel_launch(%1226:tensor<[1, 16, 680, 80], Float32, CPU>, %1227:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1229:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x00000000000665 prog.free(%1227:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000666 prog.free(%1226:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000667 prog.kernel_launch(%1229:tensor<[1, 16, 680, 680], Float32, CPU>, %1230:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1231:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x00000000000668 prog.free(%1230:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x00000000000669 prog.free(%1229:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000066a prog.kernel_launch(%1231:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1232:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.30.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000066b prog.free(%1231:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000066c prog.kernel_launch(%1232:tensor<[1, 16, 680, 680], Float32, CPU>, %1228:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1233:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x0000000000066d prog.free(%1228:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000066e prog.free(%1232:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x0000000000066f prog.kernel_launch(%1233:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1234:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000670 prog.free(%1233:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x00000000000671 prog.kernel_launch(%1234:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1234:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x00000000000672 prog.kernel_launch(%1234:tensor<[680, 1280], Float32, CPU>) -> (%1235:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.30.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000673 prog.free(%1234:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000674 prog.ret
        addr:0x00000000000675 prog.label[symbol:visual.blocks.30.mlp.__entry]
        addr:0x00000000000676 prog.kernel_launch(%1237:tensor<[680, 1280], Float32, CPU>) -> (%1238:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.30.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000677 prog.free(%1237:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000678 prog.kernel_launch(%1238:tensor<[680, 5120], Float32, CPU>) -> (%1239:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.30.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000679 prog.free(%1238:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000067a prog.kernel_launch(%1239:tensor<[680, 5120], Float32, CPU>) -> (%1240:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.30.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000067b prog.free(%1239:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x0000000000067c prog.ret
        addr:0x0000000000067d prog.label[symbol:visual.blocks.31.__entry]
        addr:0x0000000000067e prog.kernel_launch(%1241:tensor<[680, 1280], Float32, CPU>) -> (%1242:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.31.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000067f prog.jump visual.blocks.31.attn.__entry[offset:10]
        addr:0x00000000000680 prog.kernel_launch(%1241:tensor<[680, 1280], Float32, CPU>, %1256:tensor<[680, 1280], Float32, CPU>) -> (%1257:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000681 prog.free(%1256:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000682 prog.free(%1241:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000683 prog.kernel_launch(%1257:tensor<[680, 1280], Float32, CPU>) -> (%1258:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.31.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000684 prog.jump visual.blocks.31.mlp.__entry[offset:39]
        addr:0x00000000000685 prog.kernel_launch(%1257:tensor<[680, 1280], Float32, CPU>, %1261:tensor<[680, 1280], Float32, CPU>) -> (%1262:tensor<[680, 1280], Float32, CPU>)[op_type:Add, op_options:null]
        addr:0x00000000000686 prog.free(%1261:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000687 prog.free(%1257:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x00000000000688 prog.ret
        addr:0x00000000000689 prog.label[symbol:visual.blocks.31.attn.__entry]
        addr:0x0000000000068a prog.kernel_launch(%1242:tensor<[680, 1280], Float32, CPU>) -> (%1243:tensor<[680, 3840], Float32, CPU>)[symbol_name:visual.blocks.31.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000068b prog.free(%1242:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x0000000000068c prog.kernel_launch(%1243:tensor<[680, 3840], Float32, CPU>) -> (%1243:tensor<[680, 3, 16, 80], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,3,16,80]}]
        addr:0x0000000000068d prog.kernel_launch(%1243:tensor<[680, 3, 16, 80], Float32, CPU>) -> (%1244:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Permute, op_options:{"axis":[1,0,2,3]}]
        addr:0x0000000000068e prog.free(%1243:tensor<[680, 3, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000068f prog.kernel_launch(%1244:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1244:tensor<[3, 680, 16, 80], Float32, CPU>, %1244:tensor<[3, 680, 16, 80], Float32, CPU>, %1244:tensor<[3, 680, 16, 80], Float32, CPU>)[op_type:Split, op_options:{"dim":0,"split_size_or_sections":[1]}]
        addr:0x00000000000690 prog.kernel_launch(%1244:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1245:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.31.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000691 prog.kernel_launch(%1244:tensor<[3, 680, 16, 80], Float32, CPU>, %588:tensor<[680, 40], Float32, CPU>, %589:tensor<[680, 40], Float32, CPU>) -> (%1246:tensor<[1, 680, 16, 80], Float32, CPU>)[symbol_name:visual.blocks.31.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000692 prog.free(%589:tensor<[680, 40], Float32, CPU>) -> ()
        addr:0x00000000000693 prog.free(%588:tensor<[680, 40], Float32, CPU>) -> ()
        addr:0x00000000000694 prog.kernel_launch(%1245:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1247:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000695 prog.free(%1245:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000696 prog.kernel_launch(%1246:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1248:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000697 prog.free(%1246:tensor<[1, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x00000000000698 prog.kernel_launch(%1244:tensor<[3, 680, 16, 80], Float32, CPU>) -> (%1249:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x00000000000699 prog.free(%1244:tensor<[3, 680, 16, 80], Float32, CPU>) -> ()
        addr:0x0000000000069a prog.kernel_launch(%1247:tensor<[1, 16, 680, 80], Float32, CPU>, %1248:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1250:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":true}]
        addr:0x0000000000069b prog.free(%1248:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000069c prog.free(%1247:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x0000000000069d prog.kernel_launch(%1250:tensor<[1, 16, 680, 680], Float32, CPU>, %1251:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> (%1252:tensor<[1, 16, 680, 680], Float32, CPU>)[op_type:Mul, op_options:null]
        addr:0x0000000000069e prog.free(%1251:tensor<[1], Float32, CPU>[constant: [0.1118034]]) -> ()
        addr:0x0000000000069f prog.free(%1250:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000006a0 prog.kernel_launch(%1252:tensor<[1, 16, 680, 680], Float32, CPU>) -> (%1253:tensor<[1, 16, 680, 680], Float32, CPU>)[symbol_name:visual.blocks.31.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000006a1 prog.free(%1252:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000006a2 prog.kernel_launch(%1253:tensor<[1, 16, 680, 680], Float32, CPU>, %1249:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1254:tensor<[1, 16, 680, 80], Float32, CPU>)[op_type:MatMul, op_options:{"matmul_type":"Default","transpose_a":false,"transpose_b":false}]
        addr:0x000000000006a3 prog.free(%1249:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000006a4 prog.free(%1253:tensor<[1, 16, 680, 680], Float32, CPU>) -> ()
        addr:0x000000000006a5 prog.kernel_launch(%1254:tensor<[1, 16, 680, 80], Float32, CPU>) -> (%1255:tensor<[1, 680, 16, 80], Float32, CPU>)[op_type:Transpose, op_options:{"dim0":1,"dim1":2}]
        addr:0x000000000006a6 prog.free(%1254:tensor<[1, 16, 680, 80], Float32, CPU>) -> ()
        addr:0x000000000006a7 prog.kernel_launch(%1255:tensor<[1, 680, 16, 80], Float32, CPU>) -> (%1255:tensor<[680, 1280], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,1280]}]
        addr:0x000000000006a8 prog.kernel_launch(%1255:tensor<[680, 1280], Float32, CPU>) -> (%1256:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.31.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000006a9 prog.free(%1255:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000006aa prog.ret
        addr:0x000000000006ab prog.label[symbol:visual.blocks.31.mlp.__entry]
        addr:0x000000000006ac prog.kernel_launch(%1258:tensor<[680, 1280], Float32, CPU>) -> (%1259:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.31.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000006ad prog.free(%1258:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000006ae prog.kernel_launch(%1259:tensor<[680, 5120], Float32, CPU>) -> (%1260:tensor<[680, 5120], Float32, CPU>)[symbol_name:visual.blocks.31.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000006af prog.free(%1259:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000006b0 prog.kernel_launch(%1260:tensor<[680, 5120], Float32, CPU>) -> (%1261:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.blocks.31.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000006b1 prog.free(%1260:tensor<[680, 5120], Float32, CPU>) -> ()
        addr:0x000000000006b2 prog.ret
        addr:0x000000000006b3 prog.label[symbol:visual.merger.__entry]
        addr:0x000000000006b4 prog.kernel_launch(%1262:tensor<[680, 1280], Float32, CPU>) -> (%1263:tensor<[680, 1280], Float32, CPU>)[symbol_name:visual.merger.ln_q, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000006b5 prog.free(%1262:tensor<[680, 1280], Float32, CPU>) -> ()
        addr:0x000000000006b6 prog.kernel_launch(%1263:tensor<[680, 1280], Float32, CPU>) -> (%1263:tensor<[170, 5120], Float32, CPU>)[op_type:View, op_options:{"to_shape":[-1,5120]}]
        addr:0x000000000006b7 prog.kernel_launch(%1263:tensor<[170, 5120], Float32, CPU>) -> (%1264:tensor<[170, 5120], Float32, CPU>)[symbol_name:visual.merger.mlp.0, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":5120}]
        addr:0x000000000006b8 prog.free(%1263:tensor<[170, 5120], Float32, CPU>) -> ()
        addr:0x000000000006b9 prog.kernel_launch(%1264:tensor<[170, 5120], Float32, CPU>) -> (%1265:tensor<[170, 5120], Float32, CPU>)[symbol_name:visual.merger.mlp.gelu, op_type:GELU, op_options:null]
        addr:0x000000000006ba prog.free(%1264:tensor<[170, 5120], Float32, CPU>) -> ()
        addr:0x000000000006bb prog.kernel_launch(%1265:tensor<[170, 5120], Float32, CPU>) -> (%1266:tensor<[170, 1536], Float32, CPU>)[symbol_name:visual.merger.mlp.2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1536}]
        addr:0x000000000006bc prog.free(%1265:tensor<[170, 5120], Float32, CPU>) -> ()
        addr:0x000000000006bd prog.ret
    }
    prog.fragment @__MLLM_JIT_PACKAGE_SYMBOL_TABLE_SEGMENT <CPU> <table> {
        addr:0x00000000000000 prog.value_symbol() -> (%499:tensor<[1505280], Float32, CPU>[@visual.patch_embed.proj.weight])[symbol:visual.patch_embed.proj.weight]
        addr:0x00000000000001 prog.value_symbol() -> (%338:tensor<[1280], Float32, CPU>[@visual.blocks.0.norm1.weight])[symbol:visual.blocks.0.norm1.weight]
        addr:0x00000000000002 prog.value_symbol() -> (%540:tensor<[1280], Float32, CPU>[@visual.blocks.0.norm1.bias])[symbol:visual.blocks.0.norm1.bias]
        addr:0x00000000000003 prog.value_symbol() -> (%315:tensor<[2795520], UInt8, CPU>[@visual.blocks.0.attn.qkv.weight])[symbol:visual.blocks.0.attn.qkv.weight]
        addr:0x00000000000004 prog.value_symbol() -> (%112:tensor<[931840], UInt8, CPU>[@visual.blocks.0.attn.proj.weight])[symbol:visual.blocks.0.attn.proj.weight]
        addr:0x00000000000005 prog.value_symbol() -> (%313:tensor<[1280], Float32, CPU>[@visual.blocks.0.norm2.weight])[symbol:visual.blocks.0.norm2.weight]
        addr:0x00000000000006 prog.value_symbol() -> (%527:tensor<[1280], Float32, CPU>[@visual.blocks.0.norm2.bias])[symbol:visual.blocks.0.norm2.bias]
        addr:0x00000000000007 prog.value_symbol() -> (%89:tensor<[3727360], UInt8, CPU>[@visual.blocks.0.mlp.fc1.weight])[symbol:visual.blocks.0.mlp.fc1.weight]
        addr:0x00000000000008 prog.value_symbol() -> (%59:tensor<[3696640], UInt8, CPU>[@visual.blocks.0.mlp.fc2.weight])[symbol:visual.blocks.0.mlp.fc2.weight]
        addr:0x00000000000009 prog.value_symbol() -> (%509:tensor<[1280], Float32, CPU>[@visual.blocks.1.norm1.weight])[symbol:visual.blocks.1.norm1.weight]
        addr:0x0000000000000a prog.value_symbol() -> (%311:tensor<[1280], Float32, CPU>[@visual.blocks.1.norm1.bias])[symbol:visual.blocks.1.norm1.bias]
        addr:0x0000000000000b prog.value_symbol() -> (%108:tensor<[2795520], UInt8, CPU>[@visual.blocks.1.attn.qkv.weight])[symbol:visual.blocks.1.attn.qkv.weight]
        addr:0x0000000000000c prog.value_symbol() -> (%117:tensor<[931840], UInt8, CPU>[@visual.blocks.1.attn.proj.weight])[symbol:visual.blocks.1.attn.proj.weight]
        addr:0x0000000000000d prog.value_symbol() -> (%310:tensor<[1280], Float32, CPU>[@visual.blocks.1.norm2.weight])[symbol:visual.blocks.1.norm2.weight]
        addr:0x0000000000000e prog.value_symbol() -> (%351:tensor<[1280], Float32, CPU>[@visual.blocks.1.norm2.bias])[symbol:visual.blocks.1.norm2.bias]
        addr:0x0000000000000f prog.value_symbol() -> (%77:tensor<[3727360], UInt8, CPU>[@visual.blocks.1.mlp.fc1.weight])[symbol:visual.blocks.1.mlp.fc1.weight]
        addr:0x00000000000010 prog.value_symbol() -> (%74:tensor<[3696640], UInt8, CPU>[@visual.blocks.1.mlp.fc2.weight])[symbol:visual.blocks.1.mlp.fc2.weight]
        addr:0x00000000000011 prog.value_symbol() -> (%364:tensor<[1280], Float32, CPU>[@visual.blocks.2.norm1.weight])[symbol:visual.blocks.2.norm1.weight]
        addr:0x00000000000012 prog.value_symbol() -> (%505:tensor<[1280], Float32, CPU>[@visual.blocks.2.norm1.bias])[symbol:visual.blocks.2.norm1.bias]
        addr:0x00000000000013 prog.value_symbol() -> (%101:tensor<[2795520], UInt8, CPU>[@visual.blocks.2.attn.qkv.weight])[symbol:visual.blocks.2.attn.qkv.weight]
        addr:0x00000000000014 prog.value_symbol() -> (%361:tensor<[931840], UInt8, CPU>[@visual.blocks.2.attn.proj.weight])[symbol:visual.blocks.2.attn.proj.weight]
        addr:0x00000000000015 prog.value_symbol() -> (%257:tensor<[1280], Float32, CPU>[@visual.blocks.2.norm2.weight])[symbol:visual.blocks.2.norm2.weight]
        addr:0x00000000000016 prog.value_symbol() -> (%538:tensor<[1280], Float32, CPU>[@visual.blocks.2.norm2.bias])[symbol:visual.blocks.2.norm2.bias]
        addr:0x00000000000017 prog.value_symbol() -> (%453:tensor<[3727360], UInt8, CPU>[@visual.blocks.2.mlp.fc1.weight])[symbol:visual.blocks.2.mlp.fc1.weight]
        addr:0x00000000000018 prog.value_symbol() -> (%62:tensor<[3696640], UInt8, CPU>[@visual.blocks.2.mlp.fc2.weight])[symbol:visual.blocks.2.mlp.fc2.weight]
        addr:0x00000000000019 prog.value_symbol() -> (%221:tensor<[1280], Float32, CPU>[@visual.blocks.3.norm1.weight])[symbol:visual.blocks.3.norm1.weight]
        addr:0x0000000000001a prog.value_symbol() -> (%488:tensor<[1280], Float32, CPU>[@visual.blocks.3.norm1.bias])[symbol:visual.blocks.3.norm1.bias]
        addr:0x0000000000001b prog.value_symbol() -> (%222:tensor<[2795520], UInt8, CPU>[@visual.blocks.3.attn.qkv.weight])[symbol:visual.blocks.3.attn.qkv.weight]
        addr:0x0000000000001c prog.value_symbol() -> (%269:tensor<[931840], UInt8, CPU>[@visual.blocks.3.attn.proj.weight])[symbol:visual.blocks.3.attn.proj.weight]
        addr:0x0000000000001d prog.value_symbol() -> (%542:tensor<[1280], Float32, CPU>[@visual.blocks.3.norm2.weight])[symbol:visual.blocks.3.norm2.weight]
        addr:0x0000000000001e prog.value_symbol() -> (%424:tensor<[1280], Float32, CPU>[@visual.blocks.3.norm2.bias])[symbol:visual.blocks.3.norm2.bias]
        addr:0x0000000000001f prog.value_symbol() -> (%82:tensor<[3727360], UInt8, CPU>[@visual.blocks.3.mlp.fc1.weight])[symbol:visual.blocks.3.mlp.fc1.weight]
        addr:0x00000000000020 prog.value_symbol() -> (%562:tensor<[3696640], UInt8, CPU>[@visual.blocks.3.mlp.fc2.weight])[symbol:visual.blocks.3.mlp.fc2.weight]
        addr:0x00000000000021 prog.value_symbol() -> (%482:tensor<[1280], Float32, CPU>[@visual.blocks.4.norm1.weight])[symbol:visual.blocks.4.norm1.weight]
        addr:0x00000000000022 prog.value_symbol() -> (%215:tensor<[1280], Float32, CPU>[@visual.blocks.4.norm1.bias])[symbol:visual.blocks.4.norm1.bias]
        addr:0x00000000000023 prog.value_symbol() -> (%103:tensor<[2795520], UInt8, CPU>[@visual.blocks.4.attn.qkv.weight])[symbol:visual.blocks.4.attn.qkv.weight]
        addr:0x00000000000024 prog.value_symbol() -> (%320:tensor<[931840], UInt8, CPU>[@visual.blocks.4.attn.proj.weight])[symbol:visual.blocks.4.attn.proj.weight]
        addr:0x00000000000025 prog.value_symbol() -> (%213:tensor<[1280], Float32, CPU>[@visual.blocks.4.norm2.weight])[symbol:visual.blocks.4.norm2.weight]
        addr:0x00000000000026 prog.value_symbol() -> (%214:tensor<[1280], Float32, CPU>[@visual.blocks.4.norm2.bias])[symbol:visual.blocks.4.norm2.bias]
        addr:0x00000000000027 prog.value_symbol() -> (%476:tensor<[3727360], UInt8, CPU>[@visual.blocks.4.mlp.fc1.weight])[symbol:visual.blocks.4.mlp.fc1.weight]
        addr:0x00000000000028 prog.value_symbol() -> (%559:tensor<[3696640], UInt8, CPU>[@visual.blocks.4.mlp.fc2.weight])[symbol:visual.blocks.4.mlp.fc2.weight]
        addr:0x00000000000029 prog.value_symbol() -> (%212:tensor<[1280], Float32, CPU>[@visual.blocks.5.norm1.weight])[symbol:visual.blocks.5.norm1.weight]
        addr:0x0000000000002a prog.value_symbol() -> (%237:tensor<[1280], Float32, CPU>[@visual.blocks.5.norm1.bias])[symbol:visual.blocks.5.norm1.bias]
        addr:0x0000000000002b prog.value_symbol() -> (%111:tensor<[2795520], UInt8, CPU>[@visual.blocks.5.attn.qkv.weight])[symbol:visual.blocks.5.attn.qkv.weight]
        addr:0x0000000000002c prog.value_symbol() -> (%557:tensor<[931840], UInt8, CPU>[@visual.blocks.5.attn.proj.weight])[symbol:visual.blocks.5.attn.proj.weight]
        addr:0x0000000000002d prog.value_symbol() -> (%514:tensor<[1280], Float32, CPU>[@visual.blocks.5.norm2.weight])[symbol:visual.blocks.5.norm2.weight]
        addr:0x0000000000002e prog.value_symbol() -> (%372:tensor<[1280], Float32, CPU>[@visual.blocks.5.norm2.bias])[symbol:visual.blocks.5.norm2.bias]
        addr:0x0000000000002f prog.value_symbol() -> (%92:tensor<[3727360], UInt8, CPU>[@visual.blocks.5.mlp.fc1.weight])[symbol:visual.blocks.5.mlp.fc1.weight]
        addr:0x00000000000030 prog.value_symbol() -> (%522:tensor<[3696640], UInt8, CPU>[@visual.blocks.5.mlp.fc2.weight])[symbol:visual.blocks.5.mlp.fc2.weight]
        addr:0x00000000000031 prog.value_symbol() -> (%369:tensor<[1280], Float32, CPU>[@visual.blocks.6.norm1.weight])[symbol:visual.blocks.6.norm1.weight]
        addr:0x00000000000032 prog.value_symbol() -> (%211:tensor<[1280], Float32, CPU>[@visual.blocks.6.norm1.bias])[symbol:visual.blocks.6.norm1.bias]
        addr:0x00000000000033 prog.value_symbol() -> (%105:tensor<[2795520], UInt8, CPU>[@visual.blocks.6.attn.qkv.weight])[symbol:visual.blocks.6.attn.qkv.weight]
        addr:0x00000000000034 prog.value_symbol() -> (%323:tensor<[931840], UInt8, CPU>[@visual.blocks.6.attn.proj.weight])[symbol:visual.blocks.6.attn.proj.weight]
        addr:0x00000000000035 prog.value_symbol() -> (%529:tensor<[1280], Float32, CPU>[@visual.blocks.6.norm2.weight])[symbol:visual.blocks.6.norm2.weight]
        addr:0x00000000000036 prog.value_symbol() -> (%425:tensor<[1280], Float32, CPU>[@visual.blocks.6.norm2.bias])[symbol:visual.blocks.6.norm2.bias]
        addr:0x00000000000037 prog.value_symbol() -> (%90:tensor<[3727360], UInt8, CPU>[@visual.blocks.6.mlp.fc1.weight])[symbol:visual.blocks.6.mlp.fc1.weight]
        addr:0x00000000000038 prog.value_symbol() -> (%483:tensor<[3696640], UInt8, CPU>[@visual.blocks.6.mlp.fc2.weight])[symbol:visual.blocks.6.mlp.fc2.weight]
        addr:0x00000000000039 prog.value_symbol() -> (%210:tensor<[1280], Float32, CPU>[@visual.blocks.7.norm1.weight])[symbol:visual.blocks.7.norm1.weight]
        addr:0x0000000000003a prog.value_symbol() -> (%258:tensor<[1280], Float32, CPU>[@visual.blocks.7.norm1.bias])[symbol:visual.blocks.7.norm1.bias]
        addr:0x0000000000003b prog.value_symbol() -> (%227:tensor<[2795520], UInt8, CPU>[@visual.blocks.7.attn.qkv.weight])[symbol:visual.blocks.7.attn.qkv.weight]
        addr:0x0000000000003c prog.value_symbol() -> (%123:tensor<[931840], UInt8, CPU>[@visual.blocks.7.attn.proj.weight])[symbol:visual.blocks.7.attn.proj.weight]
        addr:0x0000000000003d prog.value_symbol() -> (%208:tensor<[1280], Float32, CPU>[@visual.blocks.7.norm2.weight])[symbol:visual.blocks.7.norm2.weight]
        addr:0x0000000000003e prog.value_symbol() -> (%209:tensor<[1280], Float32, CPU>[@visual.blocks.7.norm2.bias])[symbol:visual.blocks.7.norm2.bias]
        addr:0x0000000000003f prog.value_symbol() -> (%450:tensor<[3727360], UInt8, CPU>[@visual.blocks.7.mlp.fc1.weight])[symbol:visual.blocks.7.mlp.fc1.weight]
        addr:0x00000000000040 prog.value_symbol() -> (%573:tensor<[3696640], UInt8, CPU>[@visual.blocks.7.mlp.fc2.weight])[symbol:visual.blocks.7.mlp.fc2.weight]
        addr:0x00000000000041 prog.value_symbol() -> (%501:tensor<[1280], Float32, CPU>[@visual.blocks.8.norm1.weight])[symbol:visual.blocks.8.norm1.weight]
        addr:0x00000000000042 prog.value_symbol() -> (%207:tensor<[1280], Float32, CPU>[@visual.blocks.8.norm1.bias])[symbol:visual.blocks.8.norm1.bias]
        addr:0x00000000000043 prog.value_symbol() -> (%431:tensor<[2795520], UInt8, CPU>[@visual.blocks.8.attn.qkv.weight])[symbol:visual.blocks.8.attn.qkv.weight]
        addr:0x00000000000044 prog.value_symbol() -> (%118:tensor<[931840], UInt8, CPU>[@visual.blocks.8.attn.proj.weight])[symbol:visual.blocks.8.attn.proj.weight]
        addr:0x00000000000045 prog.value_symbol() -> (%205:tensor<[1280], Float32, CPU>[@visual.blocks.8.norm2.weight])[symbol:visual.blocks.8.norm2.weight]
        addr:0x00000000000046 prog.value_symbol() -> (%206:tensor<[1280], Float32, CPU>[@visual.blocks.8.norm2.bias])[symbol:visual.blocks.8.norm2.bias]
        addr:0x00000000000047 prog.value_symbol() -> (%94:tensor<[3727360], UInt8, CPU>[@visual.blocks.8.mlp.fc1.weight])[symbol:visual.blocks.8.mlp.fc1.weight]
        addr:0x00000000000048 prog.value_symbol() -> (%72:tensor<[3696640], UInt8, CPU>[@visual.blocks.8.mlp.fc2.weight])[symbol:visual.blocks.8.mlp.fc2.weight]
        addr:0x00000000000049 prog.value_symbol() -> (%486:tensor<[1280], Float32, CPU>[@visual.blocks.9.norm1.weight])[symbol:visual.blocks.9.norm1.weight]
        addr:0x0000000000004a prog.value_symbol() -> (%204:tensor<[1280], Float32, CPU>[@visual.blocks.9.norm1.bias])[symbol:visual.blocks.9.norm1.bias]
        addr:0x0000000000004b prog.value_symbol() -> (%544:tensor<[2795520], UInt8, CPU>[@visual.blocks.9.attn.qkv.weight])[symbol:visual.blocks.9.attn.qkv.weight]
        addr:0x0000000000004c prog.value_symbol() -> (%316:tensor<[931840], UInt8, CPU>[@visual.blocks.9.attn.proj.weight])[symbol:visual.blocks.9.attn.proj.weight]
        addr:0x0000000000004d prog.value_symbol() -> (%513:tensor<[1280], Float32, CPU>[@visual.blocks.9.norm2.weight])[symbol:visual.blocks.9.norm2.weight]
        addr:0x0000000000004e prog.value_symbol() -> (%203:tensor<[1280], Float32, CPU>[@visual.blocks.9.norm2.bias])[symbol:visual.blocks.9.norm2.bias]
        addr:0x0000000000004f prog.value_symbol() -> (%96:tensor<[3727360], UInt8, CPU>[@visual.blocks.9.mlp.fc1.weight])[symbol:visual.blocks.9.mlp.fc1.weight]
        addr:0x00000000000050 prog.value_symbol() -> (%75:tensor<[3696640], UInt8, CPU>[@visual.blocks.9.mlp.fc2.weight])[symbol:visual.blocks.9.mlp.fc2.weight]
        addr:0x00000000000051 prog.value_symbol() -> (%560:tensor<[1280], Float32, CPU>[@visual.blocks.10.norm1.weight])[symbol:visual.blocks.10.norm1.weight]
        addr:0x00000000000052 prog.value_symbol() -> (%308:tensor<[1280], Float32, CPU>[@visual.blocks.10.norm1.bias])[symbol:visual.blocks.10.norm1.bias]
        addr:0x00000000000053 prog.value_symbol() -> (%459:tensor<[2795520], UInt8, CPU>[@visual.blocks.10.attn.qkv.weight])[symbol:visual.blocks.10.attn.qkv.weight]
        addr:0x00000000000054 prog.value_symbol() -> (%346:tensor<[931840], UInt8, CPU>[@visual.blocks.10.attn.proj.weight])[symbol:visual.blocks.10.attn.proj.weight]
        addr:0x00000000000055 prog.value_symbol() -> (%305:tensor<[1280], Float32, CPU>[@visual.blocks.10.norm2.weight])[symbol:visual.blocks.10.norm2.weight]
        addr:0x00000000000056 prog.value_symbol() -> (%427:tensor<[1280], Float32, CPU>[@visual.blocks.10.norm2.bias])[symbol:visual.blocks.10.norm2.bias]
        addr:0x00000000000057 prog.value_symbol() -> (%76:tensor<[3727360], UInt8, CPU>[@visual.blocks.10.mlp.fc1.weight])[symbol:visual.blocks.10.mlp.fc1.weight]
        addr:0x00000000000058 prog.value_symbol() -> (%61:tensor<[3696640], UInt8, CPU>[@visual.blocks.10.mlp.fc2.weight])[symbol:visual.blocks.10.mlp.fc2.weight]
        addr:0x00000000000059 prog.value_symbol() -> (%302:tensor<[1280], Float32, CPU>[@visual.blocks.11.norm1.weight])[symbol:visual.blocks.11.norm1.weight]
        addr:0x0000000000005a prog.value_symbol() -> (%303:tensor<[1280], Float32, CPU>[@visual.blocks.11.norm1.bias])[symbol:visual.blocks.11.norm1.bias]
        addr:0x0000000000005b prog.value_symbol() -> (%523:tensor<[2795520], UInt8, CPU>[@visual.blocks.11.attn.qkv.weight])[symbol:visual.blocks.11.attn.qkv.weight]
        addr:0x0000000000005c prog.value_symbol() -> (%304:tensor<[931840], UInt8, CPU>[@visual.blocks.11.attn.proj.weight])[symbol:visual.blocks.11.attn.proj.weight]
        addr:0x0000000000005d prog.value_symbol() -> (%298:tensor<[1280], Float32, CPU>[@visual.blocks.11.norm2.weight])[symbol:visual.blocks.11.norm2.weight]
        addr:0x0000000000005e prog.value_symbol() -> (%300:tensor<[1280], Float32, CPU>[@visual.blocks.11.norm2.bias])[symbol:visual.blocks.11.norm2.bias]
        addr:0x0000000000005f prog.value_symbol() -> (%79:tensor<[3727360], UInt8, CPU>[@visual.blocks.11.mlp.fc1.weight])[symbol:visual.blocks.11.mlp.fc1.weight]
        addr:0x00000000000060 prog.value_symbol() -> (%71:tensor<[3696640], UInt8, CPU>[@visual.blocks.11.mlp.fc2.weight])[symbol:visual.blocks.11.mlp.fc2.weight]
        addr:0x00000000000061 prog.value_symbol() -> (%312:tensor<[1280], Float32, CPU>[@visual.blocks.12.norm1.weight])[symbol:visual.blocks.12.norm1.weight]
        addr:0x00000000000062 prog.value_symbol() -> (%294:tensor<[1280], Float32, CPU>[@visual.blocks.12.norm1.bias])[symbol:visual.blocks.12.norm1.bias]
        addr:0x00000000000063 prog.value_symbol() -> (%295:tensor<[2795520], UInt8, CPU>[@visual.blocks.12.attn.qkv.weight])[symbol:visual.blocks.12.attn.qkv.weight]
        addr:0x00000000000064 prog.value_symbol() -> (%296:tensor<[931840], UInt8, CPU>[@visual.blocks.12.attn.proj.weight])[symbol:visual.blocks.12.attn.proj.weight]
        addr:0x00000000000065 prog.value_symbol() -> (%293:tensor<[1280], Float32, CPU>[@visual.blocks.12.norm2.weight])[symbol:visual.blocks.12.norm2.weight]
        addr:0x00000000000066 prog.value_symbol() -> (%518:tensor<[1280], Float32, CPU>[@visual.blocks.12.norm2.bias])[symbol:visual.blocks.12.norm2.bias]
        addr:0x00000000000067 prog.value_symbol() -> (%78:tensor<[3727360], UInt8, CPU>[@visual.blocks.12.mlp.fc1.weight])[symbol:visual.blocks.12.mlp.fc1.weight]
        addr:0x00000000000068 prog.value_symbol() -> (%68:tensor<[3696640], UInt8, CPU>[@visual.blocks.12.mlp.fc2.weight])[symbol:visual.blocks.12.mlp.fc2.weight]
        addr:0x00000000000069 prog.value_symbol() -> (%287:tensor<[1280], Float32, CPU>[@visual.blocks.13.norm1.weight])[symbol:visual.blocks.13.norm1.weight]
        addr:0x0000000000006a prog.value_symbol() -> (%289:tensor<[1280], Float32, CPU>[@visual.blocks.13.norm1.bias])[symbol:visual.blocks.13.norm1.bias]
        addr:0x0000000000006b prog.value_symbol() -> (%516:tensor<[2795520], UInt8, CPU>[@visual.blocks.13.attn.qkv.weight])[symbol:visual.blocks.13.attn.qkv.weight]
        addr:0x0000000000006c prog.value_symbol() -> (%115:tensor<[931840], UInt8, CPU>[@visual.blocks.13.attn.proj.weight])[symbol:visual.blocks.13.attn.proj.weight]
        addr:0x0000000000006d prog.value_symbol() -> (%285:tensor<[1280], Float32, CPU>[@visual.blocks.13.norm2.weight])[symbol:visual.blocks.13.norm2.weight]
        addr:0x0000000000006e prog.value_symbol() -> (%286:tensor<[1280], Float32, CPU>[@visual.blocks.13.norm2.bias])[symbol:visual.blocks.13.norm2.bias]
        addr:0x0000000000006f prog.value_symbol() -> (%493:tensor<[3727360], UInt8, CPU>[@visual.blocks.13.mlp.fc1.weight])[symbol:visual.blocks.13.mlp.fc1.weight]
        addr:0x00000000000070 prog.value_symbol() -> (%290:tensor<[3696640], UInt8, CPU>[@visual.blocks.13.mlp.fc2.weight])[symbol:visual.blocks.13.mlp.fc2.weight]
        addr:0x00000000000071 prog.value_symbol() -> (%497:tensor<[1280], Float32, CPU>[@visual.blocks.14.norm1.weight])[symbol:visual.blocks.14.norm1.weight]
        addr:0x00000000000072 prog.value_symbol() -> (%288:tensor<[1280], Float32, CPU>[@visual.blocks.14.norm1.bias])[symbol:visual.blocks.14.norm1.bias]
        addr:0x00000000000073 prog.value_symbol() -> (%110:tensor<[2795520], UInt8, CPU>[@visual.blocks.14.attn.qkv.weight])[symbol:visual.blocks.14.attn.qkv.weight]
        addr:0x00000000000074 prog.value_symbol() -> (%282:tensor<[931840], UInt8, CPU>[@visual.blocks.14.attn.proj.weight])[symbol:visual.blocks.14.attn.proj.weight]
        addr:0x00000000000075 prog.value_symbol() -> (%280:tensor<[1280], Float32, CPU>[@visual.blocks.14.norm2.weight])[symbol:visual.blocks.14.norm2.weight]
        addr:0x00000000000076 prog.value_symbol() -> (%281:tensor<[1280], Float32, CPU>[@visual.blocks.14.norm2.bias])[symbol:visual.blocks.14.norm2.bias]
        addr:0x00000000000077 prog.value_symbol() -> (%80:tensor<[3727360], UInt8, CPU>[@visual.blocks.14.mlp.fc1.weight])[symbol:visual.blocks.14.mlp.fc1.weight]
        addr:0x00000000000078 prog.value_symbol() -> (%73:tensor<[3696640], UInt8, CPU>[@visual.blocks.14.mlp.fc2.weight])[symbol:visual.blocks.14.mlp.fc2.weight]
        addr:0x00000000000079 prog.value_symbol() -> (%274:tensor<[1280], Float32, CPU>[@visual.blocks.15.norm1.weight])[symbol:visual.blocks.15.norm1.weight]
        addr:0x0000000000007a prog.value_symbol() -> (%275:tensor<[1280], Float32, CPU>[@visual.blocks.15.norm1.bias])[symbol:visual.blocks.15.norm1.bias]
        addr:0x0000000000007b prog.value_symbol() -> (%276:tensor<[2795520], UInt8, CPU>[@visual.blocks.15.attn.qkv.weight])[symbol:visual.blocks.15.attn.qkv.weight]
        addr:0x0000000000007c prog.value_symbol() -> (%547:tensor<[931840], UInt8, CPU>[@visual.blocks.15.attn.proj.weight])[symbol:visual.blocks.15.attn.proj.weight]
        addr:0x0000000000007d prog.value_symbol() -> (%496:tensor<[1280], Float32, CPU>[@visual.blocks.15.norm2.weight])[symbol:visual.blocks.15.norm2.weight]
        addr:0x0000000000007e prog.value_symbol() -> (%348:tensor<[1280], Float32, CPU>[@visual.blocks.15.norm2.bias])[symbol:visual.blocks.15.norm2.bias]
        addr:0x0000000000007f prog.value_symbol() -> (%86:tensor<[3727360], UInt8, CPU>[@visual.blocks.15.mlp.fc1.weight])[symbol:visual.blocks.15.mlp.fc1.weight]
        addr:0x00000000000080 prog.value_symbol() -> (%314:tensor<[3696640], UInt8, CPU>[@visual.blocks.15.mlp.fc2.weight])[symbol:visual.blocks.15.mlp.fc2.weight]
        addr:0x00000000000081 prog.value_symbol() -> (%271:tensor<[1280], Float32, CPU>[@visual.blocks.16.norm1.weight])[symbol:visual.blocks.16.norm1.weight]
        addr:0x00000000000082 prog.value_symbol() -> (%272:tensor<[1280], Float32, CPU>[@visual.blocks.16.norm1.bias])[symbol:visual.blocks.16.norm1.bias]
        addr:0x00000000000083 prog.value_symbol() -> (%568:tensor<[2795520], UInt8, CPU>[@visual.blocks.16.attn.qkv.weight])[symbol:visual.blocks.16.attn.qkv.weight]
        addr:0x00000000000084 prog.value_symbol() -> (%273:tensor<[931840], UInt8, CPU>[@visual.blocks.16.attn.proj.weight])[symbol:visual.blocks.16.attn.proj.weight]
        addr:0x00000000000085 prog.value_symbol() -> (%270:tensor<[1280], Float32, CPU>[@visual.blocks.16.norm2.weight])[symbol:visual.blocks.16.norm2.weight]
        addr:0x00000000000086 prog.value_symbol() -> (%284:tensor<[1280], Float32, CPU>[@visual.blocks.16.norm2.bias])[symbol:visual.blocks.16.norm2.bias]
        addr:0x00000000000087 prog.value_symbol() -> (%93:tensor<[3727360], UInt8, CPU>[@visual.blocks.16.mlp.fc1.weight])[symbol:visual.blocks.16.mlp.fc1.weight]
        addr:0x00000000000088 prog.value_symbol() -> (%500:tensor<[3696640], UInt8, CPU>[@visual.blocks.16.mlp.fc2.weight])[symbol:visual.blocks.16.mlp.fc2.weight]
        addr:0x00000000000089 prog.value_symbol() -> (%266:tensor<[1280], Float32, CPU>[@visual.blocks.17.norm1.weight])[symbol:visual.blocks.17.norm1.weight]
        addr:0x0000000000008a prog.value_symbol() -> (%267:tensor<[1280], Float32, CPU>[@visual.blocks.17.norm1.bias])[symbol:visual.blocks.17.norm1.bias]
        addr:0x0000000000008b prog.value_symbol() -> (%100:tensor<[2795520], UInt8, CPU>[@visual.blocks.17.attn.qkv.weight])[symbol:visual.blocks.17.attn.qkv.weight]
        addr:0x0000000000008c prog.value_symbol() -> (%422:tensor<[931840], UInt8, CPU>[@visual.blocks.17.attn.proj.weight])[symbol:visual.blocks.17.attn.proj.weight]
        addr:0x0000000000008d prog.value_symbol() -> (%556:tensor<[1280], Float32, CPU>[@visual.blocks.17.norm2.weight])[symbol:visual.blocks.17.norm2.weight]
        addr:0x0000000000008e prog.value_symbol() -> (%503:tensor<[1280], Float32, CPU>[@visual.blocks.17.norm2.bias])[symbol:visual.blocks.17.norm2.bias]
        addr:0x0000000000008f prog.value_symbol() -> (%268:tensor<[3727360], UInt8, CPU>[@visual.blocks.17.mlp.fc1.weight])[symbol:visual.blocks.17.mlp.fc1.weight]
        addr:0x00000000000090 prog.value_symbol() -> (%69:tensor<[3696640], UInt8, CPU>[@visual.blocks.17.mlp.fc2.weight])[symbol:visual.blocks.17.mlp.fc2.weight]
        addr:0x00000000000091 prog.value_symbol() -> (%265:tensor<[1280], Float32, CPU>[@visual.blocks.18.norm1.weight])[symbol:visual.blocks.18.norm1.weight]
        addr:0x00000000000092 prog.value_symbol() -> (%479:tensor<[1280], Float32, CPU>[@visual.blocks.18.norm1.bias])[symbol:visual.blocks.18.norm1.bias]
        addr:0x00000000000093 prog.value_symbol() -> (%352:tensor<[2795520], UInt8, CPU>[@visual.blocks.18.attn.qkv.weight])[symbol:visual.blocks.18.attn.qkv.weight]
        addr:0x00000000000094 prog.value_symbol() -> (%384:tensor<[931840], UInt8, CPU>[@visual.blocks.18.attn.proj.weight])[symbol:visual.blocks.18.attn.proj.weight]
        addr:0x00000000000095 prog.value_symbol() -> (%264:tensor<[1280], Float32, CPU>[@visual.blocks.18.norm2.weight])[symbol:visual.blocks.18.norm2.weight]
        addr:0x00000000000096 prog.value_symbol() -> (%473:tensor<[1280], Float32, CPU>[@visual.blocks.18.norm2.bias])[symbol:visual.blocks.18.norm2.bias]
        addr:0x00000000000097 prog.value_symbol() -> (%87:tensor<[3727360], UInt8, CPU>[@visual.blocks.18.mlp.fc1.weight])[symbol:visual.blocks.18.mlp.fc1.weight]
        addr:0x00000000000098 prog.value_symbol() -> (%401:tensor<[3696640], UInt8, CPU>[@visual.blocks.18.mlp.fc2.weight])[symbol:visual.blocks.18.mlp.fc2.weight]
        addr:0x00000000000099 prog.value_symbol() -> (%262:tensor<[1280], Float32, CPU>[@visual.blocks.19.norm1.weight])[symbol:visual.blocks.19.norm1.weight]
        addr:0x0000000000009a prog.value_symbol() -> (%407:tensor<[1280], Float32, CPU>[@visual.blocks.19.norm1.bias])[symbol:visual.blocks.19.norm1.bias]
        addr:0x0000000000009b prog.value_symbol() -> (%98:tensor<[2795520], UInt8, CPU>[@visual.blocks.19.attn.qkv.weight])[symbol:visual.blocks.19.attn.qkv.weight]
        addr:0x0000000000009c prog.value_symbol() -> (%113:tensor<[931840], UInt8, CPU>[@visual.blocks.19.attn.proj.weight])[symbol:visual.blocks.19.attn.proj.weight]
        addr:0x0000000000009d prog.value_symbol() -> (%347:tensor<[1280], Float32, CPU>[@visual.blocks.19.norm2.weight])[symbol:visual.blocks.19.norm2.weight]
        addr:0x0000000000009e prog.value_symbol() -> (%259:tensor<[1280], Float32, CPU>[@visual.blocks.19.norm2.bias])[symbol:visual.blocks.19.norm2.bias]
        addr:0x0000000000009f prog.value_symbol() -> (%261:tensor<[3727360], UInt8, CPU>[@visual.blocks.19.mlp.fc1.weight])[symbol:visual.blocks.19.mlp.fc1.weight]
        addr:0x000000000000a0 prog.value_symbol() -> (%260:tensor<[3696640], UInt8, CPU>[@visual.blocks.19.mlp.fc2.weight])[symbol:visual.blocks.19.mlp.fc2.weight]
        addr:0x000000000000a1 prog.value_symbol() -> (%462:tensor<[1280], Float32, CPU>[@visual.blocks.20.norm1.weight])[symbol:visual.blocks.20.norm1.weight]
        addr:0x000000000000a2 prog.value_symbol() -> (%255:tensor<[1280], Float32, CPU>[@visual.blocks.20.norm1.bias])[symbol:visual.blocks.20.norm1.bias]
        addr:0x000000000000a3 prog.value_symbol() -> (%102:tensor<[2795520], UInt8, CPU>[@visual.blocks.20.attn.qkv.weight])[symbol:visual.blocks.20.attn.qkv.weight]
        addr:0x000000000000a4 prog.value_symbol() -> (%468:tensor<[931840], UInt8, CPU>[@visual.blocks.20.attn.proj.weight])[symbol:visual.blocks.20.attn.proj.weight]
        addr:0x000000000000a5 prog.value_symbol() -> (%543:tensor<[1280], Float32, CPU>[@visual.blocks.20.norm2.weight])[symbol:visual.blocks.20.norm2.weight]
        addr:0x000000000000a6 prog.value_symbol() -> (%508:tensor<[1280], Float32, CPU>[@visual.blocks.20.norm2.bias])[symbol:visual.blocks.20.norm2.bias]
        addr:0x000000000000a7 prog.value_symbol() -> (%340:tensor<[3727360], UInt8, CPU>[@visual.blocks.20.mlp.fc1.weight])[symbol:visual.blocks.20.mlp.fc1.weight]
        addr:0x000000000000a8 prog.value_symbol() -> (%397:tensor<[3696640], UInt8, CPU>[@visual.blocks.20.mlp.fc2.weight])[symbol:visual.blocks.20.mlp.fc2.weight]
        addr:0x000000000000a9 prog.value_symbol() -> (%250:tensor<[1280], Float32, CPU>[@visual.blocks.21.norm1.weight])[symbol:visual.blocks.21.norm1.weight]
        addr:0x000000000000aa prog.value_symbol() -> (%515:tensor<[1280], Float32, CPU>[@visual.blocks.21.norm1.bias])[symbol:visual.blocks.21.norm1.bias]
        addr:0x000000000000ab prog.value_symbol() -> (%254:tensor<[2795520], UInt8, CPU>[@visual.blocks.21.attn.qkv.weight])[symbol:visual.blocks.21.attn.qkv.weight]
        addr:0x000000000000ac prog.value_symbol() -> (%114:tensor<[931840], UInt8, CPU>[@visual.blocks.21.attn.proj.weight])[symbol:visual.blocks.21.attn.proj.weight]
        addr:0x000000000000ad prog.value_symbol() -> (%247:tensor<[1280], Float32, CPU>[@visual.blocks.21.norm2.weight])[symbol:visual.blocks.21.norm2.weight]
        addr:0x000000000000ae prog.value_symbol() -> (%248:tensor<[1280], Float32, CPU>[@visual.blocks.21.norm2.bias])[symbol:visual.blocks.21.norm2.bias]
        addr:0x000000000000af prog.value_symbol() -> (%95:tensor<[3727360], UInt8, CPU>[@visual.blocks.21.mlp.fc1.weight])[symbol:visual.blocks.21.mlp.fc1.weight]
        addr:0x000000000000b0 prog.value_symbol() -> (%251:tensor<[3696640], UInt8, CPU>[@visual.blocks.21.mlp.fc2.weight])[symbol:visual.blocks.21.mlp.fc2.weight]
        addr:0x000000000000b1 prog.value_symbol() -> (%277:tensor<[1280], Float32, CPU>[@visual.blocks.22.norm1.weight])[symbol:visual.blocks.22.norm1.weight]
        addr:0x000000000000b2 prog.value_symbol() -> (%246:tensor<[1280], Float32, CPU>[@visual.blocks.22.norm1.bias])[symbol:visual.blocks.22.norm1.bias]
        addr:0x000000000000b3 prog.value_symbol() -> (%252:tensor<[2795520], UInt8, CPU>[@visual.blocks.22.attn.qkv.weight])[symbol:visual.blocks.22.attn.qkv.weight]
        addr:0x000000000000b4 prog.value_symbol() -> (%376:tensor<[931840], UInt8, CPU>[@visual.blocks.22.attn.proj.weight])[symbol:visual.blocks.22.attn.proj.weight]
        addr:0x000000000000b5 prog.value_symbol() -> (%244:tensor<[1280], Float32, CPU>[@visual.blocks.22.norm2.weight])[symbol:visual.blocks.22.norm2.weight]
        addr:0x000000000000b6 prog.value_symbol() -> (%245:tensor<[1280], Float32, CPU>[@visual.blocks.22.norm2.bias])[symbol:visual.blocks.22.norm2.bias]
        addr:0x000000000000b7 prog.value_symbol() -> (%83:tensor<[3727360], UInt8, CPU>[@visual.blocks.22.mlp.fc1.weight])[symbol:visual.blocks.22.mlp.fc1.weight]
        addr:0x000000000000b8 prog.value_symbol() -> (%64:tensor<[3696640], UInt8, CPU>[@visual.blocks.22.mlp.fc2.weight])[symbol:visual.blocks.22.mlp.fc2.weight]
        addr:0x000000000000b9 prog.value_symbol() -> (%511:tensor<[1280], Float32, CPU>[@visual.blocks.23.norm1.weight])[symbol:visual.blocks.23.norm1.weight]
        addr:0x000000000000ba prog.value_symbol() -> (%383:tensor<[1280], Float32, CPU>[@visual.blocks.23.norm1.bias])[symbol:visual.blocks.23.norm1.bias]
        addr:0x000000000000bb prog.value_symbol() -> (%242:tensor<[2795520], UInt8, CPU>[@visual.blocks.23.attn.qkv.weight])[symbol:visual.blocks.23.attn.qkv.weight]
        addr:0x000000000000bc prog.value_symbol() -> (%121:tensor<[931840], UInt8, CPU>[@visual.blocks.23.attn.proj.weight])[symbol:visual.blocks.23.attn.proj.weight]
        addr:0x000000000000bd prog.value_symbol() -> (%392:tensor<[1280], Float32, CPU>[@visual.blocks.23.norm2.weight])[symbol:visual.blocks.23.norm2.weight]
        addr:0x000000000000be prog.value_symbol() -> (%394:tensor<[1280], Float32, CPU>[@visual.blocks.23.norm2.bias])[symbol:visual.blocks.23.norm2.bias]
        addr:0x000000000000bf prog.value_symbol() -> (%84:tensor<[3727360], UInt8, CPU>[@visual.blocks.23.mlp.fc1.weight])[symbol:visual.blocks.23.mlp.fc1.weight]
        addr:0x000000000000c0 prog.value_symbol() -> (%66:tensor<[3696640], UInt8, CPU>[@visual.blocks.23.mlp.fc2.weight])[symbol:visual.blocks.23.mlp.fc2.weight]
        addr:0x000000000000c1 prog.value_symbol() -> (%240:tensor<[1280], Float32, CPU>[@visual.blocks.24.norm1.weight])[symbol:visual.blocks.24.norm1.weight]
        addr:0x000000000000c2 prog.value_symbol() -> (%241:tensor<[1280], Float32, CPU>[@visual.blocks.24.norm1.bias])[symbol:visual.blocks.24.norm1.bias]
        addr:0x000000000000c3 prog.value_symbol() -> (%104:tensor<[2795520], UInt8, CPU>[@visual.blocks.24.attn.qkv.weight])[symbol:visual.blocks.24.attn.qkv.weight]
        addr:0x000000000000c4 prog.value_symbol() -> (%119:tensor<[931840], UInt8, CPU>[@visual.blocks.24.attn.proj.weight])[symbol:visual.blocks.24.attn.proj.weight]
        addr:0x000000000000c5 prog.value_symbol() -> (%238:tensor<[1280], Float32, CPU>[@visual.blocks.24.norm2.weight])[symbol:visual.blocks.24.norm2.weight]
        addr:0x000000000000c6 prog.value_symbol() -> (%239:tensor<[1280], Float32, CPU>[@visual.blocks.24.norm2.bias])[symbol:visual.blocks.24.norm2.bias]
        addr:0x000000000000c7 prog.value_symbol() -> (%563:tensor<[3727360], UInt8, CPU>[@visual.blocks.24.mlp.fc1.weight])[symbol:visual.blocks.24.mlp.fc1.weight]
        addr:0x000000000000c8 prog.value_symbol() -> (%70:tensor<[3696640], UInt8, CPU>[@visual.blocks.24.mlp.fc2.weight])[symbol:visual.blocks.24.mlp.fc2.weight]
        addr:0x000000000000c9 prog.value_symbol() -> (%234:tensor<[1280], Float32, CPU>[@visual.blocks.25.norm1.weight])[symbol:visual.blocks.25.norm1.weight]
        addr:0x000000000000ca prog.value_symbol() -> (%235:tensor<[1280], Float32, CPU>[@visual.blocks.25.norm1.bias])[symbol:visual.blocks.25.norm1.bias]
        addr:0x000000000000cb prog.value_symbol() -> (%97:tensor<[2795520], UInt8, CPU>[@visual.blocks.25.attn.qkv.weight])[symbol:visual.blocks.25.attn.qkv.weight]
        addr:0x000000000000cc prog.value_symbol() -> (%353:tensor<[931840], UInt8, CPU>[@visual.blocks.25.attn.proj.weight])[symbol:visual.blocks.25.attn.proj.weight]
        addr:0x000000000000cd prog.value_symbol() -> (%232:tensor<[1280], Float32, CPU>[@visual.blocks.25.norm2.weight])[symbol:visual.blocks.25.norm2.weight]
        addr:0x000000000000ce prog.value_symbol() -> (%233:tensor<[1280], Float32, CPU>[@visual.blocks.25.norm2.bias])[symbol:visual.blocks.25.norm2.bias]
        addr:0x000000000000cf prog.value_symbol() -> (%236:tensor<[3727360], UInt8, CPU>[@visual.blocks.25.mlp.fc1.weight])[symbol:visual.blocks.25.mlp.fc1.weight]
        addr:0x000000000000d0 prog.value_symbol() -> (%67:tensor<[3696640], UInt8, CPU>[@visual.blocks.25.mlp.fc2.weight])[symbol:visual.blocks.25.mlp.fc2.weight]
        addr:0x000000000000d1 prog.value_symbol() -> (%231:tensor<[1280], Float32, CPU>[@visual.blocks.26.norm1.weight])[symbol:visual.blocks.26.norm1.weight]
        addr:0x000000000000d2 prog.value_symbol() -> (%256:tensor<[1280], Float32, CPU>[@visual.blocks.26.norm1.bias])[symbol:visual.blocks.26.norm1.bias]
        addr:0x000000000000d3 prog.value_symbol() -> (%106:tensor<[2795520], UInt8, CPU>[@visual.blocks.26.attn.qkv.weight])[symbol:visual.blocks.26.attn.qkv.weight]
        addr:0x000000000000d4 prog.value_symbol() -> (%116:tensor<[931840], UInt8, CPU>[@visual.blocks.26.attn.proj.weight])[symbol:visual.blocks.26.attn.proj.weight]
        addr:0x000000000000d5 prog.value_symbol() -> (%230:tensor<[1280], Float32, CPU>[@visual.blocks.26.norm2.weight])[symbol:visual.blocks.26.norm2.weight]
        addr:0x000000000000d6 prog.value_symbol() -> (%283:tensor<[1280], Float32, CPU>[@visual.blocks.26.norm2.bias])[symbol:visual.blocks.26.norm2.bias]
        addr:0x000000000000d7 prog.value_symbol() -> (%81:tensor<[3727360], UInt8, CPU>[@visual.blocks.26.mlp.fc1.weight])[symbol:visual.blocks.26.mlp.fc1.weight]
        addr:0x000000000000d8 prog.value_symbol() -> (%63:tensor<[3696640], UInt8, CPU>[@visual.blocks.26.mlp.fc2.weight])[symbol:visual.blocks.26.mlp.fc2.weight]
        addr:0x000000000000d9 prog.value_symbol() -> (%291:tensor<[1280], Float32, CPU>[@visual.blocks.27.norm1.weight])[symbol:visual.blocks.27.norm1.weight]
        addr:0x000000000000da prog.value_symbol() -> (%292:tensor<[1280], Float32, CPU>[@visual.blocks.27.norm1.bias])[symbol:visual.blocks.27.norm1.bias]
        addr:0x000000000000db prog.value_symbol() -> (%107:tensor<[2795520], UInt8, CPU>[@visual.blocks.27.attn.qkv.weight])[symbol:visual.blocks.27.attn.qkv.weight]
        addr:0x000000000000dc prog.value_symbol() -> (%448:tensor<[931840], UInt8, CPU>[@visual.blocks.27.attn.proj.weight])[symbol:visual.blocks.27.attn.proj.weight]
        addr:0x000000000000dd prog.value_symbol() -> (%228:tensor<[1280], Float32, CPU>[@visual.blocks.27.norm2.weight])[symbol:visual.blocks.27.norm2.weight]
        addr:0x000000000000de prog.value_symbol() -> (%229:tensor<[1280], Float32, CPU>[@visual.blocks.27.norm2.bias])[symbol:visual.blocks.27.norm2.bias]
        addr:0x000000000000df prog.value_symbol() -> (%85:tensor<[3727360], UInt8, CPU>[@visual.blocks.27.mlp.fc1.weight])[symbol:visual.blocks.27.mlp.fc1.weight]
        addr:0x000000000000e0 prog.value_symbol() -> (%60:tensor<[3696640], UInt8, CPU>[@visual.blocks.27.mlp.fc2.weight])[symbol:visual.blocks.27.mlp.fc2.weight]
        addr:0x000000000000e1 prog.value_symbol() -> (%225:tensor<[1280], Float32, CPU>[@visual.blocks.28.norm1.weight])[symbol:visual.blocks.28.norm1.weight]
        addr:0x000000000000e2 prog.value_symbol() -> (%226:tensor<[1280], Float32, CPU>[@visual.blocks.28.norm1.bias])[symbol:visual.blocks.28.norm1.bias]
        addr:0x000000000000e3 prog.value_symbol() -> (%552:tensor<[2795520], UInt8, CPU>[@visual.blocks.28.attn.qkv.weight])[symbol:visual.blocks.28.attn.qkv.weight]
        addr:0x000000000000e4 prog.value_symbol() -> (%120:tensor<[931840], UInt8, CPU>[@visual.blocks.28.attn.proj.weight])[symbol:visual.blocks.28.attn.proj.weight]
        addr:0x000000000000e5 prog.value_symbol() -> (%224:tensor<[1280], Float32, CPU>[@visual.blocks.28.norm2.weight])[symbol:visual.blocks.28.norm2.weight]
        addr:0x000000000000e6 prog.value_symbol() -> (%472:tensor<[1280], Float32, CPU>[@visual.blocks.28.norm2.bias])[symbol:visual.blocks.28.norm2.bias]
        addr:0x000000000000e7 prog.value_symbol() -> (%88:tensor<[3727360], UInt8, CPU>[@visual.blocks.28.mlp.fc1.weight])[symbol:visual.blocks.28.mlp.fc1.weight]
        addr:0x000000000000e8 prog.value_symbol() -> (%365:tensor<[3696640], UInt8, CPU>[@visual.blocks.28.mlp.fc2.weight])[symbol:visual.blocks.28.mlp.fc2.weight]
        addr:0x000000000000e9 prog.value_symbol() -> (%243:tensor<[1280], Float32, CPU>[@visual.blocks.29.norm1.weight])[symbol:visual.blocks.29.norm1.weight]
        addr:0x000000000000ea prog.value_symbol() -> (%535:tensor<[1280], Float32, CPU>[@visual.blocks.29.norm1.bias])[symbol:visual.blocks.29.norm1.bias]
        addr:0x000000000000eb prog.value_symbol() -> (%441:tensor<[2795520], UInt8, CPU>[@visual.blocks.29.attn.qkv.weight])[symbol:visual.blocks.29.attn.qkv.weight]
        addr:0x000000000000ec prog.value_symbol() -> (%403:tensor<[931840], UInt8, CPU>[@visual.blocks.29.attn.proj.weight])[symbol:visual.blocks.29.attn.proj.weight]
        addr:0x000000000000ed prog.value_symbol() -> (%223:tensor<[1280], Float32, CPU>[@visual.blocks.29.norm2.weight])[symbol:visual.blocks.29.norm2.weight]
        addr:0x000000000000ee prog.value_symbol() -> (%279:tensor<[1280], Float32, CPU>[@visual.blocks.29.norm2.bias])[symbol:visual.blocks.29.norm2.bias]
        addr:0x000000000000ef prog.value_symbol() -> (%91:tensor<[3727360], UInt8, CPU>[@visual.blocks.29.mlp.fc1.weight])[symbol:visual.blocks.29.mlp.fc1.weight]
        addr:0x000000000000f0 prog.value_symbol() -> (%249:tensor<[3696640], UInt8, CPU>[@visual.blocks.29.mlp.fc2.weight])[symbol:visual.blocks.29.mlp.fc2.weight]
        addr:0x000000000000f1 prog.value_symbol() -> (%220:tensor<[1280], Float32, CPU>[@visual.blocks.30.norm1.weight])[symbol:visual.blocks.30.norm1.weight]
        addr:0x000000000000f2 prog.value_symbol() -> (%507:tensor<[1280], Float32, CPU>[@visual.blocks.30.norm1.bias])[symbol:visual.blocks.30.norm1.bias]
        addr:0x000000000000f3 prog.value_symbol() -> (%109:tensor<[2795520], UInt8, CPU>[@visual.blocks.30.attn.qkv.weight])[symbol:visual.blocks.30.attn.qkv.weight]
        addr:0x000000000000f4 prog.value_symbol() -> (%278:tensor<[931840], UInt8, CPU>[@visual.blocks.30.attn.proj.weight])[symbol:visual.blocks.30.attn.proj.weight]
        addr:0x000000000000f5 prog.value_symbol() -> (%218:tensor<[1280], Float32, CPU>[@visual.blocks.30.norm2.weight])[symbol:visual.blocks.30.norm2.weight]
        addr:0x000000000000f6 prog.value_symbol() -> (%219:tensor<[1280], Float32, CPU>[@visual.blocks.30.norm2.bias])[symbol:visual.blocks.30.norm2.bias]
        addr:0x000000000000f7 prog.value_symbol() -> (%443:tensor<[3727360], UInt8, CPU>[@visual.blocks.30.mlp.fc1.weight])[symbol:visual.blocks.30.mlp.fc1.weight]
        addr:0x000000000000f8 prog.value_symbol() -> (%65:tensor<[3696640], UInt8, CPU>[@visual.blocks.30.mlp.fc2.weight])[symbol:visual.blocks.30.mlp.fc2.weight]
        addr:0x000000000000f9 prog.value_symbol() -> (%551:tensor<[1280], Float32, CPU>[@visual.blocks.31.norm1.weight])[symbol:visual.blocks.31.norm1.weight]
        addr:0x000000000000fa prog.value_symbol() -> (%217:tensor<[1280], Float32, CPU>[@visual.blocks.31.norm1.bias])[symbol:visual.blocks.31.norm1.bias]
        addr:0x000000000000fb prog.value_symbol() -> (%99:tensor<[2795520], UInt8, CPU>[@visual.blocks.31.attn.qkv.weight])[symbol:visual.blocks.31.attn.qkv.weight]
        addr:0x000000000000fc prog.value_symbol() -> (%122:tensor<[931840], UInt8, CPU>[@visual.blocks.31.attn.proj.weight])[symbol:visual.blocks.31.attn.proj.weight]
        addr:0x000000000000fd prog.value_symbol() -> (%216:tensor<[1280], Float32, CPU>[@visual.blocks.31.norm2.weight])[symbol:visual.blocks.31.norm2.weight]
        addr:0x000000000000fe prog.value_symbol() -> (%567:tensor<[1280], Float32, CPU>[@visual.blocks.31.norm2.bias])[symbol:visual.blocks.31.norm2.bias]
        addr:0x000000000000ff prog.value_symbol() -> (%263:tensor<[3727360], UInt8, CPU>[@visual.blocks.31.mlp.fc1.weight])[symbol:visual.blocks.31.mlp.fc1.weight]
        addr:0x00000000000100 prog.value_symbol() -> (%306:tensor<[3696640], UInt8, CPU>[@visual.blocks.31.mlp.fc2.weight])[symbol:visual.blocks.31.mlp.fc2.weight]
        addr:0x00000000000101 prog.value_symbol() -> (%202:tensor<[1280], Float32, CPU>[@visual.merger.ln_q.weight])[symbol:visual.merger.ln_q.weight]
        addr:0x00000000000102 prog.value_symbol() -> (%465:tensor<[1280], Float32, CPU>[@visual.merger.ln_q.bias])[symbol:visual.merger.ln_q.bias]
        addr:0x00000000000103 prog.value_symbol() -> (%490:tensor<[14786560], UInt8, CPU>[@visual.merger.mlp.0.weight])[symbol:visual.merger.mlp.0.weight]
        addr:0x00000000000104 prog.value_symbol() -> (%253:tensor<[4435968], UInt8, CPU>[@visual.merger.mlp.2.weight])[symbol:visual.merger.mlp.2.weight]
        addr:0x00000000000105 prog.value_symbol() -> (%705:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_705]
        addr:0x00000000000106 prog.value_symbol() -> (%747:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_747]
        addr:0x00000000000107 prog.value_symbol() -> (%768:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_768]
        addr:0x00000000000108 prog.value_symbol() -> (%915:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_915]
        addr:0x00000000000109 prog.value_symbol() -> (%999:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_999]
        addr:0x0000000000010a prog.value_symbol() -> (%1125:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1125]
        addr:0x0000000000010b prog.value_symbol() -> (%1167:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1167]
        addr:0x0000000000010c prog.value_symbol() -> (%1188:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1188]
        addr:0x0000000000010d prog.value_symbol() -> (%600:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_600]
        addr:0x0000000000010e prog.value_symbol() -> (%621:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_621]
        addr:0x0000000000010f prog.value_symbol() -> (%663:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_663]
        addr:0x00000000000110 prog.value_symbol() -> (%684:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_684]
        addr:0x00000000000111 prog.value_symbol() -> (%789:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_789]
        addr:0x00000000000112 prog.value_symbol() -> (%1020:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1020]
        addr:0x00000000000113 prog.value_symbol() -> (%1041:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1041]
        addr:0x00000000000114 prog.value_symbol() -> (%1083:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1083]
        addr:0x00000000000115 prog.value_symbol() -> (%1251:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1251]
        addr:0x00000000000116 prog.value_symbol() -> (%642:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_642]
        addr:0x00000000000117 prog.value_symbol() -> (%894:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_894]
        addr:0x00000000000118 prog.value_symbol() -> (%957:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_957]
        addr:0x00000000000119 prog.value_symbol() -> (%726:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_726]
        addr:0x0000000000011a prog.value_symbol() -> (%810:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_810]
        addr:0x0000000000011b prog.value_symbol() -> (%831:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_831]
        addr:0x0000000000011c prog.value_symbol() -> (%852:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_852]
        addr:0x0000000000011d prog.value_symbol() -> (%873:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_873]
        addr:0x0000000000011e prog.value_symbol() -> (%936:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_936]
        addr:0x0000000000011f prog.value_symbol() -> (%978:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_978]
        addr:0x00000000000120 prog.value_symbol() -> (%1062:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1062]
        addr:0x00000000000121 prog.value_symbol() -> (%1104:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1104]
        addr:0x00000000000122 prog.value_symbol() -> (%1146:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1146]
        addr:0x00000000000123 prog.value_symbol() -> (%1209:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1209]
        addr:0x00000000000124 prog.value_symbol() -> (%1230:tensor<[1], Float32, CPU>[constant: [0.1118034]])[symbol:constant_1230]
        addr:0x00000000000125 prog.kernel_symbol[symbol:visual.patch_embed.proj, op_type:Conv3D, op_options:{"bias":false,"impl_type":"Default","in_channels":3,"kernel_size":[2,14,14],"out_channels":1280,"stride":[2,14,14]}]
        addr:0x00000000000126 prog.kernel_symbol[symbol:visual.blocks.0.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000127 prog.kernel_symbol[symbol:visual.blocks.0.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000128 prog.kernel_symbol[symbol:visual.blocks.0.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000129 prog.kernel_symbol[symbol:visual.blocks.0.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000012a prog.kernel_symbol[symbol:visual.blocks.0.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000012b prog.kernel_symbol[symbol:visual.blocks.0.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000012c prog.kernel_symbol[symbol:visual.blocks.0.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000012d prog.kernel_symbol[symbol:visual.blocks.0.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000012e prog.kernel_symbol[symbol:visual.blocks.0.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000012f prog.kernel_symbol[symbol:visual.blocks.0.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000130 prog.kernel_symbol[symbol:visual.blocks.1.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000131 prog.kernel_symbol[symbol:visual.blocks.1.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000132 prog.kernel_symbol[symbol:visual.blocks.1.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000133 prog.kernel_symbol[symbol:visual.blocks.1.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000134 prog.kernel_symbol[symbol:visual.blocks.1.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000135 prog.kernel_symbol[symbol:visual.blocks.1.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000136 prog.kernel_symbol[symbol:visual.blocks.1.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000137 prog.kernel_symbol[symbol:visual.blocks.1.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000138 prog.kernel_symbol[symbol:visual.blocks.1.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000139 prog.kernel_symbol[symbol:visual.blocks.1.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000013a prog.kernel_symbol[symbol:visual.blocks.2.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000013b prog.kernel_symbol[symbol:visual.blocks.2.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000013c prog.kernel_symbol[symbol:visual.blocks.2.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000013d prog.kernel_symbol[symbol:visual.blocks.2.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000013e prog.kernel_symbol[symbol:visual.blocks.2.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000013f prog.kernel_symbol[symbol:visual.blocks.2.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000140 prog.kernel_symbol[symbol:visual.blocks.2.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000141 prog.kernel_symbol[symbol:visual.blocks.2.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000142 prog.kernel_symbol[symbol:visual.blocks.2.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000143 prog.kernel_symbol[symbol:visual.blocks.2.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000144 prog.kernel_symbol[symbol:visual.blocks.3.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000145 prog.kernel_symbol[symbol:visual.blocks.3.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000146 prog.kernel_symbol[symbol:visual.blocks.3.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000147 prog.kernel_symbol[symbol:visual.blocks.3.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000148 prog.kernel_symbol[symbol:visual.blocks.3.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000149 prog.kernel_symbol[symbol:visual.blocks.3.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000014a prog.kernel_symbol[symbol:visual.blocks.3.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000014b prog.kernel_symbol[symbol:visual.blocks.3.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000014c prog.kernel_symbol[symbol:visual.blocks.3.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000014d prog.kernel_symbol[symbol:visual.blocks.3.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000014e prog.kernel_symbol[symbol:visual.blocks.4.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000014f prog.kernel_symbol[symbol:visual.blocks.4.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000150 prog.kernel_symbol[symbol:visual.blocks.4.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000151 prog.kernel_symbol[symbol:visual.blocks.4.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000152 prog.kernel_symbol[symbol:visual.blocks.4.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000153 prog.kernel_symbol[symbol:visual.blocks.4.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000154 prog.kernel_symbol[symbol:visual.blocks.4.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000155 prog.kernel_symbol[symbol:visual.blocks.4.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000156 prog.kernel_symbol[symbol:visual.blocks.4.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000157 prog.kernel_symbol[symbol:visual.blocks.4.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000158 prog.kernel_symbol[symbol:visual.blocks.5.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000159 prog.kernel_symbol[symbol:visual.blocks.5.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000015a prog.kernel_symbol[symbol:visual.blocks.5.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000015b prog.kernel_symbol[symbol:visual.blocks.5.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000015c prog.kernel_symbol[symbol:visual.blocks.5.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000015d prog.kernel_symbol[symbol:visual.blocks.5.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000015e prog.kernel_symbol[symbol:visual.blocks.5.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000015f prog.kernel_symbol[symbol:visual.blocks.5.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000160 prog.kernel_symbol[symbol:visual.blocks.5.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000161 prog.kernel_symbol[symbol:visual.blocks.5.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000162 prog.kernel_symbol[symbol:visual.blocks.6.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000163 prog.kernel_symbol[symbol:visual.blocks.6.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000164 prog.kernel_symbol[symbol:visual.blocks.6.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000165 prog.kernel_symbol[symbol:visual.blocks.6.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000166 prog.kernel_symbol[symbol:visual.blocks.6.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000167 prog.kernel_symbol[symbol:visual.blocks.6.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000168 prog.kernel_symbol[symbol:visual.blocks.6.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000169 prog.kernel_symbol[symbol:visual.blocks.6.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000016a prog.kernel_symbol[symbol:visual.blocks.6.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000016b prog.kernel_symbol[symbol:visual.blocks.6.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000016c prog.kernel_symbol[symbol:visual.blocks.7.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000016d prog.kernel_symbol[symbol:visual.blocks.7.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000016e prog.kernel_symbol[symbol:visual.blocks.7.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000016f prog.kernel_symbol[symbol:visual.blocks.7.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000170 prog.kernel_symbol[symbol:visual.blocks.7.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000171 prog.kernel_symbol[symbol:visual.blocks.7.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000172 prog.kernel_symbol[symbol:visual.blocks.7.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000173 prog.kernel_symbol[symbol:visual.blocks.7.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000174 prog.kernel_symbol[symbol:visual.blocks.7.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000175 prog.kernel_symbol[symbol:visual.blocks.7.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000176 prog.kernel_symbol[symbol:visual.blocks.8.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000177 prog.kernel_symbol[symbol:visual.blocks.8.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000178 prog.kernel_symbol[symbol:visual.blocks.8.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000179 prog.kernel_symbol[symbol:visual.blocks.8.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000017a prog.kernel_symbol[symbol:visual.blocks.8.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000017b prog.kernel_symbol[symbol:visual.blocks.8.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000017c prog.kernel_symbol[symbol:visual.blocks.8.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000017d prog.kernel_symbol[symbol:visual.blocks.8.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000017e prog.kernel_symbol[symbol:visual.blocks.8.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000017f prog.kernel_symbol[symbol:visual.blocks.8.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000180 prog.kernel_symbol[symbol:visual.blocks.9.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000181 prog.kernel_symbol[symbol:visual.blocks.9.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000182 prog.kernel_symbol[symbol:visual.blocks.9.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000183 prog.kernel_symbol[symbol:visual.blocks.9.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000184 prog.kernel_symbol[symbol:visual.blocks.9.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000185 prog.kernel_symbol[symbol:visual.blocks.9.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000186 prog.kernel_symbol[symbol:visual.blocks.9.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000187 prog.kernel_symbol[symbol:visual.blocks.9.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000188 prog.kernel_symbol[symbol:visual.blocks.9.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000189 prog.kernel_symbol[symbol:visual.blocks.9.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000018a prog.kernel_symbol[symbol:visual.blocks.10.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000018b prog.kernel_symbol[symbol:visual.blocks.10.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000018c prog.kernel_symbol[symbol:visual.blocks.10.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000018d prog.kernel_symbol[symbol:visual.blocks.10.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000018e prog.kernel_symbol[symbol:visual.blocks.10.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000018f prog.kernel_symbol[symbol:visual.blocks.10.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000190 prog.kernel_symbol[symbol:visual.blocks.10.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000191 prog.kernel_symbol[symbol:visual.blocks.10.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000192 prog.kernel_symbol[symbol:visual.blocks.10.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000193 prog.kernel_symbol[symbol:visual.blocks.10.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000194 prog.kernel_symbol[symbol:visual.blocks.11.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000195 prog.kernel_symbol[symbol:visual.blocks.11.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000196 prog.kernel_symbol[symbol:visual.blocks.11.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000197 prog.kernel_symbol[symbol:visual.blocks.11.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000198 prog.kernel_symbol[symbol:visual.blocks.11.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000199 prog.kernel_symbol[symbol:visual.blocks.11.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000019a prog.kernel_symbol[symbol:visual.blocks.11.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000019b prog.kernel_symbol[symbol:visual.blocks.11.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000019c prog.kernel_symbol[symbol:visual.blocks.11.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000019d prog.kernel_symbol[symbol:visual.blocks.11.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000019e prog.kernel_symbol[symbol:visual.blocks.12.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000019f prog.kernel_symbol[symbol:visual.blocks.12.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001a0 prog.kernel_symbol[symbol:visual.blocks.12.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001a1 prog.kernel_symbol[symbol:visual.blocks.12.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001a2 prog.kernel_symbol[symbol:visual.blocks.12.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001a3 prog.kernel_symbol[symbol:visual.blocks.12.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001a4 prog.kernel_symbol[symbol:visual.blocks.12.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001a5 prog.kernel_symbol[symbol:visual.blocks.12.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001a6 prog.kernel_symbol[symbol:visual.blocks.12.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001a7 prog.kernel_symbol[symbol:visual.blocks.12.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001a8 prog.kernel_symbol[symbol:visual.blocks.13.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001a9 prog.kernel_symbol[symbol:visual.blocks.13.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001aa prog.kernel_symbol[symbol:visual.blocks.13.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001ab prog.kernel_symbol[symbol:visual.blocks.13.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001ac prog.kernel_symbol[symbol:visual.blocks.13.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001ad prog.kernel_symbol[symbol:visual.blocks.13.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001ae prog.kernel_symbol[symbol:visual.blocks.13.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001af prog.kernel_symbol[symbol:visual.blocks.13.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001b0 prog.kernel_symbol[symbol:visual.blocks.13.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001b1 prog.kernel_symbol[symbol:visual.blocks.13.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001b2 prog.kernel_symbol[symbol:visual.blocks.14.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001b3 prog.kernel_symbol[symbol:visual.blocks.14.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001b4 prog.kernel_symbol[symbol:visual.blocks.14.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001b5 prog.kernel_symbol[symbol:visual.blocks.14.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001b6 prog.kernel_symbol[symbol:visual.blocks.14.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001b7 prog.kernel_symbol[symbol:visual.blocks.14.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001b8 prog.kernel_symbol[symbol:visual.blocks.14.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001b9 prog.kernel_symbol[symbol:visual.blocks.14.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001ba prog.kernel_symbol[symbol:visual.blocks.14.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001bb prog.kernel_symbol[symbol:visual.blocks.14.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001bc prog.kernel_symbol[symbol:visual.blocks.15.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001bd prog.kernel_symbol[symbol:visual.blocks.15.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001be prog.kernel_symbol[symbol:visual.blocks.15.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001bf prog.kernel_symbol[symbol:visual.blocks.15.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001c0 prog.kernel_symbol[symbol:visual.blocks.15.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001c1 prog.kernel_symbol[symbol:visual.blocks.15.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001c2 prog.kernel_symbol[symbol:visual.blocks.15.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001c3 prog.kernel_symbol[symbol:visual.blocks.15.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001c4 prog.kernel_symbol[symbol:visual.blocks.15.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001c5 prog.kernel_symbol[symbol:visual.blocks.15.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001c6 prog.kernel_symbol[symbol:visual.blocks.16.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001c7 prog.kernel_symbol[symbol:visual.blocks.16.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001c8 prog.kernel_symbol[symbol:visual.blocks.16.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001c9 prog.kernel_symbol[symbol:visual.blocks.16.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001ca prog.kernel_symbol[symbol:visual.blocks.16.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001cb prog.kernel_symbol[symbol:visual.blocks.16.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001cc prog.kernel_symbol[symbol:visual.blocks.16.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001cd prog.kernel_symbol[symbol:visual.blocks.16.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001ce prog.kernel_symbol[symbol:visual.blocks.16.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001cf prog.kernel_symbol[symbol:visual.blocks.16.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001d0 prog.kernel_symbol[symbol:visual.blocks.17.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001d1 prog.kernel_symbol[symbol:visual.blocks.17.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001d2 prog.kernel_symbol[symbol:visual.blocks.17.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001d3 prog.kernel_symbol[symbol:visual.blocks.17.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001d4 prog.kernel_symbol[symbol:visual.blocks.17.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001d5 prog.kernel_symbol[symbol:visual.blocks.17.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001d6 prog.kernel_symbol[symbol:visual.blocks.17.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001d7 prog.kernel_symbol[symbol:visual.blocks.17.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001d8 prog.kernel_symbol[symbol:visual.blocks.17.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001d9 prog.kernel_symbol[symbol:visual.blocks.17.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001da prog.kernel_symbol[symbol:visual.blocks.18.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001db prog.kernel_symbol[symbol:visual.blocks.18.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001dc prog.kernel_symbol[symbol:visual.blocks.18.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001dd prog.kernel_symbol[symbol:visual.blocks.18.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001de prog.kernel_symbol[symbol:visual.blocks.18.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001df prog.kernel_symbol[symbol:visual.blocks.18.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001e0 prog.kernel_symbol[symbol:visual.blocks.18.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001e1 prog.kernel_symbol[symbol:visual.blocks.18.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001e2 prog.kernel_symbol[symbol:visual.blocks.18.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001e3 prog.kernel_symbol[symbol:visual.blocks.18.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001e4 prog.kernel_symbol[symbol:visual.blocks.19.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001e5 prog.kernel_symbol[symbol:visual.blocks.19.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001e6 prog.kernel_symbol[symbol:visual.blocks.19.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001e7 prog.kernel_symbol[symbol:visual.blocks.19.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001e8 prog.kernel_symbol[symbol:visual.blocks.19.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001e9 prog.kernel_symbol[symbol:visual.blocks.19.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001ea prog.kernel_symbol[symbol:visual.blocks.19.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001eb prog.kernel_symbol[symbol:visual.blocks.19.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001ec prog.kernel_symbol[symbol:visual.blocks.19.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001ed prog.kernel_symbol[symbol:visual.blocks.19.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001ee prog.kernel_symbol[symbol:visual.blocks.20.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001ef prog.kernel_symbol[symbol:visual.blocks.20.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001f0 prog.kernel_symbol[symbol:visual.blocks.20.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001f1 prog.kernel_symbol[symbol:visual.blocks.20.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001f2 prog.kernel_symbol[symbol:visual.blocks.20.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001f3 prog.kernel_symbol[symbol:visual.blocks.20.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001f4 prog.kernel_symbol[symbol:visual.blocks.20.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001f5 prog.kernel_symbol[symbol:visual.blocks.20.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x000000000001f6 prog.kernel_symbol[symbol:visual.blocks.20.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x000000000001f7 prog.kernel_symbol[symbol:visual.blocks.20.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x000000000001f8 prog.kernel_symbol[symbol:visual.blocks.21.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001f9 prog.kernel_symbol[symbol:visual.blocks.21.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x000000000001fa prog.kernel_symbol[symbol:visual.blocks.21.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x000000000001fb prog.kernel_symbol[symbol:visual.blocks.21.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x000000000001fc prog.kernel_symbol[symbol:visual.blocks.21.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x000000000001fd prog.kernel_symbol[symbol:visual.blocks.21.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x000000000001fe prog.kernel_symbol[symbol:visual.blocks.21.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x000000000001ff prog.kernel_symbol[symbol:visual.blocks.21.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000200 prog.kernel_symbol[symbol:visual.blocks.21.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000201 prog.kernel_symbol[symbol:visual.blocks.21.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000202 prog.kernel_symbol[symbol:visual.blocks.22.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000203 prog.kernel_symbol[symbol:visual.blocks.22.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000204 prog.kernel_symbol[symbol:visual.blocks.22.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000205 prog.kernel_symbol[symbol:visual.blocks.22.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000206 prog.kernel_symbol[symbol:visual.blocks.22.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000207 prog.kernel_symbol[symbol:visual.blocks.22.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000208 prog.kernel_symbol[symbol:visual.blocks.22.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000209 prog.kernel_symbol[symbol:visual.blocks.22.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000020a prog.kernel_symbol[symbol:visual.blocks.22.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000020b prog.kernel_symbol[symbol:visual.blocks.22.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000020c prog.kernel_symbol[symbol:visual.blocks.23.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000020d prog.kernel_symbol[symbol:visual.blocks.23.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000020e prog.kernel_symbol[symbol:visual.blocks.23.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000020f prog.kernel_symbol[symbol:visual.blocks.23.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000210 prog.kernel_symbol[symbol:visual.blocks.23.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000211 prog.kernel_symbol[symbol:visual.blocks.23.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000212 prog.kernel_symbol[symbol:visual.blocks.23.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000213 prog.kernel_symbol[symbol:visual.blocks.23.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000214 prog.kernel_symbol[symbol:visual.blocks.23.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000215 prog.kernel_symbol[symbol:visual.blocks.23.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000216 prog.kernel_symbol[symbol:visual.blocks.24.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000217 prog.kernel_symbol[symbol:visual.blocks.24.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000218 prog.kernel_symbol[symbol:visual.blocks.24.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000219 prog.kernel_symbol[symbol:visual.blocks.24.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000021a prog.kernel_symbol[symbol:visual.blocks.24.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000021b prog.kernel_symbol[symbol:visual.blocks.24.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000021c prog.kernel_symbol[symbol:visual.blocks.24.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000021d prog.kernel_symbol[symbol:visual.blocks.24.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000021e prog.kernel_symbol[symbol:visual.blocks.24.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000021f prog.kernel_symbol[symbol:visual.blocks.24.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000220 prog.kernel_symbol[symbol:visual.blocks.25.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000221 prog.kernel_symbol[symbol:visual.blocks.25.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000222 prog.kernel_symbol[symbol:visual.blocks.25.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000223 prog.kernel_symbol[symbol:visual.blocks.25.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000224 prog.kernel_symbol[symbol:visual.blocks.25.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000225 prog.kernel_symbol[symbol:visual.blocks.25.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000226 prog.kernel_symbol[symbol:visual.blocks.25.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000227 prog.kernel_symbol[symbol:visual.blocks.25.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000228 prog.kernel_symbol[symbol:visual.blocks.25.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000229 prog.kernel_symbol[symbol:visual.blocks.25.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000022a prog.kernel_symbol[symbol:visual.blocks.26.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000022b prog.kernel_symbol[symbol:visual.blocks.26.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000022c prog.kernel_symbol[symbol:visual.blocks.26.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000022d prog.kernel_symbol[symbol:visual.blocks.26.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000022e prog.kernel_symbol[symbol:visual.blocks.26.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000022f prog.kernel_symbol[symbol:visual.blocks.26.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000230 prog.kernel_symbol[symbol:visual.blocks.26.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000231 prog.kernel_symbol[symbol:visual.blocks.26.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000232 prog.kernel_symbol[symbol:visual.blocks.26.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000233 prog.kernel_symbol[symbol:visual.blocks.26.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000234 prog.kernel_symbol[symbol:visual.blocks.27.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000235 prog.kernel_symbol[symbol:visual.blocks.27.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000236 prog.kernel_symbol[symbol:visual.blocks.27.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000237 prog.kernel_symbol[symbol:visual.blocks.27.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000238 prog.kernel_symbol[symbol:visual.blocks.27.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000239 prog.kernel_symbol[symbol:visual.blocks.27.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000023a prog.kernel_symbol[symbol:visual.blocks.27.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000023b prog.kernel_symbol[symbol:visual.blocks.27.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000023c prog.kernel_symbol[symbol:visual.blocks.27.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000023d prog.kernel_symbol[symbol:visual.blocks.27.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000023e prog.kernel_symbol[symbol:visual.blocks.28.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000023f prog.kernel_symbol[symbol:visual.blocks.28.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000240 prog.kernel_symbol[symbol:visual.blocks.28.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000241 prog.kernel_symbol[symbol:visual.blocks.28.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000242 prog.kernel_symbol[symbol:visual.blocks.28.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000243 prog.kernel_symbol[symbol:visual.blocks.28.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000244 prog.kernel_symbol[symbol:visual.blocks.28.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000245 prog.kernel_symbol[symbol:visual.blocks.28.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000246 prog.kernel_symbol[symbol:visual.blocks.28.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000247 prog.kernel_symbol[symbol:visual.blocks.28.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000248 prog.kernel_symbol[symbol:visual.blocks.29.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000249 prog.kernel_symbol[symbol:visual.blocks.29.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000024a prog.kernel_symbol[symbol:visual.blocks.29.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000024b prog.kernel_symbol[symbol:visual.blocks.29.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x0000000000024c prog.kernel_symbol[symbol:visual.blocks.29.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x0000000000024d prog.kernel_symbol[symbol:visual.blocks.29.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x0000000000024e prog.kernel_symbol[symbol:visual.blocks.29.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x0000000000024f prog.kernel_symbol[symbol:visual.blocks.29.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000250 prog.kernel_symbol[symbol:visual.blocks.29.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000251 prog.kernel_symbol[symbol:visual.blocks.29.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000252 prog.kernel_symbol[symbol:visual.blocks.30.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000253 prog.kernel_symbol[symbol:visual.blocks.30.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000254 prog.kernel_symbol[symbol:visual.blocks.30.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x00000000000255 prog.kernel_symbol[symbol:visual.blocks.30.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000256 prog.kernel_symbol[symbol:visual.blocks.30.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000257 prog.kernel_symbol[symbol:visual.blocks.30.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000258 prog.kernel_symbol[symbol:visual.blocks.30.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000259 prog.kernel_symbol[symbol:visual.blocks.30.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x0000000000025a prog.kernel_symbol[symbol:visual.blocks.30.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x0000000000025b prog.kernel_symbol[symbol:visual.blocks.30.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x0000000000025c prog.kernel_symbol[symbol:visual.blocks.31.norm1, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000025d prog.kernel_symbol[symbol:visual.blocks.31.norm2, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x0000000000025e prog.kernel_symbol[symbol:visual.blocks.31.attn.qkv, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":3840}]
        addr:0x0000000000025f prog.kernel_symbol[symbol:visual.blocks.31.attn.vision_rope_q, op_type:SiLU, op_options:null]
        addr:0x00000000000260 prog.kernel_symbol[symbol:visual.blocks.31.attn.vision_rope_k, op_type:SiLU, op_options:null]
        addr:0x00000000000261 prog.kernel_symbol[symbol:visual.blocks.31.attn.softmax, op_type:Softmax, op_options:{"axis":-1}]
        addr:0x00000000000262 prog.kernel_symbol[symbol:visual.blocks.31.attn.proj, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":1280}]
        addr:0x00000000000263 prog.kernel_symbol[symbol:visual.blocks.31.mlp.fc1, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":1280,"out_channels":5120}]
        addr:0x00000000000264 prog.kernel_symbol[symbol:visual.blocks.31.mlp.act, op_type:QuickGELU, op_options:null]
        addr:0x00000000000265 prog.kernel_symbol[symbol:visual.blocks.31.mlp.fc2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1280}]
        addr:0x00000000000266 prog.kernel_symbol[symbol:visual.merger.ln_q, op_type:LayerNorm, op_options:{"bias":true,"elementwise_affine":true,"eps":9.999999974752427e-07,"normalized_shape":[1280]}]
        addr:0x00000000000267 prog.kernel_symbol[symbol:visual.merger.mlp.0, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":5120}]
        addr:0x00000000000268 prog.kernel_symbol[symbol:visual.merger.mlp.gelu, op_type:GELU, op_options:null]
        addr:0x00000000000269 prog.kernel_symbol[symbol:visual.merger.mlp.2, op_type:Linear, op_options:{"bias":true,"impl_type":"KaiLinear_f32_qai8dxp_qsi4c32p_mxk_nxk_qai8dxp1x8_qsi4c32p8x8_1x8x32","in_channels":5120,"out_channels":1536}]
    }
}
 
